% This file was created with JabRef 2.10.
% Encoding: UTF-8


@book{2009ConvergenceSystems,
  title     = {{Convergence and Knowledge Processing in Multi-Agent Systems}},
  publisher = {Springer London},
  year      = {2009},
  booktitle = {Convergence and Knowledge Processing in Multi-Agent Systems},
  doi       = {10.1007/978-1-84882-063-0}
}

@misc{6.Documentation,
  title = {{6. Camera Hardware — Picamera 1.12 documentation}},
  url   = {https://picamera.readthedocs.io/en/release-1.12/fov.html}
}

@article{Abukhalil2016DeploymentRobots,
  title    = {{Deployment environment for a swarm of heterogeneous robots}},
  author   = {Abukhalil, Tamer and Patil, Madhav and Patel, Sarosh and Sobh, Tarek},
  journal  = {Robotics},
  year     = {2016},
  doi      = {10.3390/robotics5040022},
  issn     = {22186581},
  keywords = {Dynamic robotic coordination, Heterogeneous swarm agents, Reconfigurable robotic agents, Robotics interactive software, Robots deployment environment}
}

@inproceedings{Adhvaryu2017,
  title     = {{Design of fuzzy based intelligent controller for autonomous mobile robot navigation}},
  author    = {Adhvaryu, Aniket D. and Adarsh, S. and Ramchandran, K. I.},
  booktitle = {2017 International Conference on Advances in Computing, Communications and Informatics, ICACCI 2017},
  year      = {2017},
  month     = {11},
  pages     = {841--846},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  volume    = {2017-Janua},
  doi       = {10.1109/ICACCI.2017.8125946},
  isbn      = {9781509063673},
  keywords  = {Autonomous mobile robot, Data fusion, Fuzzy inference system, LiDAR, Obstacle avoidance, Ultrasonic}
}

@techreport{Ahmed2015,
  title     = {{Path Planning of Mobile Robot by using Modified Optimized Potential Field Method}},
  author    = {Ahmed, Alaa A and Abdalla, Turki Y and Abed, Ali A},
  year      = {2015},
  number    = {4},
  booktitle = {International Journal of Computer Applications},
  keywords  = {Artificial Potential Fields, PID Controller, Particle swarm optimization, Path Planning},
  pages     = {975--8887},
  url       = {https://pdfs.semanticscholar.org/8c7c/3c723514b338a09deb589da80c093d9dc116.pdf},
  volume    = {113}
}

@article{Alkafaween2017,
  title     = {{On enhancing genetic algorithms using new crossovers}},
  author    = {Alkafaween, Esra'a and Hassanat, Ahmad B.A.},
  journal   = {International Journal of Computer Applications in Technology},
  year      = {2017},
  number    = {3},
  pages     = {202},
  volume    = {55},
  doi       = {10.1504/ijcat.2017.10005868},
  issn      = {0952-8091},
  publisher = {Inderscience Publishers}
}

@inproceedings{Alsaab2014,
  title     = {{Improving velocity obstacle approach for obstacle avoidance in indoor environments}},
  author    = {Alsaab, Ahmad and Bicker, Robert},
  booktitle = {2014 UKACC International Conference on Control, CONTROL 2014 - Proceedings},
  year      = {2014},
  month     = {10},
  pages     = {325--330},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  doi       = {10.1109/CONTROL.2014.6915161},
  isbn      = {9781479950119},
  keywords  = {Velocity obstacle, collision time, non-circular objects}
}

@inproceedings{Amato2015,
  title     = {{Planning for decentralized control of multiple robots under uncertainty}},
  author    = {Amato, Christopher and Konidaris, George and Cruz, Gabriel and Maynor, Christopher A. and How, Jonathan P. and Kaelbling, Leslie P.},
  booktitle = {2015 IEEE International Conference on Robotics and Automation (ICRA)},
  year      = {2015},
  month     = {5},
  pages     = {1241--1248},
  publisher = {IEEE},
  doi       = {10.1109/ICRA.2015.7139350},
  isbn      = {978-1-4799-6923-4},
  url       = {http://ieeexplore.ieee.org/document/7139350/}
}

@inproceedings{Amato2015PlanningUncertainty,
  title     = {{Planning for decentralized control of multiple robots under uncertainty}},
  author    = {Amato, Christopher and Konidaris, George and Cruz, Gabriel and Maynor, Christopher A. and How, Jonathan P. and Kaelbling, Leslie P.},
  booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
  year      = {2015},
  number    = {June},
  pages     = {1241--1248},
  volume    = {2015-June},
  arxivid   = {1402.2871},
  doi       = {10.1109/ICRA.2015.7139350},
  issn      = {10504729},
  url       = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7139350&tag=1}
}

@techreport{Amato2017Decision-MakingLearning,
  title    = {{Decision-Making Under Uncertainty in Multi-Agent and Multi-Robot Systems: Planning and Learning}},
  author   = {Amato, Christopher},
  year     = {2017},
  keywords = {Agent-based and Multi-agent Systems: Multi-agent Learning, Agent-based and Multi-agent Systems: Multi-agent Planning, Machine Learning: Reinforcement Learning, Robotics: Multi-Robot Systems},
  url      = {https://youtu.be/34xHxXrnPHw,}
}

@article{Amir2019SummarizingStrategies,
  title     = {{Summarizing agent strategies}},
  author    = {Amir, Ofra and Doshi-Velez, Finale and Sarne, David},
  journal   = {Autonomous Agents and Multi-Agent Systems},
  year      = {2019},
  month     = {9},
  number    = {5},
  pages     = {628--644},
  volume    = {33},
  doi       = {10.1007/s10458-019-09418-w},
  issn      = {1387-2532},
  publisher = {Springer Science and Business Media LLC}
}

@techreport{AnAlgorithms,
  title = {{An Idiot's guide to Support vector machines (SVMs) R. Berwick, Village Idiot SVMs: A New Generation of Learning Algorithms}},
  url   = {http://web.mit.edu/6.034/wwwbob/svm-notes-long-08.pdf}
}

@article{Aras2010AnPOMDPs,
  title   = {{An investigation into mathematical programming for finite horizon decentralized POMDPs}},
  author  = {Aras, Raghav and Dutech, Alain},
  journal = {Journal of Artificial Intelligence Research},
  year    = {2010},
  month   = {1},
  pages   = {329--396},
  volume  = {37},
  doi     = {10.1613/jair.2915},
  issn    = {10769757}
}

@article{Arbanas2018DecentralizedTeams,
  title    = {{Decentralized planning and control for UAV-UGV cooperative teams}},
  author   = {Arbanas, Barbara and Ivanovic, Antun and Car, Marko and Orsag, Matko and Petrovic, Tamara and Bogdan, Stjepan},
  journal  = {Autonomous Robots},
  year     = {2018},
  pages    = {1601--1618},
  volume   = {42},
  doi      = {10.1007/s10514-018-9712-y},
  keywords = {Aerial manipulation, Decentralized planning, Heterogeneous robotics systems, Unmanned aerial system},
  url      = {https://doi.org/10.1007/s10514-018-9712-y}
}
@techreport{Arora2019OnlineOcclusion,
  title     = {{Online Inverse Reinforcement Learning Under Occlusion}},
  author    = {Arora, Saurabh and Doshi, Prashant and Banerjee, Bikramjit},
  year      = {2019},
  keywords  = {Inverse Reinforcement Learning, Online Learning, Reinforcement Learning, Robot Learning, Robotics},
  publisher = {AAMAS},
  url       = {www.ifaamas.org}
}


@article{Ayanian2019DART:Teams,
  title     = {{DART: Diversity-enhanced Autonomy in Robot Teams}},
  author    = {Ayanian, Nora},
  journal   = {International Journal of Robotics Research},
  year      = {2019},
  month     = {10},
  doi       = {10.1177/0278364919839137},
  issn      = {17413176},
  keywords  = {Multi-robot systems, multi-agent systems},
  publisher = {SAGE Publications Inc.}
}

@article{Bailey2019FiniteDescent-Ascent,
  title   = {{Finite Regret and Cycles with Fixed Step-Size via Alternating Gradient Descent-Ascent}},
  author  = {Bailey, James P and Gidel, Gauthier},
  year    = {2019},
  pages   = {1--15},
  arxivid = {arXiv:1907.04392v1}
}

@techreport{Bailey2019Multi-AgentSystem,
  title     = {{Multi-Agent Learning in Net-work Zero-Sum Games is a Hamiltonian System}},
  author    = {Bailey, James P and Piliouras, Georgios},
  year      = {2019},
  booktitle = {IFAAMAS},
  url       = {www.ifaamas.org},
  volume    = {9}
}
@inproceedings{Baklouti2015,
  title     = {{Autonomous mobile robot navigation coupling fuzzy logic and reactive DVZ 3D obstacle avoidance control}},
  author    = {Baklouti, Emna and Jallouli, Mohamed and Ben Amor, Nader and Titi, Sondes and Nafti, Ahlem},
  booktitle = {INISTA 2015 - 2015 International Symposium on Innovations in Intelligent SysTems and Applications, Proceedings},
  year      = {2015},
  month     = {9},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  doi       = {10.1109/INISTA.2015.7276748},
  isbn      = {9781467390965},
  keywords  = {3D obstacle, Autonomous robot, DVZ, FLC, Obstacle avoidance, Reactive control}
}

@book{Barber2012,
  title     = {{Bayesian Reasoning and Machine Learning}},
  author    = {Barber, D},
  publisher = {Cambridge University Press},
  year      = {2012}
}

@inproceedings{Bardi1991DifferentialDisturbances,
  title     = {{Differential games and totally risk-averse optimal control of systems with small disturbances}},
  author    = {Bardi, Martino and Sartori, Caterina},
  booktitle = {Lecture Notes in Control and Information Sciences},
  year      = {1991},
  pages     = {91--99},
  publisher = {Publ by Springer-Verlag Berlin},
  volume    = {156},
  doi       = {10.1007/bfb0040230},
  issn      = {01708643}
}


@misc{BASE,
  title = {{BASE}},
  url   = {https://base.xsens.com/hc/en-us/articles/115000224125-RMS-noise-of-accelerometers-and-gyroscopes}
}


@misc{BASEb,
  title = {{BASE}},
  url   = {https://base.xsens.com/hc/en-us/articles/115000224125-RMS-noise-of-accelerometers-and-gyroscopes}
}


@misc{BASEc,
  title = {{BASE}},
  url   = {https://base.xsens.com/hc/en-us/articles/115000224125-RMS-noise-of-accelerometers-and-gyroscopes}
}


@misc{BasicDownload,
  title = {{Basic variety of flat drones Vector | Free Download}},
  url   = {https://www.freepik.com/free-vector/basic-variety-flat-drones_1348538.htm#page=1&query=drone&position=2}
}

@misc{Beauregard,
  title  = {{Improving the Beginner’s PID – Introduction « Project Blog}},
  author = {Beauregard, Brett},
  url    = {http://brettbeauregard.com/blog/2011/04/improving-the-beginners-pid-introduction/?fbclid=IwAR0THEfOHcZrEy6XChFd-4apMfGsoOZ1KC1iLWEcK-LUvhERLpxJROuOiq8}
}

@article{Bellomo2017,
  abstract  = {This paper addresses some preliminary steps toward the modeling and qualitative analysis of swarms viewed as living complex systems. The approach is based on the methods of kinetic theory and statistical mechanics, where interactions at the microscopic scale are nonlocal, nonlinearly additive and modeled by theoretical tools of stochastic game theory. Collective learning theory can play an important role in the modeling approach. We present a kinetic equation incorporating the Cucker-Smale flocking force and stochastic game theoretic interactions in collision operators. We also present a sufficient framework leading to the asymptotic velocity alignment and global existence of smooth solutions for the proposed kinetic model with a special kernel. Analytic results on the global existence and flocking dynamics are presented, while the last part of the paper looks ahead to research perspectives.},
  author    = {Bellomo, Nicola and Ha, Seung Yeal},
  doi       = {10.1142/S0218202517500154},
  issn      = {02182025},
  journal   = {Mathematical Models and Methods in Applied Sciences},
  keywords  = {Collective dynamics,Cucker-Smale flocking,collective behavior,learning,living complex systems,nonlinear interactions,self-organization,swarming},
  month     = {apr},
  number    = {4},
  pages     = {745--770},
  publisher = {World Scientific Publishing Co. Pte Ltd},
  title     = {{A quest toward a mathematical theory of the dynamics of swarms}},
  volume    = {27},
  year      = {2017}
}

@inproceedings{Berkenkamp2017,
  title         = {{Safe model-based reinforcement learning with stability guarantees}},
  author        = {Berkenkamp, Felix and Turchetta, Matteo and Schoellig, Angela P and Krause, Andreas},
  booktitle     = {Advances in Neural Information Processing Systems},
  year          = {2017},
  pages         = {909--919},
  volume        = {2017-Decem},
  abstract      = {Reinforcement learning is a powerful paradigm for learning optimal policies from experimental data. However, to find optimal policies, most reinforcement learning algorithms explore all possible actions, which may be harmful for real-world systems. As a consequence, learning algorithms are rarely applied on safety-critical systems in the real world. In this paper, we present a learning algorithm that explicitly considers safety, defined in terms of stability guarantees. Specifically, we extend control-theoretic results on Lyapunov stability verification and show how to use statistical models of the dynamics to obtain high-performance control policies with provable stability certificates. Moreover, under additional regularity assumptions in terms of a Gaussian process prior, we prove that one can effectively and safely collect data in order to learn about the dynamics and thus both improve control performance and expand the safe region of the state space. In our experiments, we show how the resulting algorithm can safely optimize a neural network policy on a simulated inverted pendulum, without the pendulum ever falling down.},
  archiveprefix = {arXiv},
  arxivid       = {1705.08551},
  eprint        = {1705.08551},
  file          = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Berkenkamp et al. - Unknown - Safe Model-based Reinforcement Learning with Stability Guarantees.pdf:pdf},
  issn          = {10495258}
}

@inproceedings{Berkenkamp2017SafeGuarantees,
  title     = {{Safe model-based reinforcement learning with stability guarantees}},
  author    = {Berkenkamp, Felix and Turchetta, Matteo and Schoellig, Angela P and Krause, Andreas},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2017},
  pages     = {909--919},
  volume    = {2017-Decem},
  arxivid   = {1705.08551},
  issn      = {10495258}
}

@misc{BernardineDias2006Market-basedAnalysis,
  title     = {{Market-based multirobot coordination: A survey and analysis}},
  author    = {Bernardine Dias, M. and Zlot, Robert and Kalra, Nidhi and Stentz, Anthony},
  month     = {7},
  year      = {2006},
  booktitle = {Proceedings of the IEEE},
  doi       = {10.1109/JPROC.2006.876939},
  issn      = {00189219},
  keywords  = {Auctions, Market-based coordination, Multirobot teams, Resource allocation, Task allocation},
  number    = {7},
  pages     = {1257--1270},
  volume    = {94}
}

@techreport{Bhalla2019TrainingLearning,
  title    = {{Training Cooperative Agents for Multi-Agent Reinforcement Learning}},
  author   = {Bhalla, Sushrut and Subramanian, Sriram G and Crowley, Mark},
  year     = {2019},
  arxivid  = {1606.01540},
  keywords = {Autonomous Driving, MARL, Multi-Agent Reinforcement Learning, MultiAgent Systems, Reinforcement Learning},
  url      = {www.ifaamas.org}
}

@inproceedings{Blackmore2007,
  abstract  = {Hybrid discrete-continuous models, such as Jump Markov Linear Systems, are convenient tools for representing many real-world systems; in the case of fault detection, discrete jumps in the continuous dynamics are used to model system failures. Stochastic uncertainty in hybrid systems arises in both the continuous dynamics, in the form of uncertain state estimation, disturbances or uncertain modeling, and in the discrete dynamics, which are themselves stochastic. In this paper we present a novel method for optimal predictive control of Jump Markov Linear Systems that is robust to both continuous and discrete uncertainty. The approach extends our previous 'particle control' approach, which approximates the predicted distribution of the system state using a finite number of particles. Here, we present a weighted particle control approach, which uses importance weighting to ensure that low probability events such as failures are considered. We demonstrate the method with a car braking scenario. {\textcopyright} Springer-Verlag Berlin Heidelberg 2007.},
  author    = {Blackmore, Lars and Bektassov, Askar and Ono, Masahiro and Williams, Brian C.},
  booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  doi       = {10.1007/978-3-540-71493-4_11},
  isbn      = {9783540714927},
  issn      = {03029743},
  pages     = {104--117},
  title     = {{Robust, optimal predictive control of jump Markov Linear Systems using particles}},
  volume    = {4416 LNCS},
  year      = {2007}
}

@techreport{BlochInterdisciplinaryEdition,
  title  = {{Interdisciplinary Applied Mathematics 24 Nonholonomic Mechanics and Control Second Edition}},
  author = {Bloch, A M and Baillieul, J and Crouch, P and Marsden, J E and Zenkov, D},
  url    = {http://www.springer.com/series/1390}
}

@article{Boone2019FromTheory,
  title   = {{From Darwin to Poincar{\textbackslash}'e and von Neumann: Recurrence and Cycles in Evolutionary and Algorithmic Game Theory}},
  author  = {Boone, Victor and Piliouras, Georgios},
  year    = {2019},
  arxivid = {1910.01334},
  url     = {http://arxiv.org/abs/1910.01334}
}

@techreport{Borenstein1991,
  title     = {{THE VECTOR FIELD HISTOGRAM-FAST OBSTACLE AVOIDANCE FOR MOBILE ROBOTS}},
  author    = {Borenstein, by J and Koren, Y and Member, Senior},
  year      = {1991},
  number    = {3},
  booktitle = {IEEE Journal of Robotics and Automation},
  pages     = {278--288},
  url       = {http://www-personal.umich.edu/~johannb/Papers/paper16.pdf},
  volume    = {7}
}

@article{Borzi2015,
  abstract  = {A new refined flocking model that includes self-propelling, friction, attraction and repulsion, and alignment features is presented. This model takes into account various behavioral phenomena observed in biological and social systems. In addition, the presence of a leader is included in the system in order to develop a control strategy for the flocking model to accomplish desired objectives. Specifically, a model predictive control scheme is proposed that requires the solution of a sequence of open-loop optimality systems. An accurate Runge-Kutta scheme to discretize the optimality systems and a nonlinear conjugate gradient solver are implemented and discussed. Numerical experiments are performed that investigate the properties of the refined flocking model and demonstrate the ability of the control strategy to drive the flocking system to attain a desired target configuration and to follow a given trajectory.},
  author    = {Borz{\`{i}}, Alfio and Wongkaew, Suttida},
  doi       = {10.1142/S0218202515500098},
  issn      = {02182025},
  journal   = {Mathematical Models and Methods in Applied Sciences},
  keywords  = {Optimal control theory,Runge-Kutta method.,Swarming systems},
  month     = {feb},
  number    = {2},
  pages     = {255--282},
  publisher = {World Scientific Publishing Co. Pte Ltd},
  title     = {{Modeling and control through leadership of a refined flocking system}},
  volume    = {25},
  year      = {2015}
}

@inproceedings{Brafman2013QualitativeDomains,
  title     = {{Qualitative planning under partial observability in multi-agent domains}},
  author    = {Brafman, Ronen I. and Shani, Guy and Zilberstein, Shlomo},
  booktitle = {Proceedings of the 27th AAAI Conference on Artificial Intelligence, AAAI 2013},
  year      = {2013},
  pages     = {130--137},
  isbn      = {9781577356158}
}

@techreport{Bredereck2019HedonicGames,
  title    = {{Hedonic Diversity Games}},
  author   = {Bredereck, Robert and Elkind, Edith and Igarashi, Ayumi},
  year     = {2019},
  keywords = {Hedonic games, Schelling segregation, fractional hedonic games},
  url      = {www.ifaamas.org}
}

@incollection{Breitner1994ReentryGame,
  title     = {{Reentry Trajectory Optimization under Atmospheric Uncertainty as a Differential Game}},
  author    = {Breitner, Michael H. and Pesch, H. Joseph},
  booktitle = {Advances in Dynamic Games and Applications},
  publisher = {Birkh{\"{a}}user Boston},
  year      = {1994},
  pages     = {70--86},
  doi       = {10.1007/978-1-4612-0245-5{\_}4}
}

@article{Brunton2019MachineMechanics,
  title    = {{Machine Learning for Fluid Mechanics}},
  author   = {Brunton, Steven L and Noack, Bernd R and Koumoutsakos, Petros},
  year     = {2019},
  arxivid  = {1905.11075v2},
  doi      = {10.1146/((please)},
  keywords = {control, data-driven modeling, machine learning, optimization},
  url      = {https://doi.org/10.1146/}
}

@techreport{Busoniu2006Multi-agentSurvey,
  title    = {{Multi-agent reinforcement learning: A survey * "Multi-agent reinforcement learning: A survey Multi-Agent Reinforcement Learning: A Survey}},
  author   = {Bus¸oniu, L Bus¸oniu and Babu{\v{s}}ka, R and De Schutter, B and Bus¸oniu, Lucian Bus¸oniu and Babu{\v{s}}ka, Robert and De Schutter, Bart},
  year     = {2006},
  isbn     = {3115278.66.7},
  keywords = {distributed control, game theory, multi-agent systems, reinforcement learning},
  pages    = {527--532}
}

@inproceedings{Cacitti,
  title     = {{Reactive behaviours of mobile manipulators based on the DVZ approach}},
  author    = {Cacitti, A. and Zapata, R.},
  booktitle = {Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164)},
  pages     = {680--685},
  publisher = {IEEE},
  volume    = {1},
  doi       = {10.1109/ROBOT.2001.932629},
  isbn      = {0-7803-6576-3},
  url       = {http://ieeexplore.ieee.org/document/932629/}
}

@article{Cao2015MixedUAV,
  title    = {{Mixed dynamic task allocation for multiple UAV}},
  author   = {Cao, Lei and Tan, Heshun and Peng, Hui and Pan, Mingcong},
  journal  = {Nanjing Li Gong Daxue Xuebao/Journal of Nanjing University of Science and Technology},
  year     = {2015},
  doi      = {10.14177/j.cnki.32-1397n.2015.39.02.014},
  issn     = {10059830},
  keywords = {Decentralized auction algorithm, Dynamic task allocation, Particle swarm optimizer-fish swarm algorithm, State information}
}

@article{Carcassi2018FromMechanics,
  title   = {{From physical assumptions to classical and quantum Hamiltonian and Lagrangian particle mechanics}},
  author  = {Carcassi, Gabriele and Aidala, Christine and Baker, David John and Bieri, Lydia},
  journal = {Journal of Physics Communications},
  year    = {2018},
  arxivid = {1702.07052},
  doi     = {10.1088/2399-6528/aaba25},
  issn    = {2399-6528}
}

@book{CarrerasPerez2004,
  title     = {{A Proposal of a behavior-based control architecture with reinforcement learning for an autonomous underwater robot}},
  author    = {Carreras Pérez, Marc. and Ridao Rodríguez, Pere. and Universitat de Girona. Departament d'Electrònica, Informàtica i Automàtica.},
  publisher = {Universitat de Girona},
  year      = {2004},
  isbn      = {8468852546}
}

@misc{Cerarsouza2010,
  title  = {{Kernel Functions for Machine Learning Applications – C{\'{e}}sar Souza}},
  author = {{Cerarsouza}},
  year   = {2010},
  url    = {http://crsouza.com/2010/03/17/kernel-functions-for-machine-learning-applications/}
}

@article{Chakravarthy1998,
  title    = {{Obstacle avoidance in a dynamic environment: A collision cone approach}},
  author   = {Chakravarthy, Animesh and Ghose, Debasish},
  journal  = {IEEE Transactions on Systems, Man, and Cybernetics Part A:Systems and Humans.},
  year     = {1998},
  number   = {5},
  pages    = {562--574},
  volume   = {28},
  doi      = {10.1109/3468.709600},
  issn     = {10834427},
  keywords = {Collision cone, Dynamic environments, Obstacle avoidance, Path planning}
}

@article{Chakravarthy2012,
  title    = {{Generalization of the collision cone approach for motion safety in 3-D environments}},
  author   = {Chakravarthy, Animesh and Ghose, Debasish},
  journal  = {Autonomous Robots},
  year     = {2012},
  month    = {4},
  number   = {3},
  pages    = {243--266},
  volume   = {32},
  doi      = {10.1007/s10514-011-9270-z},
  issn     = {09295593},
  keywords = {Collision cone, Dynamic environments, Obstacle avoidance, Path planning, Quadric surfaces}
}

@techreport{CheatSheet2019,
  title  = {{ML Cheatsheet Documentation Team}},
  author = {{CheatSheet}},
  year   = {2019},
  url    = {https://buildmedia.readthedocs.org/media/pdf/ml-cheatsheet/latest/ml-cheatsheet.pdf}
}

@article{Chen2010ACollaboration,
  title    = {{A Multi-Robots Task Allocation Algorithm Based on Relevance and Ability With Group Collaboration}},
  author   = {Chen, Jian and Yang, Xiangguo and Hu, Yuxi and Han, Yanyan and Li, Deshi and Zhang, Guangmin},
  journal  = {Article in International Journal of Intelligent Engineering and Systems},
  year     = {2010},
  doi      = {10.22266/ijies2010.0630.05},
  keywords = {Group Collaboration, Mobile Agent, Multi-Robots, Task Allocation, ：Mobile Robots Team},
  url      = {https://www.researchgate.net/publication/267968475}
}

@incollection{Cherkassky2002,
  title  = {{Selection of Meta-parameters for Support Vector Regression}},
  author = {Cherkassky, Vladimir and Ma, Yunqian},
  year   = {2002},
  pages  = {687--693},
  doi    = {10.1007/3-540-46084-5{\_}112},
  url    = {http://link.springer.com/10.1007/3-540-46084-5_112}
}

@article{Christofides2013,
  title    = {{Distributed model predictive control: A tutorial review and future research directions}},
  author   = {Christofides, Panagiotis D. and Scattolini, Riccardo and {Mu{\~{n}}oz de la Pe{\~{n}}a}, David and Liu, Jinfeng},
  journal  = {Computers and Chemical Engineering},
  year     = {2013},
  month    = {apr},
  pages    = {21--41},
  volume   = {51},
  abstract = {In this paper, we provide a tutorial review of recent results in the design of distributed model predictive control systems. Our goal is to not only conceptually review the results in this area but also to provide enough algorithmic details so that the advantages and disadvantages of the various approaches can become quite clear. In this sense, our hope is that this paper would complement a series of recent review papers and catalyze future research in this rapidly evolving area. We conclude discussing our viewpoint on future research directions in this area. {\textcopyright} 2012 Elsevier Ltd.},
  doi      = {10.1016/j.compchemeng.2012.05.011},
  file     = {::},
  issn     = {00981354}
}

@misc{ClassificationUse,
  title = {{Classification Accuracy is Not Enough: More Performance Measures You Can Use}},
  url   = {https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/}
}

@article{Clerc2005,
  title   = {{Library design using genetic algorithms for catalyst discovery and optimization}},
  author  = {Clerc, Frederic and Lengliz, Mourad and Farrusseng, David and Mirodatos, Claude and Pereira, Sílvia R. M. and Rakotomalala, Ricco},
  journal = {Review of Scientific Instruments},
  year    = {2005},
  month   = {6},
  number  = {6},
  pages   = {062208},
  volume  = {76},
  doi     = {10.1063/1.1906086},
  issn    = {0034-6748},
  url     = {http://aip.scitation.org/doi/10.1063/1.1906086}
}

@techreport{ConitzerAWESOME:,
  title  = {{AWESOME: A General Multiagent Learning Algorithm that Converges in Self-Play and Learns a Best Response Against Stationary Opponents *}},
  author = {Conitzer, Vincent and Sandholm, Tuomas}
}

@phdthesis{Conte2014,
  title     = {{Stability and Computations in Cooperative Distributed Model Predictive Control}},
  author    = {Conte, Christian},
  year      = {2014},
  abstract  = {The main theme of this thesis is the development of cooperative distributed model predictive control (MPC) methods for large-scale networks of constrained dynamic systems. MPC is a modern control methodology, which is particularly suited for constrained systems and has proven successful in practice. For large-scale networks of systems, which are often subject to communication constraints, MPC controllers have to be operated in a distributed way, i.e. each system in the network has to take local control decisions based on local measurements and communication with neighboring systems. Moreover, for networks of systems with a common objective function, it is desirable for the systems to take their control decisions cooperatively, which implies the need for cooperative distributed MPC. Distributed optimization is a well-established methodology which allows the combination of the cooperative and the distributed aspect within the MPC framework. Specifically, one finite-horizon optimal control problem, in the following referred to as MPC problem, can be formulated for the whole network of systems, and it can be solved by a distributed optimization method at each time step. This thesis is concerned with issues arising from the use of distributed optimization in MPC. In the first part of the thesis, distributed optimization based cooperative distributed MPC controllers for networks of linear systems are presented. All controllers guarantee stability and feasibility in closed-loop. The first controller presented is a nominal MPC controller. Closed-loop stability and feasibility are guaranteed by adapting well-established methodologies from the centralized MPC literature. Specifically, the global MPC problem is equipped with a suitably designed terminal cost, which is a Lyapunov function for the unconstrained system, and a terminal set, which is positively invariant (PI). In order to make the MPC problem amenable to distributed optimization algorithms, the terminal cost is designed as a separable function and the terminal set is a Cartesian product of local sets, which are time-varying. Specific synthesis methods for terminal cost and set are presented, where these methods can be executed in a distributed fashion themselves. In the following, two cooperative distributed MPC controller are presented, which extend the nominal one described above. The first is a robust MPC controller for networks of linear systems subject to bounded additive noise, the second is an MPC controller for reference tracking. In both cases, well established methodologies from the centralized MPC literature x Abstract ￼￼are adapted for the use in a cooperative distributed setup, where the MPC problem is solved by distributed optimization. For distributed robust MPC, the main additional ingredients are structured robust positive invariant (RPI) sets, as well as constraint tightening methods, which can be executed in a distributed way. For distributed reference tracking MPC, the main additional ingredient is an invariant set for tracking, again designed as a Cartesian product, and again equipped with a synthesis method that can be carried out in a distributed fashion. In the second part of the thesis, computational aspects of specific distributed optimization methods in MPC are investigated. In particular, the performance of these methods on the MPC problem, i.e. the number of iterations to convergence, is computationally analyzed under various system setups and operational modes. A first study contains computational results for general networks of linear systems, which are controlled by standard nominal cooperative distributed MPC controllers. In the computational scenarios considered, various system properties, such as the strength of the dynamic coupling between the systems or the network topology, are varied. The results show that the performance of distributed optimization is sensitive to changes in these properties. In particular, as a general qualitative observation, the performance decreases in cases where coordination among the systems in the network is crucial, which usually manifests in Lagrange multipliers of large magnitude. These observations could be confirmed in a wind farm application study. In particular, it is shown that the performance of the distributed optimization methods decreases in operational conditions where the power production has to be dynamically reallocated across the wind farm. This is the case for example when there is not enough wind to fulfill the farm-wide power production requirements.},
  booktitle = {Thesis},
  doi       = {10.3929/ETHZ-A-010194426},
  isbn      = {9783906031668},
  keywords  = {COMPUTER APPLICATIONS IN AUTOMATIC CONTROL (CONTRO,COMPUTERANWENDUNGEN/AUTOMATISCHE REGELUNG (REGELUN,DYNAMIC PROGRAMMING (OPERATIONS RESEARCH),DYNAMISCHE OPTIMIERUNG (OPERATIONS RESEARCH)},
  publisher = {ETH-Z{\"{u}}rich},
  url       = {https://control.ee.ethz.ch/index.cgi?page=publications{\&}action=details{\&}id=4809}
}

@inproceedings{Couceiro2015,
  title     = {{Towards a predictive model of an evolutionary swarm robotics algorithm}},
  author    = {Couceiro, Micael S. and Rocha, R. P. and Martins, Fernando M. L.},
  booktitle = {2015 IEEE Congress on Evolutionary Computation (CEC)},
  year      = {2015},
  month     = {5},
  pages     = {2090--2096},
  publisher = {IEEE},
  doi       = {10.1109/CEC.2015.7257142},
  isbn      = {978-1-4799-7492-4},
  url       = {http://ieeexplore.ieee.org/document/7257142/}
}

@misc{Coumans,
  title  = {{Bullet Real-Time Physics Simulation | Home of Bullet and PyBullet: physics simulation for games, visual effects, robotics and reinforcement learning.}},
  author = {Coumans, Erwin},
  url    = {https://pybullet.org/wordpress/}
}

@article{Crane2017,
  title   = {{The heat method for distance computation}},
  author  = {Crane, Keenan and Weischedel, Clarisse and Wardetzky, Max},
  journal = {Communications of the ACM},
  year    = {2017},
  month   = {10},
  number  = {11},
  pages   = {90--99},
  volume  = {60},
  doi     = {10.1145/3131280},
  issn    = {00010782},
  url     = {http://dl.acm.org/citation.cfm?doid=3154816.3131280}
}

@techreport{CS229Algorithm,
  title = {{CS229 Simplified SMO Algorithm}},
  url   = {http://research.microsoft.com/}
}

@article{Dai2017,
  title    = {{Distributed Stochastic MPC of Linear Systems with Additive Uncertainty and Coupled Probabilistic Constraints}},
  author   = {Dai, Li and Xia, Yuanqing and Gao, Yulong and Cannon, Mark},
  journal  = {IEEE Transactions on Automatic Control},
  year     = {2017},
  number   = {7},
  pages    = {3474--3481},
  volume   = {62},
  abstract = {This technical note develops a new form of distributed stochastic model predictive control (DSMPC) algorithm for a group of linear stochastic subsystems subject to additive uncertainty and coupled probabilistic constraints. We provide an appropriate way to design the DSMPC algorithm by extending a centralized SMPC (CSMPC) scheme. To achieve the satisfaction of coupled probabilistic constraints in a distributed manner, only one subsystem is permitted to optimize at each time step. In addition, by making explicit use of the probabilistic distribution of the uncertainties, probabilistic constraints are converted into a set of deterministic constraints for the predictions of nominal models. The distributed controller can achieve recursive feasibility and ensure closed-loop stability for any choice of update sequence. Numerical examples illustrate the efficacy of the algorithm.},
  doi      = {10.1109/TAC.2016.2612822},
  file     = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Xx, Xxxx - 2016 - Distributed Stochastic MPC of Linear Systems with Additive Uncertainty and Coupled Probabilistic Constraints.pdf:pdf},
  issn     = {00189286},
  keywords = {Distributed control,model predictive control (MPC),probabilistic constraints,stochastic systems},
  url      = {http://www.ieee.org/publications{\_}standards/publications/rights/index.html}
}

@misc{Dai2018,
  title     = {{Task Allocation Without Communication Based on Incomplete Information Game Theory for Multi-robot Systems}},
  author    = {Dai, Wei and Lu, Huimin and Xiao, Junhao and Zheng, Zhiqiang},
  month     = {2},
  year      = {2018},
  booktitle = {Journal of Intelligent and Robotic Systems: Theory and Applications},
  doi       = {10.1007/s10846-018-0783-y},
  issn      = {15730409},
  keywords  = {Incomplete information game, Soccer robots, Task allocation, Without communication},
  pages     = {1--16},
  publisher = {Springer Netherlands}
}

@misc{DataKaggle,
  title = {{Data Science for Good: Kiva Crowdfunding | Kaggle}},
  url   = {https://www.kaggle.com/kiva/data-science-for-good-kiva-crowdfunding}
}

@misc{DeepTut,
  title  = {{Unsupervised Feature Learning and Deep Learning Tutorial}},
  author = {{DeepTut}},
  url    = {http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/}
}

@article{DeSimone2015,
  title    = {{Influence of Aerodynamics on Quadrotor Dynamics}},
  author   = {DeSimone, Marco C. and Serena, Russo and Alessandro, Ruggiero},
  journal  = {Recent Researches in Mechanical and Transportation Systems Influence},
  year     = {2015},
  pages    = {111--118},
  doi      = {10.13140/RG.2.1.5099.3128},
  isbn     = {9781618043160},
  keywords = {Key-Words: UAV, PID Control, Quadcopter, Under-Actuated System},
  url      = {http://www.wseas.us/e-library/conferences/2015/Salerno/ICTA/ICTA-16.pdf}
}

@article{Diaconis1993ComparisonChains,
  title   = {{Comparison Theorems for Reversible Markov Chains}},
  author  = {Diaconis, Persi and Saloff-Coste, Laurent},
  journal = {The Annals of Applied Probability},
  year    = {1993},
  number  = {3},
  pages   = {696--730},
  volume  = {3},
  doi     = {10.1214/aoap/1177005359},
  issn    = {1050-5164},
  url     = {https://doi.org/10.1007/978-3-642-24106-2_23}
}

@article{Dias2000ASystem,
  title     = {{A Free Market Architecture for Distributed Control of a Multirobot System}},
  author    = {Dias, M. Bernardine and Stentz, Anthony},
  year      = {2000},
  month     = {1},
  doi       = {10.1184/R1/6550274.V1},
  keywords  = {Robotics},
  publisher = {Carnegie Mellon University}
}

@article{Dibangoye2014OptimallyAlgorithms,
  title    = {{Optimally solving Dec-POMDPs as continuous-state MDPs: Theory and algorithms}},
  author   = {Dibangoye, Jilles Steeve and Amato, Christopher and Buffet, Olivier and Charpillet, François},
  journal  = {Journal of Artificial Intelligence Research},
  year     = {2014},
  pages    = {443--497},
  volume   = {55},
  isbn     = {9781577356332},
  issn     = {0249-6399},
  keywords = {concurrent, dec-pomdp, decentralized, enhancement, lim-com, nondet-outcomes, partial-obs}
}

@inproceedings{Dibangoye2015ExploitingMDPs,
  title     = {{Exploiting separability in multiagent planning with continuous-state MDPs}},
  author    = {Dibangoye, Jilles S. and Amato, Christopher and Buffet, Olivier and Charpillet, François},
  booktitle = {IJCAI International Joint Conference on Artificial Intelligence},
  year      = {2015},
  pages     = {4254--4260},
  publisher = {International Joint Conferences on Artificial Intelligence},
  volume    = {2015-Janua},
  isbn      = {9781577357384},
  issn      = {10450823}
}

@techreport{DickensTheLearning,
  title  = {{The Dynamics of Multi-Agent Reinforcement Learning}},
  author = {Dickens, Luke and Broda, Krysia and Russo, Alessandra}
}

@misc{DJISpecs,
  title = {{DJI Tello Specs}},
  url   = {https://www.drone-world.com/dji-tello-specs}
}

@misc{DJISpecsb,
  title = {{DJI Tello Specs}},
  url   = {https://www.drone-world.com/dji-tello-specs}
}

@techreport{Djugash,
  title  = {{Neural Networks for Obstacle Avoidance}},
  author = {Djugash, Joseph and Hamner, Bradley}
}

@article{Dong2008QuantumLearning,
  title    = {{Quantum reinforcement learning}},
  author   = {Dong, Daoyi and Chen, Chunlin and Li, Hanxiong and Tarn, Txyh Jong},
  journal  = {IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics},
  year     = {2008},
  number   = {5},
  pages    = {1207--1220},
  volume   = {38},
  arxivid  = {0810.3828},
  doi      = {10.1109/TSMCB.2008.925743},
  issn     = {10834419},
  keywords = {Collapse, Grover iteration, Probability amplitude, Quantum reinforcement learning (QRL), State superposition}
}

@article{Dorigo2008SwarmExperiment,
  title   = {{Swarm intelligence and swarm robotics. The swarm-bot experiment}},
  author  = {Dorigo, M},
  journal = {ICINCO 2008 Proceedings of the Fifth International Conference on Informatics in Control Automation and Robotics},
  year    = {2008}
}

@inproceedings{Dosilovic2018ExplainableSurvey,
  title     = {{Explainable artificial intelligence: A survey}},
  author    = {Dosilovic, Filip Karlo and Brcic, Mario and Hlupic, Nikica},
  booktitle = {2018 41st International Convention on Information and Communication Technology, Electronics and Microelectronics, MIPRO 2018 - Proceedings},
  year      = {2018},
  month     = {6},
  pages     = {210--215},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  doi       = {10.23919/MIPRO.2018.8400040},
  isbn      = {9789532330977},
  keywords  = {comprehensibility, explainability, explainable artificial intelligence, interpretability}
}

@misc{DragCoefficient,
  title = {{Drag Coefficient}},
  url   = {https://www.engineeringtoolbox.com/drag-coefficient-d_627.html}
}

@misc{DragPhysics,
  title = {{Drag Forces – College Physics}},
  url   = {https://opentextbc.ca/physicstestbook2/chapter/drag-forces/}
}

@incollection{Du2014,
  title     = {{Recurrent Neural Networks}},
  author    = {Du, Ke-Lin and Swamy, M. N. S.},
  booktitle = {Neural Networks and Statistical Learning},
  publisher = {Springer London},
  year      = {2014},
  address   = {London},
  pages     = {337--353},
  doi       = {10.1007/978-1-4471-5571-3{\_}11},
  url       = {http://link.springer.com/10.1007/978-1-4471-5571-3_11}
}

@techreport{DucatelleSelf-organizedSwarms,
  title    = {{Self-organized Cooperation between Robotic Swarms}},
  author   = {Ducatelle, Frederick and Caro, Gianni A Di and Pinciroli, Carlo and Gambardella, uca},
  keywords = {Swarm robotics, ant foraging, heterogeneous robot swarms, multi-robot systems, robot navigation, self-organization, stigmergy, swarm intelligence},
  url      = {http://www.swarmanoid.org}
}

@article{Egerstedt2016SwarmingRobots,
  title   = {{Swarming robots}},
  author  = {Egerstedt, Magnus},
  journal = {Snapshot of Modern Mathematics},
  year    = {2016},
  number  = {1},
  pages   = {1--9},
  volume  = {1}
}

@inproceedings{Eker2011,
  title     = {{A finite horizon DEC-POMDP approach to multi-robot task learning}},
  author    = {Eker, Baris and Ozkucur, Ergin and Mericli, Cetin and Mericli, Tekin and Akin, H. Levent},
  booktitle = {2011 5th International Conference on Application of Information and Communication Technologies (AICT)},
  year      = {2011},
  month     = {10},
  pages     = {1--5},
  publisher = {IEEE},
  doi       = {10.1109/ICAICT.2011.6111001},
  isbn      = {978-1-61284-832-7},
  url       = {http://ieeexplore.ieee.org/document/6111001/}
}

@phdthesis{Elamvazhuthi2019,
  author = {Elamvazhuthi, Karthik and Berman, Spring and Kawski, Matthias and Kuiper, Hendrik and Mignolet, Marc and Peet, Matthew},
  file   = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Elamvazhuthi et al. - 2019 - Controllability and Stabilization of Kolmogorov Forward Equations for Robotic Swarms.pdf:pdf},
  title  = {{Controllability and Stabilization of Kolmogorov Forward Equations for Robotic Swarms}},
  year   = {2019}
}

@article{Elamvazhuthi2019b,
  abstract  = {We present a survey on the application of fluid approximations, in the form of mean-field models, to the design of control strategies in swarm robotics. Mean-field models that consist of ordinary differential equations, partial differential equations, and difference equations have been used in the swarm robotics literature, depending on whether the state of each agent and the time variable take values from a discrete or continuous set. These macroscopic models are independent of the number of agents in the swarm, and hence can be used to synthesize robot control strategies in a scalable manner, in contrast to individual-based microscopic models of swarms that represent finite numbers of discrete agents. Moreover, mean-field models are amenable to rigorous investigation using tools from dynamical systems theory, control theory, stochastic processes, and analysis of partial differential equations, enabling new insights and provable guarantees on the dynamics of collective behaviors. In this paper, we survey the applications of these models to problems in swarm robotics that include coverage, task allocation, self-assembly, consensus, and environmental mapping.},
  author    = {Elamvazhuthi, Karthik and Berman, Spring},
  doi       = {10.1088/1748-3190/ab49a4},
  issn      = {17483190},
  journal   = {Bioinspiration {\&} biomimetics},
  month     = {nov},
  number    = {1},
  pages     = {015001},
  publisher = {NLM (Medline)},
  title     = {{Mean-field models in swarm robotics: a survey}},
  volume    = {15},
  year      = {2019}
}

@techreport{Emery-Montemerlo,
  title  = {{Approximate Solutions For Partially Observable Stochastic Games with Common Payoffs}},
  author = {Emery-Montemerlo, Rosemary and Gordon, Geoff and Schneider, Jeff and Thrun, Sebastian}
}

@article{Env2018,
  title    = {{A Survey on Obstacles Avoidance Mobile Robot in Static Unknown Environment}},
  author   = {{Env}},
  journal  = {International Journal of Computer (IJC)},
  year     = {2018},
  number   = {1},
  pages    = {160--173},
  volume   = {28},
  issn     = {2307-4523},
  keywords = {Autonomous navigation., Mobile robot, Obstacle avoidance, Static environment}
}

@inproceedings{Eraqi2016,
  title     = {{Reactive collision avoidance using evolutionary neural networks}},
  author    = {Eraqi, Hesham M. and Eldin, Youssef Emad and Moustafa, Mohamed N.},
  booktitle = {IJCCI 2016 - Proceedings of the 8th International Joint Conference on Computational Intelligence},
  year      = {2016},
  pages     = {251--257},
  publisher = {SciTePress},
  volume    = {1},
  isbn      = {9789897582011},
  keywords  = {Collision avoidance, Evolutionary neural networks, Genetic algorithm, Lane keeping}
}

@article{Faisal2013,
  title    = {{Fuzzy logic navigation and obstacle avoidance by a mobile robot in an unknown dynamic environment}},
  author   = {Faisal, Mohammed and Hedjar, Ramdane and Al Sulaiman, Mansour and Al-Mutib, Khalid},
  journal  = {International Journal of Advanced Robotic Systems},
  year     = {2013},
  month    = {1},
  volume   = {10},
  doi      = {10.5772/54427},
  issn     = {17298806},
  keywords = {Fuzzy logic control, Navigation and obstacles, Wheeled mobile robot, Wireless communication}
}

@techreport{FaulknerActiveLearning,
  title    = {{Active Attention-Modified Policy Shaping Socially Interactive Agents Track Human-robot interaction; reinforcement learning; active learning}},
  author   = {Faulkner, Taylor Kessler and Gutierrez, Reymundo A and Short, Elaine Schaertl and Hoffman, Guy and Thomaz, Andrea L},
  keywords = {Human-robot interaction, active learning, reinforcement learning},
  url      = {www.ifaamas.org}
}

@techreport{Fiorini,
  title  = {{Motion Planning in Dynamic Environments using Velocity Obstacles}},
  author = {Fiorini, Paolo and Shiller, Zvi}
}

@techreport{Fletcher2008,
  title  = {{Support Vector Machines Explained}},
  author = {Fletcher, Tristan},
  year   = {2008},
  url    = {www.cs.ucl.ac.uk/staff/T.Fletcher/}
}

@article{Foerster,
  title         = {{Bayesian Action Decoder for Deep Multi-Agent Reinforcement Learning}},
  author        = {Foerster, Jakob N and Song, Francis and Hughes, Edward and Burch, Neil and Dunning, Iain and Whiteson, Shimon and Botvinick, Matthew and Bowling, Michael},
  year          = {2018},
  abstract      = {When observing the actions of others, humans make inferences about why they acted as they did, and what this implies about the world; humans also use the fact that their actions will be interpreted in this manner, allowing them to act informatively and thereby communicate efficiently with others. Although learning algorithms have recently achieved superhuman performance in a number of two-player, zero-sum games, scalable multi-agent reinforcement learning algorithms that can discover effective strategies and conventions in complex, partially observable settings have proven elusive. We present the Bayesian action decoder (BAD), a new multi-agent learning method that uses an approximate Bayesian update to obtain a public belief that conditions on the actions taken by all agents in the environment. BAD introduces a new Markov decision process, the public belief MDP, in which the action space consists of all deterministic partial policies, and exploits the fact that an agent acting only on this public belief state can still learn to use its private information if the action space is augmented to be over all partial policies mapping private information into environment actions. The Bayesian update is closely related to the theory of mind reasoning that humans carry out when observing others' actions. We first validate BAD on a proof-of-principle two-step matrix game, where it outperforms policy gradient methods; we then evaluate BAD on the challenging, cooperative partial-information card game Hanabi, where, in the two-player setting, it surpasses all previously published learning and hand-coded approaches, establishing a new state of the art.},
  archiveprefix = {arXiv},
  arxivid       = {1811.01458},
  eprint        = {1811.01458},
  file          = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Foerster et al. - Unknown - Bayesian Action Decoder for Deep Multi-Agent Reinforcement Learning.pdf:pdf},
  url           = {http://arxiv.org/abs/1811.01458}
}

@techreport{Foerster2018DeepLearning,
  title  = {{Deep Multi-Agent Reinforcement Learning}},
  author = {Foerster, Jakob N},
  year   = {2018}
}

@techreport{Foerster2018LearningAwareness,
  title    = {{Learning with Opponent-Learning Awareness}},
  author   = {Foerster, Jakob and Chen, Richard Y and Maruan Al-Shedivat, OpenAI and Whiteson, Shimon and Abbeel, Pieter and Mordatch OpenAI, Igor and Al-Shedivat, Maruan},
  year     = {2018},
  keywords = {deep reinforcement learning, game theory, multi-agent learning},
  url      = {www.ifaamas.org}
}

@techreport{Foerster2018LearningAwarenessb,
  title    = {{Learning with Opponent-Learning Awareness}},
  author   = {Foerster, Jakob and Chen, Richard Y and Maruan Al-Shedivat, OpenAI and Whiteson, Shimon and Abbeel, Pieter and Mordatch OpenAI, Igor and Al-Shedivat, Maruan},
  year     = {2018},
  keywords = {deep reinforcement learning, game theory, multi-agent learning},
  url      = {www.ifaamas.org}
}

@misc{Fridman2019,
  title     = {{Intro to Deep Reinforcement Learning}},
  author    = {Fridman, L},
  year      = {2019},
  publisher = {MIT Press}
}

@article{Frison2010Self-organizedPartitioning,
  title   = {{Self-organized Task Partitioning}},
  author  = {Frison, Marco and Tran, Nam-luc and Baiboun, Nadir and Brutschy, Arne and Pini, Giovanni and Roli, Andrea and Dorigo, Marco and Birattari, Mauro},
  journal = {Lecture Notes in Computer Science},
  year    = {2010},
  doi     = {10.1007/978-3-642-15461-4{\_}25}
}

@phdthesis{FUHRMANFrancescoRUSSO,
  title  = {{Probabilistic Representation of HJB Equations for Optimal Control of Jump Processes , BSDEs and Related Stochastic Calculus}},
  author = {Milano, Politecnico},
  year   = {2016},
  file   = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/FUHRMAN Francesco RUSSO, LUCCHETTI Fr{\'{e}}d{\'{e}}ric PAULIN - Unknown - Politecnico di Milano Probabilistic Representation of HJB Equations for.pdf:pdf}
}

@techreport{Fung,
  title    = {{A Feature Selection Newton Method for Support Vector Machine Classification}},
  author   = {Fung, Glenn and Mangasarian, O L},
  keywords = {Newton, classification, feature selection, lin-ear programming},
  url      = {https://pdfs.semanticscholar.org/6687/4b845c72834a11c63cfa62714bf2d0b4c663.pdf?fbclid=IwAR3yNRMBSDjyMp9qfrJDhtw659th4qKDfBqE1ir2Z9kcqCb4s2XzOoD4ydE}
}

@article{Gabbard2019ARResearch,
  title   = {{AR DriveSim: An Immersive Driving Simulator for Augmented Reality Head-Up Display Research}},
  author  = {Gabbard, Joseph L. and Smith, Missie and Tanous, Kyle and Kim, Hyungil and Jonas, Bryan},
  journal = {Frontiers in Robotics and AI},
  year    = {2019},
  month   = {10},
  volume  = {6},
  doi     = {10.3389/frobt.2019.00098},
  issn    = {2296-9144},
  url     = {https://www.frontiersin.org/article/10.3389/frobt.2019.00098/full}
}

@inproceedings{Gao2018,
  title     = {{An improved hybrid group intelligent algorithm based on artificial bee colony and particle swarm optimization}},
  author    = {Gao, Yuxi},
  booktitle = {Proceedings - 2018 International Conference on Virtual Reality and Intelligent Systems, ICVRIS 2018},
  year      = {2018},
  month     = {11},
  pages     = {160--163},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  doi       = {10.1109/ICVRIS.2018.00046},
  isbn      = {9781538680315},
  keywords  = {Artificial Bee Colony, Hybrid algorithm, Particle Swarm Optimization, Swarm Intelligence}
}

@incollection{Garapati2018AMissions,
  title     = {{A game of drones: Game theoretic approaches for multi-robot task allocation in security missions}},
  author    = {Garapati, Kala and Rold{\'{a}}n, Juan Jesús and Garz{\'{o}}n, Mario and del Cerro, Jaime and Barrientos, Antonio},
  booktitle = {Advances in Intelligent Systems and Computing},
  publisher = {Springer Verlag},
  year      = {2018},
  pages     = {855--866},
  volume    = {693},
  doi       = {10.1007/978-3-319-70833-1{\_}69},
  issn      = {21945357},
  keywords  = {Game theory, Multi-robot mission, Security, Swarm, Task allocation}
}

@misc{GAVIN,
  title  = {{LIDAR-Lite 3 Laser Rangefinder - RobotShop}},
  author = {{GAVIN}},
  url    = {https://www.robotshop.com/uk/lidar-lite-3-laser-rangefinder.html}
}

@inproceedings{Gavran2017Antlab:Server,
  title     = {{Antlab: A multi-robot task server}},
  author    = {Gavran, Ivan and Majumdar, Rupak and Saha, Indranil},
  booktitle = {ACM Transactions on Embedded Computing Systems},
  year      = {2017},
  doi       = {10.1145/3126513},
  issn      = {15583465},
  keywords  = {Cyber-physical systems, Multi-robot systems, Planning, Programming abstractions for robotics}
}

@article{Gerkey2002Sold:Coordination,
  title    = {{Sold!: Auction methods for multirobot coordination}},
  author   = {Gerkey, Brian P. and Matari{\'{c}}, Maja J.},
  journal  = {IEEE Transactions on Robotics and Automation},
  year     = {2002},
  month    = {10},
  number   = {5},
  pages    = {758--768},
  volume   = {18},
  doi      = {10.1109/TRA.2002.803462},
  issn     = {1042296X},
  keywords = {Auctions, Contract nets, Coordination, Multirobot systems, Task allocation}
}

@misc{GetKingdom,
  title = {{Get Started with ROS - MATLAB {\&}amp; Simulink - MathWorks United Kingdom}},
  url   = {https://uk.mathworks.com/help/robotics/examples/get-started-with-ros.html#d120e104}
}

@techreport{Gibiansky,
  title  = {{Quadcopter Dynamics, Simulation, and Control}},
  author = {Gibiansky, Andrew}
}

@techreport{Gilonis2014,
  title  = {{Aeronautics {\&} Astronautics Third Year Individual Project IP Number: 960 IP Title: Low-complexity controller design for an unmanned helicopter}},
  author = {Gilonis, Samuel and Shu, Zhan},
  year   = {2014}
}

@article{Giulioni2015,
  title  = {{Stochastic Model Predictive Control with Application to Distributed Control Systems}},
  author = {Giulioni, Luca},
  year   = {2015},
  pages  = {1--208},
  file   = {:Users/aamalh/Downloads/thesis (1).pdf:pdf}
}

@misc{GPS.gov:Accuracy,
  title = {{GPS.gov: GPS Accuracy}},
  url   = {https://www.gps.gov/systems/gps/performance/accuracy/}
}

@misc{GPS.gov:Accuracyb,
  title = {{GPS.gov: GPS Accuracy}},
  url   = {https://www.gps.gov/systems/gps/performance/accuracy/}
}

@misc{GPS.gov:Accuracyc,
  title = {{GPS.gov: GPS Accuracy}},
  url   = {https://www.gps.gov/systems/gps/performance/accuracy/}
}

@inproceedings{Guha2018Multi-playerGames,
  title     = {{Multi-player flow games}},
  author    = {Guha, Shibashis and Kupferman, Orna and Vardi, Gal},
  booktitle = {Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS},
  year      = {2018},
  pages     = {104--112},
  volume    = {1},
  doi       = {10.1007/s10458-019-09420-2},
  isbn      = {9781510868083},
  issn      = {15582914},
  keywords  = {Game Theory for practical applications, Methodologies for agent-based systems, Noncoopera tive games: Theory {\&} analysis, Noncooperative games computation},
  url       = {www.ifaamas.org}
}

@inproceedings{Gunn2013,
  title     = {{Effective task allocation for evolving multi-robot teams in dangerous environments}},
  author    = {Gunn, Tyler and Anderson, John},
  booktitle = {Proceedings - 2013 IEEE/WIC/ACM International Conference on Intelligent Agent Technology, IAT 2013},
  year      = {2013},
  pages     = {231--238},
  publisher = {IEEE Computer Society},
  volume    = {2},
  doi       = {10.1109/WI-IAT.2013.114},
  isbn      = {9781479929023},
  keywords  = {Heterogeneity, Multi-robot systems, Roles, Task allocation, Team management, USAR}
}

@misc{Gym,
  title  = {{OpenAI Gym}},
  author = {{Gym}},
  url    = {https://gym.openai.com/envs/CartPole-v0/}
}

@article{H.Sawalmeh2018,
  title     = {{An Overview of Collision Avoidance Approaches and Network Architecture of Unmanned Aerial Vehicles (UAVs)}},
  author    = {H. Sawalmeh, Ahmad and Shamsiah Othman, Noor},
  journal   = {International Journal of Engineering {\&} Technology},
  year      = {2018},
  month     = {11},
  number    = {4.35},
  pages     = {924},
  volume    = {7},
  doi       = {10.14419/ijet.v7i4.35.27395},
  publisher = {Science Publishing Corporation}
}

@book{Hamalainen1991DifferentialFinland,
  title     = {{Differential games : developments in modelling and computation : proceedings of the Fourth International Symposium on Differential Games and Applications, August 9-10, 1990, Helsinki University of Technology, Finland}},
  author    = {Hamalainen, Raimo P. and Ehtamo, H. K. (Harri Kalevi)},
  publisher = {Springer-Verlag},
  year      = {1991},
  isbn      = {3540537872},
  pages     = {292}
}

@phdthesis{Hamann2008,
  abstract = {In this book, a genericmodel in as far as possiblemathematical closed-formis developed that predicts the behavior of large self-organizing robot groups (robot swarms) based on their control algorithm. In addition, an extensive subsumption of the relatively young and distinctive interdisciplinary research field of swarm robotics is emphasized. The connection to many related fields is highlighted and the concepts and methods borrowed from these fields are described shortly.},
  author   = {Hamann, Heiko},
  file     = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Hamann - 2008 - Space-Time Continuous Models of Swarm Robotic Systems Supporting Global-to-Local Programming.pdf:pdf},
  title    = {{Space-Time Continuous Models of Swarm Robotics Systems: Supporting Global-to-Local Programming}},
  url      = {http://heikohamann.de/pub/hamannPhDThesis.pdf},
  year     = {2008}
}

@inproceedings{Harutyunyan2018LearningOff-policy,
  title     = {{Learning with options that terminate off-policy}},
  author    = {Harutyunyan, Anna and Vrancx, Peter and Bacon, Pierre Luc and Precup, Doina and Now{\'{e}}, Ann},
  booktitle = {32nd AAAI Conference on Artificial Intelligence, AAAI 2018},
  year      = {2018},
  pages     = {3173--3182},
  arxivid   = {1711.03817},
  isbn      = {9781577358008},
  keywords  = {Hierarchical Reinforcement Learning, Multi-agent Learning},
  url       = {www.ifaamas.org}
}

@inproceedings{He2008,
  title     = {{A fuzzy neural network based on T-S model for mobile robots to avoid obstacles}},
  author    = {He, Kunpeng and Gao, Yanbin and Sun, Hua},
  booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year      = {2008},
  number    = {PART 1},
  pages     = {1127--1134},
  volume    = {5314 LNAI},
  doi       = {10.1007/978-3-540-88513-9-120},
  isbn      = {3540885129},
  issn      = {03029743},
  keywords  = {Avoiding obstacles, Fuzzy neural network, Mobile robot, Multi-sensor}
}

@article{Heirung2019,
  title     = {{Model predictive control with active learning for stochastic systems with structural model uncertainty: Online model discrimination}},
  author    = {Heirung, Tor Aksel N. and Santos, Tito L.M. and Mesbah, Ali},
  journal   = {Computers and Chemical Engineering},
  year      = {2019},
  month     = {sep},
  pages     = {128--140},
  volume    = {128},
  abstract  = {Structural model uncertainty is prevalent in control design and arises from incomplete knowledge of the system or the existence of different modes of dynamic behavior, such as those arising from system faults and malfunctions. This paper addresses control of stochastic nonlinear systems using model predictive control, or MPC, under structural model uncertainty. Inspired by dual control, the MPC strategy with active learning presented here can probe the uncertain system to select, among a set of candidates, the model that best describes the observed closed-loop system data. The proposed controller involves online model selection based on estimation of the model-hypothesis probabilities and minimization of a computationally tractable measure of the predicted Bayes risk of selection error. The performance of the proposed approach is compared to that of nominal MPC with no learning, MPC with passive learning, and a robust MPC approach that systematically accounts for structural model uncertainty but has no learning mechanism. Simulation results on a nonlinear bioreactor demonstrate that active learning can have significant advantages in maintaining adequate control performance in the presence of structural uncertainty. Active learning can be particularly beneficial for improving online model discrimination and active fault diagnosis under closed-loop control.},
  doi       = {10.1016/j.compchemeng.2019.05.012},
  file      = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Heirung, Santos, Mesbah - 2019 - Model predictive control with active learning for stochastic systems with structural model uncertain(2).pdf:pdf},
  issn      = {00981354},
  keywords  = {Bayesian decision theory,Closed-loop fault diagnosis,Dual control,Online model discrimination,Predictive control,Stochastic systems,Structural model uncertainty},
  publisher = {Elsevier Ltd}
}

@techreport{HenriquesMapNet:Environments,
  title  = {{MapNet: An Allocentric Spatial Memory for Mapping Environments}},
  author = {Henriques, João F and Vedaldi, Andrea}
}

@techreport{Hernandez-LealA,
  title   = {{A Survey and Critique of Multiagent Deep Reinforcement Learning {\$}}},
  author  = {Hernandez-Leal, Pablo and Kartal, Bilal and Taylor, Matthew E},
  arxivid = {1810.05587v3},
  isbn    = {1810.05587v3}
}

@incollection{HilmiIsmail2019,
  title     = {{A Survey and Analysis of Cooperative Multi-Agent Robot Systems: Challenges and Directions}},
  author    = {Hilmi Ismail, Zool and Sariff, Nohaidda},
  booktitle = {Applications of Mobile Robots [Working Title]},
  publisher = {IntechOpen},
  year      = {2019},
  month     = {2},
  doi       = {10.5772/intechopen.79337}
}

@techreport{Hong2018ASystems,
  title    = {{A Deep Policy Inference Q-Network for Multi-Agent Systems}},
  author   = {Hong, Zhang-Wei and Su, Shih-Yang and Shann, Tzu-Yun and Chang, Yi-Hsiang and Lee, Chun-Yi},
  year     = {2018},
  keywords = {Deep Reinforcement Learning, Multi-agent Learning, Opponent Modeling},
  url      = {www.ifaamas.org}
}

@inproceedings{Honig2018ScalableEnvironments,
  title     = {{Scalable task and motion planning for multi-robot systems in obstacle-rich environments}},
  author    = {H{\"{o}}nig, Wolfgang},
  booktitle = {Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS},
  year      = {2018},
  pages     = {1746--1748},
  volume    = {3},
  isbn      = {9781510868083},
  issn      = {15582914},
  url       = {www.ifaamas.org}
}

@article{Hu2019QNetworks,
  title     = {{Q Learning with Quantum Neural Networks}},
  author    = {Hu, Wei and Hu, James},
  journal   = {Natural Science},
  year      = {2019},
  number    = {01},
  pages     = {31--39},
  volume    = {11},
  doi       = {10.4236/ns.2019.111005},
  issn      = {2150-4091},
  publisher = {Scientific Research Publishing, Inc,}
}

@inproceedings{Huang2005,
  title     = {{Reinforcement learning neural network to the problem of autonomous mobile robot obstacle avoidance}},
  author    = {Huang, Bing Qiang and Cao, Guang Yi and Guo, Min},
  booktitle = {2005 International Conference on Machine Learning and Cybernetics, ICMLC 2005},
  year      = {2005},
  pages     = {85--89},
  isbn      = {078039092X},
  keywords  = {Obstacle avoidance, Reinforcement learning, Reinforcement learning neural network}
}

@book{IanGoodfellowandYoshuaBengioandAaronCourville2016,
  title     = {{Deep Learning}},
  author    = {{Ian Goodfellow and Yoshua Bengio and Aaron Courville}},
  publisher = {MIT Press},
  year      = {2016},
  url       = {http://www.deeplearningbook.org}
}

@techreport{Inc,
  title    = {{Parallax Continuous Rotation Servo ({\#}900-00008)}},
  author   = {Inc, Parallax},
  keywords = {BASIC Stamp, Propeller P8X32A, animatronics, bidirectional rotation, full rotation, motor, robot drive, robot motor, servomotor, wheeled robot},
  url      = {https://www.parallax.com/sites/default/files/downloads/900-00008-Continuous-Rotation-Servo-Documentation-v2.2.pdf}
}

@inproceedings{Inoue2019,
  title     = {{Stochastic self-organizing control for swarm robot systems}},
  author    = {Inoue, Daisuke and Murai, Daisuke and Yoshida, Hiroaki},
  booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year      = {2019},
  pages     = {405--416},
  publisher = {Springer Verlag},
  volume    = {11655 LNCS},
  abstract  = {In swarm robot systems, forming a target shape with autonomously moving robots is an important task. Considering cost and scalability, it is desirable that the observation information required by the robots to form patterns be minimal, whereas the patterns themselves can be as complicated as needed. In this paper, we propose a method of achieving this task under the situation that a scalar value representing a clue to its position is the only information that each robot can observe. We adopted the optimization method proposed by Mesquita et al. [International workshop on hybrid systems: Computation and control, pp. 358 (2008)] as a control method for the swarm robot systems. This method requires neither centralized controllers nor position identification of each robot, and we thus refer to it as “self-organizing control.” Compared with existing control methods, the proposed method reduces memory usage and computational complexity. By means of both numerical simulations and experiments with actual robots, we quantitatively confirmed that self-organization was achieved.},
  doi       = {10.1007/978-3-030-26369-0_38},
  isbn      = {9783030263683},
  issn      = {16113349},
  keywords  = {Multi-agent systems,Self-organization,Swarm robotics}
}

@inproceedings{Jakubuv2015UsingPlanning,
  title     = {{Using process calculi for plan verification in multiagent planning}},
  author    = {Jakubův, Jan and To{\v{z}}i{\v{c}}ka, Jan and Komenda, Antonín},
  booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year      = {2015},
  volume    = {9494},
  doi       = {10.1007/978-3-319-27947-3{\_}13},
  isbn      = {9783319279466},
  issn      = {16113349}
}

@techreport{Jeurgens2017,
  title  = {{Identification and Control Implementation of an AR.Drone 2.0}},
  author = {Jeurgens, N L M},
  year   = {2017}
}

@article{Jiang2019Multi-robotSynergies,
  title    = {{Multi-robot planning with conflicts and synergies}},
  author   = {Jiang, Yuqian and Yedidsion, Harel and Zhang, Shiqi and Sharon, Guni and Stone, Peter},
  journal  = {Autonomous Robots},
  year     = {2019},
  pages    = {2011--2032},
  volume   = {43},
  doi      = {10.1007/s10514-019-09848-1},
  isbn     = {43:20112032},
  keywords = {Intelligent mobile robotics, Multi-robot planning, Planning under temporal uncertainty},
  url      = {https://doi.org/10.1007/s10514-019-09848-1}
}

@article{Jin2018Stability-certifiedPerspective,
  title    = {{Stability-certified reinforcement learning: A control-theoretic perspective}},
  author   = {Jin, Ming and Lavaei, Javad},
  year     = {2018},
  arxivid  = {1810.11505},
  isbn     = {1810.11505v1},
  keywords = {93D09, 93E35, Reinforcement learning, decentralized control synthesis, policy gradient optimization, robust control, safe reinforcement learning AMS subject classifica},
  url      = {http://arxiv.org/abs/1810.11505}
}

@inproceedings{Jin2019Control-TheoreticLearning,
  title     = {{Control-Theoretic Analysis of Smoothness for Stability-Certified Reinforcement Learning}},
  author    = {Jin, Ming and Lavaei, Javad},
  booktitle = {Proceedings of the IEEE Conference on Decision and Control},
  year      = {2019},
  month     = {1},
  pages     = {6840--6847},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  volume    = {2018-December},
  doi       = {10.1109/CDC.2018.8618996},
  isbn      = {9781538613955},
  issn      = {07431546}
}

@inproceedings{Jung2001DistributedArgumentation,
  title     = {{Distributed constraint satisfaction as a computational model of negotiation via argumentation}},
  author    = {Jung, Hyuckchul},
  booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year      = {2001},
  pages     = {767},
  publisher = {Springer Verlag},
  volume    = {2239},
  doi       = {10.1007/3-540-45578-7{\_}68},
  isbn      = {3540428631},
  issn      = {16113349}
}

@article{Katt2018BayesianPOMDPs,
  title    = {{Bayesian Reinforcement Learning in Factored POMDPs}},
  author   = {Katt, Sammie and Oliehoek, Frans and Amato, Christopher},
  journal  = {IFAAMAS},
  year     = {2018},
  volume   = {9},
  arxivid  = {1811.05612},
  keywords = {Bayes Networks, Bayesian reinforcement learning, Monte-Carlo Tree Search, Monte-Chain Monte-Carlo, POMDPs},
  url      = {www.ifaamas.org http://arxiv.org/abs/1811.05612}
}

@techreport{Khatib,
  title  = {{Real-Time Obstacle Avoidance for Manipulators and Mobile Robots}},
  author = {Khatib, Oussama},
  url    = {https://journals.sagepub.com/doi/pdf/10.1177/027836498600500106}
}

@article{Kim2015,
  title   = {{Deep Neural Network for Real-Time Autonomous Indoor Navigation}},
  author  = {Kim, Dong Ki and Chen, Tsuhan},
  year    = {2015},
  month   = {11},
  arxivid = {1511.04668},
  url     = {http://arxiv.org/abs/1511.04668}
}

@inproceedings{Kim2016,
  title     = {{Smooth Path Planning by Fusion of Artificial Potential Field Method and Collision Cone Approach}},
  author    = {Kim, Yong Hwi and Son, Wan Sic and Park, Jin Bae and Yoon, Tae Sung},
  booktitle = {MATEC Web of Conferences},
  year      = {2016},
  month     = {9},
  publisher = {EDP Sciences},
  volume    = {75},
  doi       = {10.1051/matecconf/20167505004},
  issn      = {2261236X}
}

@techreport{Klima2019RobustDomains,
  title     = {{Robust Temporal Difference Learning for Critical Domains}},
  author    = {Klima, Richard and Bloembergen, Daan and Kaisers, Michael and Tuyls, Karl},
  year      = {2019},
  booktitle = {IFAAMAS},
  keywords  = {multi-agent learning, reinforcement learning, robust learning},
  url       = {www.ifaamas.org},
  volume    = {9}
}


@misc{Bloembergen2015,
abstract = {The interaction of multiple autonomous agents gives rise to highly dynamic and nondeterministic environments, contributing to the complexity in applications such as automated financial markets, smart grids, or robotics. Due to the sheer number of situations that may arise, it is not possible to foresee and program the optimal behaviour for all agents beforehand. Consequently, it becomes essential for the success of the system that the agents can learn their optimal behaviour and adapt to new situations or circumstances. The past two decades have seen the emergence of reinforcement learning, both in single and multiagent settings, as a strong, robust and adaptive learning paradigm. Progress has been substantial, and a wide range of algorithms are now available. An important challenge in the domain of multi-agent learning is to gain qualitative insights into the resulting system dynamics. In the past decade, tools and methods from evolutionary game theory have been successfully employed to study multi-agent learning dynamics formally in strategic interactions. This article surveys the dynamical models that have been derived for various multi-agent reinforcement learning algorithms, making it possible to study and compare them qualitatively. Furthermore, new learning algorithms that have been introduced using these evolutionary game theoretic tools are reviewed. The evolutionary models can be used to study complex strategic interactions. Examples of such analysis are given for the domains of automated trading in stock markets and collision avoidance in multi-robot systems. The paper provides a roadmap on the progress that has been achieved in analysing the evolutionary dynamics of multi-agent learning by highlighting the main results and accomplishments.},
author = {Bloembergen, Daan and Tuyls, Karl and Hennes, Daniel and Kaisers, Michael},
booktitle = {Journal of Artificial Intelligence Research},
doi = {10.1613/jair.4818},
file = {:home/aamalh/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bloembergen et al. - 2015 - Evolutionary dynamics of multi-agent learning A survey.pdf:pdf},
issn = {10769757},
mendeley-groups = {STAI/Literature Review/MARL},
month = {aug},
pages = {659--697},
publisher = {AI Access Foundation},
title = {{Evolutionary dynamics of multi-agent learning: A survey}},
volume = {53},
year = {2015}
}


@article{Imhof2005,
abstract = {The main obstacle for the evolution of cooperation is that natural selection favors defection in most settings. In the repeated prisoner's dilemma, two individuals interact several times, and, in each round, they have a choice between cooperation and defection. We analyze the evolutionary dynamics of three simple strategies for the repeated prisoner's dilemma: always defect (ALLD), always cooperate (ALLC), and tit-for-tat (TFT). We study mutation-selection dynamics in finite populations. Despite ALLD being the only strict Nash equilibrium, we observe evolutionary oscillations among all three strategies. The population cycles from ALLD to TFT to ALLC and back to ALLD. Most surprisingly, the time average of these oscillations can be entirely concentrated on TFT. In contrast to the classical expectation, which is informed by deterministic evolutionary game theory of infinitely large populations, stochastic evolution of finite populations need not choose the strict Nash equilibrium and can therefore favor cooperation over defection. {\textcopyright} 2005 by The National Academy of Sciences of the USA.},
author = {Imhof, Lorens A. and Fudenberg, Drew and Nowak, Martin A.},
doi = {10.1073/pnas.0502589102},
file = {:home/aamalh/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Imhof, Fudenberg, Nowak - 2005 - Evolutionary cycles of cooperation and defection.pdf:pdf},
issn = {00278424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Evolutionary dynamics,Finite population,Prisoner's dilemma,Reciprocity stochastic process},
mendeley-groups = {STAI/Literature Review/MARL},
month = {aug},
number = {31},
pages = {10797--10800},
title = {{Evolutionary cycles of cooperation and defection}},
volume = {102},
year = {2005}
}


@techreport{Hu2019,
abstract = {Modelling the dynamics of multi-agent learning has long been an important research topic, but all of the previous works focus on 2-agent settings and mostly use evolutionary game theoretic approaches. In this paper, we study an n-agent setting with n tends to infinity, such that agents learn their policies concurrently over repeated symmetric bimatrix games with some other agents. Using the mean field theory, we approximate the effects of other agents on a single agent by an averaged effect. A Fokker-Planck equation that describes the evolution of the probability distribution of Q-values in the agent population is derived. To the best of our knowledge, this is the first time to show the Q-learning dynamics under an n-agent setting can be described by a system of only three equations. We validate our model through comparisons with agent-based simulations on typical symmetric bimatrix games and different initial settings of Q-values.},
author = {Hu, Shuyue and Leung, Chin-Wing and Leung, Ho-Fung},
file = {:home/aamalh/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hu, Leung, Leung - Unknown - Modelling the Dynamics of Multiagent Q-Learning in Repeated Symmetric Games a Mean Field Theoretic Approach.pdf:pdf},
mendeley-groups = {STAI/Literature Review/MARL},
title = {{Modelling the Dynamics of Multiagent Q-Learning in Repeated Symmetric Games: a Mean Field Theoretic Approach}}
}


@techreport{Konak,
  title  = {{Multi-Objective Optimization Using Genetic Algorithms: A Tutorial}},
  author = {Konak, Abdullah and Coit, David W and Smith, Alice E},
  url    = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.83.9986&rep=rep1&type=pdf}
}

@techreport{Korein2018Multi-ArmedRobot,
  title    = {{Multi-Armed Bandit Algorithms for Spare Time Planning of a Mobile Service Robot}},
  author   = {Korein, Max and Veloso, Manuela},
  year     = {2018},
  keywords = {Machine learning for robotics, Robot autonomy, Robot planning and plan execution},
  url      = {www.ifaamas.org}
}

@techreport{Koren1991,
  title  = {{Potential Field Methods and Their Inherent Limitations for Mobile Robot Navigation}},
  author = {Koren, Yoram and Borenstein, Johann},
  year   = {1991},
  url    = {https://pdfs.semanticscholar.org/0a52/3bebee3652d2d293c215be24ad643274a319.pdf}
}

@inproceedings{Kouris2018,
  title     = {{Learning to Fly by MySelf: A Self-Supervised CNN-Based Approach for Autonomous Navigation}},
  author    = {Kouris, Alexandros and Bouganis, Christos-Savvas},
  booktitle = {2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year      = {2018},
  month     = {10},
  pages     = {1--9},
  publisher = {IEEE},
  doi       = {10.1109/IROS.2018.8594204},
  isbn      = {978-1-5386-8094-0},
  url       = {https://ieeexplore.ieee.org/document/8594204/}
}

@techreport{Kouvaros2019FormalSystems,
  title     = {{Formal Verification of Open Multi-Agent Systems}},
  author    = {Kouvaros, Panagiotis and Lomuscio, Alessio and Pirovano, Edoardo and Punchihewa, Hashan},
  year      = {2019},
  booktitle = {IFAAMAS},
  url       = {www.ifaamas.org},
  volume    = {9}
}

@inproceedings{Kraemer2013ConcurrentUncertainty,
  title     = {{Concurrent reinforcement learning as a rehearsal for decentralized planning under uncertainty}},
  author    = {Kraemer, Landon and Banerjee, Bikramjit},
  booktitle = {12th International Conference on Autonomous Agents and Multiagent Systems 2013, AAMAS 2013},
  year      = {2013},
  pages     = {1291--1292},
  publisher = {International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS)},
  volume    = {2},
  keywords  = {Decentralized partially observable Markov decision processes, Multi-agent reinforcement learning}
}

@article{Kuantama2017,
  title   = {{PID and Fuzzy-PID Control Model for Quadcopter Attitude with Disturbance Parameter}},
  author  = {Kuantama, Endrowednes and Vesselenyi, Tiberiu and Dzitac, Simona and Tarca, Radu},
  journal = {International Journal of Computers Communications {\&} Control},
  year    = {2017},
  month   = {6},
  number  = {4},
  pages   = {519},
  volume  = {12},
  doi     = {10.15837/ijccc.2017.4.2962},
  issn    = {1841-9836},
  url     = {http://www.univagora.ro/jour/index.php/ijccc/article/view/2962}
}

@techreport{KumarMohanty2012,
  title     = {{Path Generation and Obstacle Avoidance of an Autonomous Mobile Robot Using Intelligent Hybrid Controller}},
  author    = {Kumar Mohanty, Prases and Parhi, Dayal R},
  year      = {2012},
  booktitle = {LNCS},
  keywords  = {ANFIS, Mobile robot, navigation},
  pages     = {240--247},
  volume    = {7677}
}

@article{Lansdell2019,
  title   = {{Learning to solve the credit assignment problem}},
  author  = {Lansdell, Benjamin James and Prakash, Prashanth Ravi and Kording, Konrad Paul},
  year    = {2019},
  month   = {6},
  arxivid = {1906.00889},
  url     = {http://arxiv.org/abs/1906.00889}
}

@article{LAOUICI2014,
  title     = {{Hybrid Method for the Navigation of Mobile Robot Using Fuzzy Logic and Spiking Neural Networks}},
  author    = {LAOUICI, Zineb and MAMI, Mohammed Amine and KHELFI, Mohamed Fayçal},
  journal   = {International Journal of Intelligent Systems and Applications},
  year      = {2014},
  month     = {11},
  number    = {12},
  pages     = {1--9},
  volume    = {6},
  doi       = {10.5815/ijisa.2014.12.01},
  issn      = {2074904X},
  publisher = {MECS Publisher}
}

@techreport{Le2011,
  title       = {{On Optimization Methods for Deep Learning}},
  author      = {Le, Quoc V. and Ngiam, Jiquan and Coates, Adam and Lahiri, Abhik and Prochnow, Bobby and Ng, Andrew Y.},
  institution = {Stanford University},
  year        = {2011}
}


@misc{Lecun2015,
  title     = {{Deep learning}},
  author    = {Lecun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  month     = {5},
  year      = {2015},
  booktitle = {Nature},
  doi       = {10.1038/nature14539},
  issn      = {14764687},
  number    = {7553},
  pages     = {436--444},
  publisher = {Nature Publishing Group},
  volume    = {521}
}

@misc{LeCunn,
  title  = {{MNIST handwritten digit database, Yann LeCun, Corinna Cortes and Chris Burges}},
  author = {{LeCunn}},
  url    = {http://yann.lecun.com/exdb/mnist/}
}

@article{Lee2019A2017,
  title     = {{A mission management system for complex aerial logistics by multiple unmanned aerial vehicles in MBZIRC 2017}},
  author    = {Lee, Jaehyun and Shim, David Hyunchul and Cho, Sungwook and Shin, Heemin and Jung, Sunggoo and Lee, Dasol and Kang, Jaemin},
  journal   = {Journal of Field Robotics},
  year      = {2019},
  month     = {8},
  number    = {5},
  pages     = {919--939},
  volume    = {36},
  doi       = {10.1002/rob.21860},
  issn      = {15564967},
  keywords  = {MBZIRC, aerial robotics, cooperative robots, multiple UAVs},
  publisher = {John Wiley and Sons Inc.}
}

@article{Lei2018,
  title   = {{Dynamic Path Planning of Unknown Environment Based on Deep Reinforcement Learning}},
  author  = {Lei, Xiaoyun and Zhang, Zhian and Dong, Peifang},
  journal = {Journal of Robotics},
  year    = {2018},
  month   = {9},
  pages   = {1--10},
  volume  = {2018},
  doi     = {10.1155/2018/5781591},
  issn    = {1687-9600},
  url     = {https://www.hindawi.com/journals/jr/2018/5781591/}
}

@techreport{Leibo2017Multi-agentDilemmas,
  title    = {{Multi-agent Reinforcement Learning in Sequential Social Dilemmas}},
  author   = {Leibo, Joel Z and Zambaldi, Vinicius and Lanctot, Marc and Marecki, Janusz and Graepel, Thore},
  year     = {2017},
  keywords = {Agent / discrete models, CCS Concepts •Computing methodologies → Multi-agent reinforce-ment learning, Keywords Social dilemmas, cooperation, Markov games, agent-based social simulation, non-cooperative games, Stochastic games},
  url      = {www.ifaamas.org}
}

@article{Leibo2018MalthusianLearning,
  title    = {{Malthusian Reinforcement Learning}},
  author   = {Leibo, Joel Z and Perolat, Julien and Hughes, Edward and Wheelwright, Steven and Marblestone, Adam H and Du{\'{e}}{\~{n}}ez-Guzm{\'{a}}n, Edgar and Sunehag, Peter and Dunning, Iain and Graepel, Thore},
  journal  = {IFAAMAS},
  year     = {2018},
  volume   = {9},
  arxivid  = {1812.07019},
  keywords = {Adaptive radiation, Artificial general intelligence, Demography, Evolution, Intrinsic motivation},
  url      = {www.ifaamas.org http://arxiv.org/abs/1812.07019}
}

@techreport{Letcher2019DifferentiableMechanics,
  title     = {{Differentiable Game Mechanics}},
  author    = {Letcher, Alistair and Balduzzi, David and Racan{\`{i}}, Sébastien and Martens, James and Foerster, Jakob and Tuyls, Karl and Graepel, Thore},
  year      = {2019},
  booktitle = {Journal of Machine Learning Research},
  keywords  = {classical mechan-ics, deep learning, dynamical systems, game theory, generative adversarial networks, gradient descent, hamiltonian mechanics},
  pages     = {1--40},
  url       = {https://github.com/deepmind/symplectic-gradient-adjustment.},
  volume    = {20}
}

@techreport{LetcherSTABLEGAMES,
  title  = {{STABLE OPPONENT SHAPING IN DIFFERENTIABLE GAMES}},
  author = {Letcher, Alistair and Foerster, Jakob and Balduzzi, David and Rockt{\"{a}}schel, Tim and Whiteson, Shimon}
}

@inproceedings{Li2012,
  title     = {{A potential function and artificial neural network for path planning in dynamic environments based on self-reconfigurable mobile robot system}},
  author    = {Li, Bin and Chang, Jian and Wu, Chengdong},
  booktitle = {2012 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR)},
  year      = {2012},
  month     = {11},
  pages     = {1--6},
  publisher = {IEEE},
  doi       = {10.1109/SSRR.2012.6523900},
  isbn      = {978-1-4799-0165-4},
  url       = {http://ieeexplore.ieee.org/document/6523900/}
}

@inproceedings{Li2017,
  title     = {{Decentralized stochastic control of robotic swarm density: Theory, simulation, and experiment}},
  author    = {Li, Hanjun and Feng, Chunhan and Ehrhard, Henry and Shen, Yijun and Cobos, Bernardo and Zhang, Fangbo and Elamvazhuthi, Karthik and Berman, Spring and Haberland, Matt and Bertozzi, Andrea L.},
  booktitle = {IEEE International Conference on Intelligent Robots and Systems},
  year      = {2017},
  month     = {dec},
  pages     = {4341--4347},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  volume    = {2017-Septe},
  abstract  = {This paper explores a stochastic approach for controlling swarms of independent robots toward a target distribution in a bounded domain. The robot swarm has no central controller, and individual robots lack both communication and localization capabilities. Robots can only measure a scalar field (e.g. concentration of a chemical) from the environment and from this deduce the desired local swarm density. Based on this value, each robot follows a simple control law that causes the swarm as a whole to diffuse toward the target distribution. Using a new holonomic drive robot, we present the first confirmation of this control law with physical experiment. Despite deviations from assumptions underpinning the theory, the swarm achieves the theorized convergence to the target distribution in both simulation and experiment. In fact, simulated and experimental performance agree with one another and with our hypothesis that the error from the target distribution is inversely proportional to the square root of the number of robots. This is evidence that the algorithm is both practical and easily scalable to large swarms.},
  doi       = {10.1109/IROS.2017.8206299},
  isbn      = {9781538626825},
  issn      = {21530866}
}

@article{Li2018,
  title   = {{OIL: Observational Imitation Learning}},
  author  = {Li, Guohao and M{\"{u}}ller, Matthias and Casser, Vincent and Smith, Neil and Michels, Dominik L. and Ghanem, Bernard},
  year    = {2018},
  month   = {3},
  arxivid = {1803.01129},
  url     = {http://arxiv.org/abs/1803.01129}
}

@article{Lin2019,
  title     = {{Fast 3D Collision Avoidance Algorithm for Fixed Wing UAS}},
  author    = {Lin, Zijie and Castano, Lina and Mortimer, Edward and Xu, Huan},
  journal   = {Journal of Intelligent and Robotic Systems: Theory and Applications},
  year      = {2019},
  doi       = {10.1007/s10846-019-01037-7},
  issn      = {15730409},
  keywords  = {Air vehicle obstacle avoidance, Avoidance efficiency, Fast obstacle avoidance, Optimal avoidance starting time},
  publisher = {Springer Netherlands}
}

@inproceedings{Liu2017LearningMacro-actions,
  title     = {{Learning for multi-robot cooperation in partially observable stochastic environments with macro-actions}},
  author    = {Liu, Miao and Sivakumar, Kavinayan and Omidshafiei, Shayegan and Amato, Christopher and How, Jonathan P.},
  booktitle = {IEEE International Conference on Intelligent Robots and Systems},
  year      = {2017},
  pages     = {1853--1860},
  volume    = {2017-Septe},
  arxivid   = {1707.07399},
  doi       = {10.1109/IROS.2017.8206001},
  isbn      = {9781538626825},
  issn      = {21530866},
  url       = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8206001}
}

@article{Liu2019,
  abstract  = {This paper investigates the cooperative and flexible vehicle platooning problem in automated highway systems. We formulate the platoon into a dynamically decoupled system and address the flexible platooning problem using distributed model predictive control (DMPC) techniques. A two-step noniterative DMPC strategy is proposed that sequentially solves local components of a constrained optimal control problem over two batches of vehicle clusters based on intervehicle communication. By introducing the clustering procedure, the proposed DMPC scheme only requires compatibility constraints of common neighbors of two adjacent vehicle clusters. With the two-step DMPC scheme, stability of the overall closed-loop system is guaranteed by a series of linear matrix inequalities that can be efficiently solved in practical applications. Collision-free properties are addressed using coupled state constraints together with terminal sets during a cooperation procedure. Simulations of flexible platooning are conducted for both joining and leaving events to show the effectiveness of the two-step DMPC scheme.},
  author    = {Liu, Peng and Kurt, Arda and Ozguner, Umit},
  doi       = {10.1109/TCST.2018.2808911},
  issn      = {1558-0865},
  journal   = {IEEE Transactions on Control Systems Technology},
  keywords  = {Automated highway systems,controller synthesis,cooperative driving,distributed model predictive control (DMPC),platoon formation},
  month     = {may},
  number    = {3},
  pages     = {1115--1128},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  title     = {{Distributed Model Predictive Control for Cooperative and Flexible Vehicle Platooning}},
  volume    = {27},
  year      = {2019}
}

@article{Liu2019,
  title   = {{Aircraft Trajectory Optimization for Collision Avoidance Using Stochastic Optimal Control}},
  author  = {Liu, Wensheng and Liang, Xuelin and Ma, Yunzhu and Liu, Weiyi},
  journal = {Asian Journal of Control},
  year    = {2019},
  month   = {sep},
  number  = {5},
  pages   = {2308--2320},
  volume  = {21},
  doi     = {10.1002/asjc.1855},
  issn    = {1561-8625},
  url     = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asjc.1855}
}

@techreport{LiuTrust-Aware,
  title    = {{Trust-Aware Behavior Reflection for Robot Swarm Self-Healing *}},
  author   = {Liu, Rui and Jia, Fan and Luo, Wenhao and Chandarana, Meghan and Nam, Changjoo and Lewis, Michael and Sycara, Katia},
  keywords = {Behavior Reflection, Swarm Self-Healing, Trust, Trust-R, WMSR},
  url      = {www.ifaamas.org}
}

@techreport{Lomuscio2019ASystems,
  title     = {{A Counter Abstraction Tech-nique for the Verification of Probabilistic Swarm Systems}},
  author    = {Lomuscio, Alessio and Pirovano, Edoardo},
  year      = {2019},
  booktitle = {IFAAMAS},
  url       = {www.ifaamas.org},
  volume    = {9}
}

@book{Lygeros2004,
  abstract  = {The aim of this course is to introduce some fundamental concepts from the area of hybrid systems, that is dynamical systems that involve the interaction of continuous (real valued) states and discrete (finite valued) states. Applications where these types of dynamics play a prominent role will be highlighted. We will introduce general methods for investigating properties such as existence of solutions, reachability and decidability of hybrid systems. The methods will be demonstrated on the motivating applications. Students who successfully complete the course should be able to appreciate the diversity of phenomena that arise in hybrid systems and how discrete “discrete” entities and concepts such as automata, decidability and bisimulation can coexist with continuous entities and concepts, such as differential equations.},
  author    = {Lygeros, John},
  booktitle = {Reading},
  file      = {:Users/aamalh/STAI/Literature Review/Papers/lygeros.pdf:pdf},
  pages     = {82},
  title     = {{Lecture Notes on Hybrid Systems}},
  year      = {2004}
}

@article{Lyu2016,
  title     = {{Feature article: Vision-based UAV collision avoidance with 2D dynamic safety envelope}},
  author    = {Lyu, Yang and Pan, Quan and Zhao, Chunhui and Zhang, Yizhai and Hu, Jinwen},
  journal   = {IEEE Aerospace and Electronic Systems Magazine},
  year      = {2016},
  month     = {7},
  number    = {7},
  pages     = {16--26},
  volume    = {31},
  doi       = {10.1109/MAES.2016.150155},
  issn      = {08858985},
  publisher = {Institute of Electrical and Electronics Engineers Inc.}
}

@misc{Ma2017,
  title     = {{Consensus control of stochastic multi-agent systems: a survey}},
  author    = {Ma, Lifeng and Wang, Zidong and Han, Qing Long and Liu, Yurong},
  month     = {dec},
  year      = {2017},
  abstract  = {In this article, we provide a review of the consensus control problem for stochastic multi-agent systems (MASs). Recent advances are surveyed according to the method of occurrence of the stochasticity of the MASs. First, the consensus problem is discussed for MASs, wherein individual agents are corrupted by random noises, i.e., the dynamics of agents involve stochasticity in process and/or measurement equations. Both additive noises and multiplicative noises are surveyed in detail and special attention is paid to the MASs whose dynamics are governed by It{\^{o}} differential equations. Moreover, particular effort is devoted to presenting the latest progress on the consensus problem for a special type of stochastic MAS with Markovian jump parameters. Subsequently, the relevant research is summarized for MASs with noisy communication environments and stochastic sampling. Further, we provide a systematic review of the consensus problems for MASs whose communication topology varies randomly in the process of data propagation among agents. Finally, conclusions are drawn and several potential future research directions are outlined.},
  booktitle = {Science China Information Sciences},
  doi       = {10.1007/s11432-017-9169-4},
  file      = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Ma et al. - 2017 - Consensus control of stochastic multi-agent systems a survey.pdf:pdf},
  issn      = {18691919},
  keywords  = {Markovian jump systems,consensus control,random topology,stochastic multi-agent systems,stochastic noises},
  number    = {12},
  publisher = {Science in China Press},
  volume    = {60}
}

@article{Ma2017Overview:Systems,
  title     = {{Overview: A Hierarchical Framework for Plan Generation and Execution in Multirobot Systems}},
  author    = {Ma, Hang and H{\"{o}}nig, Wolfgang and Cohen, Liron and Uras, Tansel and Xu, Hong and Kumar, T. K.Satish and Ayanian, Nora and Koenig, Sven},
  journal   = {IEEE Intelligent Systems},
  year      = {2017},
  month     = {11},
  number    = {6},
  pages     = {6--12},
  volume    = {32},
  doi       = {10.1109/MIS.2017.4531217},
  issn      = {15411672},
  keywords  = {intelligent systems, multirobot planning, multirobot systems, path planning, plan execution},
  publisher = {Institute of Electrical and Electronics Engineers Inc.}
}

@inproceedings{Mac2016,
  title     = {{AR.Drone UAV control parameters tuning based on particle swarm optimization algorithm}},
  author    = {Mac, Thi Thoa and Copot, Cosmin and Duc, Trung Tran and De Keyser, Robin},
  booktitle = {2016 20th IEEE International Conference on Automation, Quality and Testing, Robotics, AQTR 2016 - Proceedings},
  year      = {2016},
  month     = {6},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  doi       = {10.1109/AQTR.2016.7501380},
  isbn      = {9781467386906}
}

@inproceedings{Mac2016a,
  title     = {{AR.Drone UAV control parameters tuning based on particle swarm optimization algorithm}},
  author    = {Mac, Thi Thoa and Copot, Cosmin and Duc, Trung Tran and De Keyser, Robin},
  booktitle = {2016 IEEE International Conference on Automation, Quality and Testing, Robotics (AQTR)},
  year      = {2016},
  month     = {5},
  pages     = {1--6},
  publisher = {IEEE},
  doi       = {10.1109/AQTR.2016.7501380},
  isbn      = {978-1-4673-8692-0},
  url       = {http://ieeexplore.ieee.org/document/7501380/}
}

@techreport{Magalhaes-Mendes,
  title    = {{A Comparative Study of Crossover Operators for Genetic Algorithms to Solve the Job Shop Scheduling Problem}},
  author   = {Magalh{\~{a}}es-Mendes, Jorge},
  keywords = {Crossover Operators, Genetic Algorithms, JSSP, Key-Words:-Scheduling, Operations Research, Optimization},
  url      = {https://pdfs.semanticscholar.org/3bda/cac99759ca1c71e241b815ea50226b05af70.pdf}
}

@techreport{Makar2001HierarchicalLearning,
  title  = {{Hierarchical Multi-Agent Reinforcement Learning}},
  author = {Makar, Rajbala and Mahadevan, Sridhar and Ghavamzadeh, Mohammad},
  year   = {2001},
  isbn   = {158113326X}
}

@techreport{MaoModellingDDPG,
  title    = {{Modelling the Dynamic Joint Policy of Teammates with Attention Multi-agent DDPG}},
  author   = {Mao, Hangyu and Zhang, Zhengchao and Xiao, Zhen and Gong, Zhibo and Gong, Zhibo 2019},
  keywords = {Agent Modelling, Deep Reinforcement Learning, Multi-agent Reinforcement Learning, Teammates Modelling},
  url      = {www.ifaamas.org}
}

@article{Marden2018AnnualControl,
  title    = {{Annual Review of Control, Robotics, and Autonomous Systems Game Theory and Control}},
  author   = {Marden, Jason R and Shamma, Jeff S},
  year     = {2018},
  doi      = {10.1146/annurev-control-060117},
  keywords = {distributed control, game theory, learning in games, mechanism design, team games, zero-sum games},
  url      = {https://doi.org/10.1146/annurev-control-060117-}
}

@article{Marinescu2014,
  title         = {{Decentralised Multi-Agent Reinforcement Learning for Dynamic and Uncertain Environments}},
  author        = {Marinescu, Andrei and Dusparic, Ivana and Taylor, Adam and Cahill, Vinny and Clarke, Siobh{\'{a}}n},
  year          = {2014},
  abstract      = {Multi-Agent Reinforcement Learning (MARL) is a widely used technique for optimization in decentralised control problems. However, most applications of MARL are in static environments, and are not suitable when agent behaviour and environment conditions are dynamic and uncertain. Addressing uncertainty in such environments remains a challenging problem for MARL-based systems. The dynamic nature of the environment causes previous knowledge of how agents interact to become outdated. Advanced knowledge of potential changes through prediction significantly supports agents converging to near-optimal control solutions. In this paper we propose P-MARL, a decentralised MARL algorithm enhanced by a prediction mechanism that provides accurate information regarding up-coming changes in the environment. This prediction is achieved by employing an Artificial Neural Network combined with a Self-Organising Map that detects and matches changes in the environment. The proposed algorithm is validated in a realistic smart-grid scenario, and provides a 92{\%} Pareto efficient solution to an electric vehicle charging problem.},
  archiveprefix = {arXiv},
  arxivid       = {1409.4561},
  eprint        = {1409.4561},
  file          = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Marinescu et al. - Unknown - Decentralised Multi-Agent Reinforcement Learning for Dynamic and Uncertain Environments.pdf:pdf},
  url           = {www.aaai.org http://arxiv.org/abs/1409.4561}
}

@incollection{Mataric2008,
  title     = {{Behavior-Based Systems}},
  author    = {Matari{\'{c}}, Maja J. and Michaud, François},
  booktitle = {Springer Handbook of Robotics},
  publisher = {Springer Berlin Heidelberg},
  year      = {2008},
  address   = {Berlin, Heidelberg},
  pages     = {891--909},
  doi       = {10.1007/978-3-540-30301-5{\_}39},
  url       = {http://link.springer.com/10.1007/978-3-540-30301-5_39}
}

@inproceedings{Matignon2018Multi-robotTrack,
  title     = {{Multi-robot simultaneous coverage and mapping of complex scene - Comparison of different strategies: Robotics track}},
  author    = {Matignon, Laetitia and Simonint, Olivier},
  booktitle = {Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS},
  year      = {2018},
  pages     = {559--567},
  volume    = {1},
  isbn      = {9781510868083},
  issn      = {15582914},
  keywords  = {Mapping and exploration, Multi-robot systems, Networked robot, Sensor systems},
  url       = {www.ifaamas.org}
}

@article{Matsuda2019,
  title   = {{Accurate and Efficient Seafloor Observations With Multiple Autonomous Underwater Vehicles: Theory and Experiments in a Hydrothermal Vent Field}},
  author  = {Matsuda, Takumi and Maki, Toshihiro and Sakamaki, Takashi},
  journal = {IEEE Robotics and Automation Letters},
  year    = {2019},
  month   = {7},
  number  = {3},
  pages   = {2333--2339},
  volume  = {4},
  doi     = {10.1109/LRA.2019.2902744},
  issn    = {2377-3766},
  url     = {https://ieeexplore.ieee.org/document/8657727/}
}

@inproceedings{Mazurowski2007SolvingOptimization,
  title     = {{Solving multi-agent control problems using particle swarm optimization}},
  author    = {Mazurowski, Maciej A. and Zurada, Jacek M.},
  booktitle = {Proceedings of the 2007 IEEE Swarm Intelligence Symposium, SIS 2007},
  year      = {2007},
  pages     = {105--111},
  doi       = {10.1109/SIS.2007.368033},
  isbn      = {1424407087}
}

@inproceedings{McFadyen2013,
  title     = {{Aircraft collision avoidance using spherical visual predictive control and single point features}},
  author    = {McFadyen, Aaron and Mejias, Luis and Corke, Peter and Pradalier, Cedric},
  booktitle = {IEEE International Conference on Intelligent Robots and Systems},
  year      = {2013},
  pages     = {50--56},
  doi       = {10.1109/IROS.2013.6696331},
  isbn      = {9781467363587},
  issn      = {21530858}
}

@article{Mendes2017,
  abstract  = {This paper presents a framework to deal with distributed optimization problems composed by binary and continuous variables. Instead of using a mixed integer quadratic programming (MIQP), the approach proposed here transforms the MIQP into a set of quadratic programming's (QP) that are easier to solve. In this way an instance of the controller related to each feasible combination of binary variables is created. The distributed controller performs an iterative process where the set of agents must agree on the value of continuous interconnection variables, while each agent must decide the values of local binary variables. During the iteration procedure the instances are rated according to a performance index and the instances with best performance are selected until the best one is obtained. The proposed methodology is applied to economic optimization of networked microgrids.},
  author    = {Mendes, Paulo R.C. and Maestre, Jose M. and Bordons, Carlos and Normey-Rico, Julio E.},
  doi       = {10.1016/j.jprocont.2017.01.001},
  issn      = {09591524},
  journal   = {Journal of Process Control},
  keywords  = {Distributed model predictive control,Hybrid systems,Networked microgrids},
  pages     = {30--41},
  publisher = {Elsevier Ltd},
  title     = {{A practical approach for hybrid distributed MPC}},
  volume    = {55},
  year      = {2017}
}

@techreport{Meng,
  title  = {{Game-Theory based Multi-Robot Searching Approach}},
  author = {Meng, Yan and Cao, Ke},
  url    = {https://www.researchgate.net/publication/237226958}
}

@techreport{MertikopoulosCYCLESLEARNING,
  title   = {{CYCLES IN ADVERSARIAL REGULARIZED LEARNING}},
  author  = {Mertikopoulos, Panayotis and Papadimitriou, Christos and Piliouras, Georgios},
  arxivid = {1709.02738v1}
}

@misc{Mesbah2016,
  title           = {{Stochastic model predictive control: An overview and perspectives for future research}},
  author          = {Mesbah, Ali},
  month           = {dec},
  year            = {2016},
  abstract        = {Model predictive control (MPC) has demonstrated exceptional success for the high-performance control of complex systems [1], [2]. The conceptual simplicity of MPC as well as its ability to effectively cope with the complex dynamics of systems with multiple inputs and outputs, input and state/output constraints, and conflicting control objectives have made it an attractive multivariable constrained control approach [1]. MPC (a.k.a. receding-horizon control) solves an open-loop constrained optimal control problem (OCP) repeatedly in a receding-horizon manner [3]. The OCP is solved over a finite sequence of control actions {\{}u 0 ,u 1 ,⋯,u N-1 {\}} at every sampling time instant that the current state of the system is measured. The first element of the sequence of optimal control actions is applied to the system, and the computations are then repeated at the next sampling time. Thus, MPC replaces a feedback control law $\pi$({\textperiodcentered}), which can have formidable offline computation, with the repeated solution of an open-loop OCP [2]. In fact, repeated solution of the OCP confers an "implicit" feedback action to MPC to cope with system uncertainties and disturbances. Alternatively, explicit MPC approaches circumvent the need to solve an OCP online by deriving relationships for the optimal control actions in terms of an "explicit" function of the state and reference vectors. However, explicit MPC is not typically intended to replace standard MPC but, rather, to extend its area of application [4]-[6].},
  booktitle       = {IEEE Control Systems},
  doi             = {10.1109/MCS.2016.2602087},
  file            = {::},
  issn            = {1066033X},
  mendeley-groups = {STAI/PhD/Games},
  number          = {6},
  pages           = {30--44},
  publisher       = {Institute of Electrical and Electronics Engineers Inc.},
  volume          = {36}
}

@techreport{MeursAdvancesIntelligence,
  title  = {{Advances in Artificial Intelligence}},
  author = {Meurs, Marie-Jean and Rudzicz, Frank and Goebel, Randy and Tanaka, Yuzuru and Wahlster, Wolfgang and Siekmann, Jörg},
  doi    = {10.1007/978-3-030-18305-9},
  url    = {http://www.springer.com/series/1244}
}

@techreport{Milchtaich2007StaticGames,
  title    = {{Static Stability in Games}},
  author   = {Milchtaich, Igal},
  year     = {2007},
  keywords = {Stability of equilibrium, static stability}
}

@inproceedings{Min-HoKim2011,
  title     = {{A path planning algorithm using artificial potential field based on probability map}},
  author    = {{Min-Ho Kim} and {Jung-Hun Heo} and {Yuanlong Wei} and {Min-Cheol Lee}},
  booktitle = {2011 8th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)},
  year      = {2011},
  month     = {11},
  pages     = {41--43},
  publisher = {IEEE},
  doi       = {10.1109/URAI.2011.6145929},
  isbn      = {978-1-4577-0723-0},
  url       = {http://ieeexplore.ieee.org/document/6145929/}
}

@article{Minsky2014,
  title     = {{Evolutionary artificial neural networks}},
  author    = {Minsky, Marvin},
  journal   = {Adaptation, Learning, and Optimization},
  year      = {2014},
  pages     = {187--230},
  volume    = {15},
  doi       = {10.1007/978-3-642-37846-1{\_}7},
  issn      = {18674542},
  publisher = {Springer Verlag}
}

@techreport{Mitra,
  title  = {{Mesh Smoothing}},
  author = {Mitra, Niloy J}
}

@incollection{Mitraa,
  title  = {{Mesh Smoothing}},
  author = {Mitra, Niloy},
  url    = {https://moodle-1819.ucl.ac.uk/pluginfile.php/370192/mod_resource/content/6/05_Smoothing.pdf}
}

@techreport{Mnih,
  title  = {{Playing Atari with Deep Reinforcement Learning}},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  url    = {https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf}
}

@misc{ModelingMotion,
  title = {{Modeling Vehicle Dynamics - Quadcopter Equations of Motion - Autonomy in Motion}},
  url   = {http://charlestytler.com/quadcopter-equations-motion/}
}

@techreport{ModuleObjectives,
  title = {{Module 2 : Electrostatics Lecture 10 : Poisson Equations Objectives}},
  url   = {https://nptel.ac.in/courses/122101002/downloads/lec-10.pdf}
}

@inproceedings{Molinos2014,
  title     = {{Dynamic obstacle avoidance based on curvature arcs}},
  author    = {Molinos, Eduardo and Llamazares, Angel and Ocana, Manuel and Herranz, Fernando},
  booktitle = {2014 IEEE/SICE International Symposium on System Integration, SII 2014},
  year      = {2014},
  month     = {1},
  pages     = {186--191},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  doi       = {10.1109/SII.2014.7028035},
  isbn      = {9781479969449}
}

@article{Montiel2015,
  title     = {{Path planning for mobile robots using Bacterial Potential Field for avoiding static and dynamic obstacles}},
  author    = {Montiel, Oscar and Orozco-Rosas, Ulises and Sep{\'{u}}lveda, Roberto},
  journal   = {Expert Systems with Applications},
  year      = {2015},
  month     = {7},
  number    = {12},
  pages     = {5177--5191},
  volume    = {42},
  doi       = {10.1016/J.ESWA.2015.02.033},
  issn      = {0957-4174},
  publisher = {Pergamon},
  url       = {https://www.sciencedirect.com/science/article/pii/S0957417415001402}
}

@inproceedings{Mordatch2018EmergencePopulations,
  title     = {{Emergence of grounded compositional language in multi-agent populations}},
  author    = {Mordatch, Igor and Abbeel, Pieter},
  booktitle = {32nd AAAI Conference on Artificial Intelligence, AAAI 2018},
  year      = {2018},
  pages     = {1495--1502},
  arxivid   = {1703.04908},
  isbn      = {9781577358008},
  keywords  = {Multi-Agent Reinforcement Learning, Multi-Robot Systems, Robot Team Formation},
  url       = {https://blog.openai.com/openai-five/.}
}

@techreport{MouraPires,
  title  = {{Lecture Notes in Artificial Intelligence 2902 Subseries of Lecture Notes in Computer Science}},
  author = {Moura Pires, Fernando and Abreu, Salvador},
  pages  = {24--28}
}

@techreport{Mueller-Wodarg2018,
  title  = {{Fluid Dynamics Third year Physics core course}},
  author = {Mueller-Wodarg, Ingo},
  year   = {2018}
}

@techreport{Mylvaganam2014,
  title  = {{APPROXIMATE FEEDBACK SOLUTIONS FOR DIFFERENTIAL GAMES THEORY AND APPLICATIONS}},
  author = {Mylvaganam, Thulasi},
  year   = {2014}
}

@article{Mylvaganam2017AutonomousApproach,
  title    = {{Autonomous collision avoidance for wheeled mobile robots using a differential game approach}},
  author   = {Mylvaganam, Thulasi and Sassano, Mario},
  journal  = {European Journal of Control},
  year     = {2017},
  pages    = {53--61},
  volume   = {40},
  doi      = {10.1016/j.ejcon.2017.11.005},
  keywords = {Collision avoidance, Differential games, Multi-agent systems, Nonlinear control systems},
  url      = {https://doi.org/10.1016/j.ejcon.2017.11.005}
}

@techreport{MylvaganamASystems,
  title  = {{A Game Theoretic Approach to Distributed Control of Homogeneous Multi-Agent Systems}},
  author = {Mylvaganam, T}
}

@book{Nagy2013,
  title     = {{Active Team Management Strategies for Multi-robot Teams in Dangerous Environments}},
  author    = {Nagy, Geoff and Anderson, John},
  publisher = {WORLD SCIENTIFIC},
  year      = {2013},
  month     = {6},
  booktitle = {Advances in Artificial Intelligence},
  doi       = {10.1142/1305}
}

@incollection{Neal2011MCMCDynamics,
  title     = {{MCMC using hamiltonian dynamics}},
  author    = {Neal, Radford M.},
  booktitle = {Handbook of Markov Chain Monte Carlo},
  publisher = {CRC Press},
  year      = {2011},
  month     = {5},
  pages     = {113--162},
  arxivid   = {1206.1901},
  doi       = {10.1201/b10905-6},
  isbn      = {9781420079425}
}

@inproceedings{Negenborn2014,
  abstract  = {This is a position paper on the current state of the art in distributed Model Predictive Control (MPC) and our view on its future potential. We present results from a recent survey of 35 distributed MPC approaches. For this, we propose a way in which distributed MPC approaches can be categorized for comparison. We also link the potential that these approaches have to the domain of other fields such as integrated environmental optimal decision making and cyber-physical systems. Many challenges for realizing these links have to be faced. We present our views on how the advances in several highly active research domains could be used to overcome these challenges. As such, this paper is intended as a starting point for the exploration of various novel research cooperations. {\textcopyright} 2014 IEEE.},
  author    = {Negenborn, R. R. and Maestre, J. M.},
  booktitle = {Proceedings of the 11th IEEE International Conference on Networking, Sensing and Control, ICNSC 2014},
  doi       = {10.1109/ICNSC.2014.6819682},
  isbn      = {9781479931064},
  keywords  = {Distributed model predictive control,algorithm categorization,emerging research areas},
  pages     = {530--535},
  publisher = {IEEE Computer Society},
  title     = {{Distributed Model Predictive Control: An overview of features and research opportunities}},
  year      = {2014}
}

@article{NoTitle,
  title = {{(No Title)}}
}

@incollection{Nowe2012GameLearning,
  title     = {{Game theory and multi-agent reinforcement learning}},
  author    = {Now{\'{e}}, Ann and Vrancx, Peter and De Hauwere, Yann Michaël},
  booktitle = {Adaptation, Learning, and Optimization},
  publisher = {Springer Verlag},
  year      = {2012},
  pages     = {441--470},
  volume    = {12},
  doi       = {10.1007/978-3-642-27645-3{\_}14},
  issn      = {18674542},
  keywords  = {Assure, Eter, Librium, Lution, Nash}
}

@inproceedings{OBeirne2006AExploration,
  title     = {{A market framework for collaborative robot exploration}},
  author    = {O'Beirne, Declan and Schukat, Michael},
  booktitle = {VDI Berichte},
  year      = {2006},
  number    = {1956},
  pages     = {305},
  issn      = {00835560},
  keywords  = {Collaborative, Exploration, Market}
}

@techreport{OliehoekDecentralizedPOMDPs,
  title  = {{Decentralized POMDPs}},
  author = {Oliehoek, Frans A}
}

@article{Omidshafiei2017DecentralizedMacro-actions,
  title   = {{Decentralized control of multi-robot partially observable Markov decision processes using belief space macro-actions}},
  author  = {Omidshafiei, Shayegan and Agha-Mohammadi, Ali-Akbar and Amato, Christopher and Liu, Shih-Yuan and How, Jonathan P and Vian, John},
  journal = {The International Journal of Robotics Research},
  year    = {2017},
  number  = {2},
  pages   = {231--258},
  volume  = {36},
  doi     = {10.1177/0278364917692864}
}

@article{Owen2005,
  title   = {{The effects of linear and quadratic drag on falling spheres: An undergraduate laboratory}},
  author  = {Owen, Julia P. and Ryu, William S.},
  journal = {European Journal of Physics},
  year    = {2005},
  month   = {11},
  number  = {6},
  pages   = {1085--1091},
  volume  = {26},
  doi     = {10.1088/0143-0807/26/6/016},
  issn    = {01430807}
}

@inproceedings{Pallottino2007ProbabilisticAvoidance,
  title     = {{Probabilistic verification of decentralized multi-agent control strategies: A Case Study in Conflict Avoidance}},
  author    = {Pallottino, Lucia and Bicchi, Antonio and Frazzoli, Emilio},
  booktitle = {Proceedings of the American Control Conference},
  year      = {2007},
  pages     = {170--175},
  doi       = {10.1109/ACC.2007.4283164},
  isbn      = {1424409888},
  issn      = {07431619}
}

@article{Paulson2019,
  title   = {{An efficient method for stochastic optimal control with joint chance constraints for nonlinear systems}},
  author  = {Paulson, Joel A. and Mesbah, Ali},
  journal = {International Journal of Robust and Nonlinear Control},
  year    = {2019},
  month   = {oct},
  number  = {15},
  pages   = {5017--5037},
  volume  = {29},
  doi     = {10.1002/rnc.3999},
  issn    = {1049-8923},
  url     = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rnc.3999}
}

@misc{PIDInstruments,
  title = {{PID Theory Explained - National Instruments}},
  url   = {http://www.ni.com/white-paper/3782/en/}
}

@misc{PigpioLibrary,
  title = {{pigpio library}},
  url   = {http://abyz.me.uk/rpi/pigpio/index.html}
}

@article{Pini2011TaskSelection,
  title    = {{Task partitioning in swarms of robots: An adaptive method for strategy selection}},
  author   = {Pini, Giovanni and Brutschy, Arne and Frison, Marco and Roli, Andrea and Dorigo, Marco and Birattari, Mauro},
  journal  = {Swarm Intelligence},
  year     = {2011},
  number   = {3-4},
  pages    = {283--304},
  volume   = {5},
  doi      = {10.1007/s11721-011-0060-1},
  issn     = {19353812},
  keywords = {Foraging, Self-organization, Swarm robotics, Task partitioning}
}

@article{Pini2013AutonomousEstimation,
  title    = {{Autonomous task partitioning in robot foraging: An approach based on cost estimation}},
  author   = {Pini, Giovanni and Brutschy, Arne and Pinciroli, Carlo and Dorigo, Marco and Birattari, Mauro},
  journal  = {Adaptive Behavior},
  year     = {2013},
  doi      = {10.1177/1059712313484771},
  issn     = {10597123},
  keywords = {Task partitioning, foraging, self-organization, swarm intelligence, swarm robotics}
}

@techreport{Platt1998,
  title  = {{Sequential Minimal Optimization: A Fast Algorithm for Training Support Vector Machines}},
  author = {Platt, John C},
  year   = {1998},
  url    = {https://pdfs.semanticscholar.org/59ee/e096b49d66f39891eb88a6c84cc89acba12d.pdf}
}

@techreport{Pounds,
  title  = {{Modelling and Control of a Quad-Rotor Robot}},
  author = {Pounds, Paul and Mahony, Robert and Corke, Peter},
  url    = {https://pdfs.semanticscholar.org/4eb8/ee77b0fe804ad6df17f80ad4d9eca1791733.pdf}
}

@book{Prince2012,
  title     = {{Computer Vision: Models, Learning, and Inference}},
  author    = {Prince, S.J.D.},
  publisher = {Cambridge University Press},
  year      = {2012}
}

@book{Prince2012a,
  title     = {{Computer Vision: Models, Learning, and Inference}},
  author    = {Prince, Simon J.D.},
  publisher = {Cambridge University Press},
  year      = {2012}
}

@inproceedings{Purian2013,
  title     = {{Mobile robots path planning using ant colony optimization and Fuzzy Logic algorithms in unknown dynamic environments}},
  author    = {Purian, Fatemeh Khosravi and Sadeghian, Ehsan},
  booktitle = {CARE 2013 - 2013 IEEE International Conference on Control, Automation, Robotics and Embedded Systems, Proceedings},
  year      = {2013},
  doi       = {10.1109/CARE.2013.6733718},
  isbn      = {9781467361538},
  keywords  = {Ants colony algorithm, fuzzy logic, mobile robot, path planning, the dynamic environment}
}

@inproceedings{Qiao2008,
  title     = {{Application of reinforcement learning based on neural network to dynamic obstacle avoidance}},
  author    = {Qiao, Junfei and Hou, Zhanjun and Ruan, Xiaogang},
  booktitle = {Proceedings of the 2008 IEEE International Conference on Information and Automation, ICIA 2008},
  year      = {2008},
  pages     = {784--788},
  doi       = {10.1109/ICINFA.2008.4608104},
  isbn      = {9781424421848}
}

@techreport{QuadcopterControl,
  title = {{Quadcopter Dynamics, Simulation, and Control}}
}

@techreport{QuadcopterControlb,
  title = {{Quadcopter Dynamics, Simulation, and Control}},
  url   = {http://andrew.gibiansky.com/downloads/pdf/Quadcopter%20Dynamics,%20Simulation,%20and%20Control.pdf}
}

@misc{QuadcopterOfficial,
  title = {{Quadcopter AR Drone 2.0 Elite Edition | Parrot Store Official}},
  url   = {https://www.parrot.com/uk/drones/parrot-ardrone-20-elite-edition}
}

@inproceedings{Ramachandran2007BayesianLearning,
  title     = {{Bayesian inverse reinforcement learning}},
  author    = {Ramachandran, Deepak and Amir, Eyal},
  booktitle = {IJCAI International Joint Conference on Artificial Intelligence},
  year      = {2007},
  issn      = {10450823}
}

@book{rawlings2017model,
  author    = {Rawlings, J B and Mayne, D Q and Diehl, M},
  isbn      = {9780975937730},
  publisher = {Nob Hill Publishing},
  title     = {{Model Predictive Control: Theory, Computation, and Design}},
  url       = {https://books.google.co.uk/books?id=MrJctAEACAAJ},
  year      = {2017}
}

@techreport{Ray2010,
  title  = {{An Extension of Bayesian Game Approximation to Partially Observable Stochastic Games with Competition and Cooperation. Theoretical and Computational Models of the Human Mind and Brain View project An Extension of Bayesian Game Approximation to Partially O}},
  author = {Ray, Laura E and Kralik, Jerald D and Shi, Dongqing and Sauter, Michael Z and Sun, Xueqing},
  year   = {2010},
  url    = {https://www.researchgate.net/publication/220835260}
}

@article{Reis2019RobustVehicles,
  title   = {{Robust Cooperative Moving Path Following Control for Marine Robotic Vehicles}},
  author  = {Reis, Matheus F. and Jain, R. Praveen and Aguiar, A. Pedro and de Sousa, Joao Borges},
  journal = {Frontiers in Robotics and AI},
  year    = {2019},
  month   = {11},
  volume  = {6},
  doi     = {10.3389/frobt.2019.00121},
  issn    = {2296-9144},
  url     = {https://www.frontiersin.org/article/10.3389/frobt.2019.00121/full}
}

@misc{Rizk2018,
  title     = {{Decision Making in Multiagent Systems: A Survey}},
  author    = {Rizk, Yara and Awad, Mariette and Tunstel, Edward W.},
  month     = {9},
  year      = {2018},
  booktitle = {IEEE Transactions on Cognitive and Developmental Systems},
  doi       = {10.1109/TCDS.2018.2840971},
  issn      = {23798939},
  keywords  = {Cooperation, Markov decision process (MDP), decision making models, game theory, multiagent systems (MASs), swarm intelligence},
  number    = {3},
  pages     = {514--529},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  volume    = {10}
}

@article{RobotAI,
  title  = {{Artificial Intelligence and Robotics}},
  author = {{RobotAI}}
}

@article{Rong2019CompetitiveNetworks,
  title    = {{Competitive Bridge Bidding with Deep Neural Networks}},
  author   = {Rong, Jiang and Qin, Tao and An, Bo},
  journal  = {IFAAMAS},
  year     = {2019},
  volume   = {9},
  arxivid  = {1903.00900},
  keywords = {artificial intelligence, contract bridge, reinforcement learning},
  url      = {https://en.wikipedia.org/wiki/Standard_American http://arxiv.org/abs/1903.00900}
}

@techreport{Rosello2018Multi-AgentTracking,
  title     = {{Multi-Agent Reinforcement Learning for Multi-Object Tracking}},
  author    = {Rosello, Pol and Kochenderfer, Mykel J},
  year      = {2018},
  booktitle = {ACM Reference Format: Pol Rosello and Mykel J. Kochenderfer},
  keywords  = {Engineering Multiagent Systems—Innovative agents a, Learning and Adaptation—Deep learning, Learning and Adaptation—Multiagent learning},
  url       = {www.ifaamas.org}
}

@article{Rosen2019CommunicatingDisplays,
  title     = {{Communicating and controlling robot arm motion intent through mixed-reality head-mounted displays}},
  author    = {Rosen, Eric and Whitney, David and Phillips, Elizabeth and Chien, Gary and Tompkin, James and Konidaris, George and Tellex, Stefanie},
  journal   = {International Journal of Robotics Research},
  year      = {2019},
  month     = {10},
  arxivid   = {1708.03655},
  doi       = {10.1177/0278364919842925},
  issn      = {17413176},
  keywords  = {Mixed reality, human–robot interaction, motion planning},
  publisher = {SAGE Publications Inc.}
}

@article{Rosenfeld2019ExplainabilitySystems,
  title     = {{Explainability in human–agent systems}},
  author    = {Rosenfeld, Avi and Richardson, Ariella},
  journal   = {Autonomous Agents and Multi-Agent Systems},
  year      = {2019},
  arxivid   = {1904.08123},
  doi       = {10.1007/s10458-019-09408-y},
  issn      = {15737454},
  keywords  = {Human–agent systems, Machine learning interpretability, Machine learning transparency, XAI},
  publisher = {Springer New York LLC}
}

@article{Rosolia2018,
  title         = {{Learning model predictive control for iterative tasks. A data-driven control framework}},
  author        = {Rosolia, Ugo and Borrelli, Francesco},
  journal       = {IEEE Transactions on Automatic Control},
  year          = {2018},
  month         = {jul},
  number        = {7},
  pages         = {1883--1896},
  volume        = {63},
  abstract      = {A learning model predictive controller for iterative tasks is presented. The controller is reference-free and is able to improve its performance by learning from previous iterations. A safe set and a terminal cost function are used in order to guarantee recursive feasibility and nondecreasing performance at each iteration. This paper presents the control design approach, and shows how to recursively construct terminal set and terminal cost from state and input trajectories of previous iterations. Simulation results show the effectiveness of the proposed control logic.},
  archiveprefix = {arXiv},
  arxivid       = {1609.01387},
  doi           = {10.1109/TAC.2017.2753460},
  eprint        = {1609.01387},
  file          = {:home/aamalh/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rosolia, Borrelli - 2018 - Learning model predictive control for iterative tasks. A data-driven control framework.pdf:pdf},
  issn          = {00189286},
  keywords      = {Data driven,iterative learning control,learning,optimal control,predictive control,safety},
  publisher     = {Institute of Electrical and Electronics Engineers Inc.}
}

@inproceedings{Ross2013,
  title     = {{Learning monocular reactive UAV control in cluttered natural environments}},
  author    = {Ross, Stephane and Melik-Barkhudarov, Narek and Shankar, Kumar Shaurya and Wendel, Andreas and Dey, Debadeepta and Bagnell, J. Andrew and Hebert, Martial},
  booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
  year      = {2013},
  pages     = {1765--1772},
  doi       = {10.1109/ICRA.2013.6630809},
  isbn      = {9781467356411},
  issn      = {10504729}
}

@techreport{Sabatino2015,
  title  = {{Quadrotor control: modeling, nonlinear control design, and simulation}},
  author = {Sabatino, Francesco},
  year   = {2015},
  url    = {https://www.kth.se/polopoly_fs/1.588039!/Thesis KTH - Francesco Sabatino.pdf}
}

@techreport{Sabatino2015a,
  title  = {{Quadrotor control: modeling, nonlinear control design, and simulation}},
  author = {Sabatino, Francesco},
  year   = {2015},
  url    = {https://www.kth.se/polopoly_fs/1.588039.1550155544!/Thesis KTH - Francesco Sabatino.pdf}
}

@techreport{Sabatino2015b,
  title  = {{Quadrotor control: modeling, nonlinear control design, and simulation}},
  author = {Sabatino, Francesco},
  year   = {2015}
}

@article{Sartoretti2014,
  title    = {{Decentralized self-selection of swarm trajectories: from dynamical systems theory to robotic implementation}},
  author   = {Sartoretti, Guillaume and Hongler, Max Olivier and de Oliveira, Marcelo Elias and Mondada, Francesco},
  journal  = {Swarm Intelligence},
  year     = {2014},
  number   = {4},
  pages    = {329--351},
  volume   = {8},
  abstract = {In this paper, we present a distributed control strategy, enabling agents to converge onto and travel along a consensually selected curve among a class of closed planar curves. Individual agents identify the number of neighbors within a finite circular sensing range and obtain information from their neighbors through local communication. The information is then processed to update the control parameters and force the swarm to converge onto and circulate along the aforementioned planar curve. The proposed mathematical framework is based on stochastic differential equations driven by white Gaussian noise (diffusion processes). Using this framework, there is maximum probability that the swarm dynamics will be driven toward the consensual closed planar curve. In the simplest configuration where a circular consensual curve is obtained, we are able to derive an analytical expression that relates the radius of the circular formation to the agent's interaction range. Such an intimate relation is also illustrated numerically for more general curves. The agent-based control strategy is then translated into a distributed Braitenberg-inspired one. The proposed robotic control strategy is then validated by numerical simulations and by implementation on an actual robotic swarm. It can be used in applications that involve large numbers of locally interacting agents, such as traffic control, deployment of communication networks in hostile environments, or environmental monitoring.},
  doi      = {10.1007/s11721-014-0101-7},
  file     = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Sartoretti et al. - 2014 - Decentralized self-selection of swarm trajectories from dynamical systems theory to robotic implementation.pdf:pdf},
  issn     = {19353820},
  keywords = {Braitenberg control mechanism,Brownian agents,Distributed swarm control,Mean-field approach,Mixed canonical-dissipative dynamics,Robotics experimental validation,Spatio-temporal pattern}
}

@techreport{Schaffer,
  title  = {{Multiple Objective Optimization with Vector Evaluated Genetic Algorithms. A Novel Approach to Event-driven Simulation of Spiking Neural Network View project 1) a diagnostic test for dementia based upon speech View project}},
  author = {Schaffer, J David},
  url    = {https://www.researchgate.net/publication/220885605}
}

@book{Scholkopf1999,
  title     = {{Advances in kernel methods : support vector learning}},
  author    = {Schölkopf, Bernhard. and Burges, Christopher J. C. and Smola, Alexander J.},
  publisher = {MIT Press},
  year      = {1999},
  booktitle = {Advances in kernel methods},
  isbn      = {0262194163},
  pages     = {376},
  url       = {https://dl.acm.org/citation.cfm?id=299106}
}

@book{SchwartzMulti-agentApproach,
  title  = {{Multi-agent machine learning : a reinforcement approach}},
  author = {Schwartz, Howard M.},
  isbn   = {9781118362082}
}

@article{Sedaghat-Pisheh2017,
  title   = {{Collision avoidance algorithms for unmanned aerial vehicles using computer vision}},
  author  = {Sedaghat-Pisheh, Hani and Rivera, Amaury and Biaz, Saad and Chapman, Richard},
  journal = {Journal of Computing Sciences in Colleges},
  year    = {2017},
  number  = {2},
  pages   = {191--197},
  volume  = {33},
  issn    = {1937-4771}
}

@article{SerdarGuzel2019AStrategy,
  title     = {{A Novel Framework for Multi-Agent Systems Using a Decentralized Strategy}},
  author    = {Serdar G{\"{u}}zel, Mehmet and Ajabshir, Vahid Babaei},
  journal   = {Robotica},
  year      = {2019},
  pages     = {691--707},
  volume    = {37},
  doi       = {10.1017/S0263574718001261},
  keywords  = {Decentralized architecture, Multi-agent systems, Pattern formation, Swarm intelligence, Vision for navigation},
  publisher = {C Cambridge University Press},
  url       = {https://doi.org/10.1017/S0263574718001261}
}

@inproceedings{Sethi2017,
  title     = {{Comparative analysis of a recommender system based on ant colony optimization and artificial bee colony optimization algorithms}},
  author    = {Sethi, Deepshikha and Singhal, Abhishek},
  booktitle = {8th International Conference on Computing, Communications and Networking Technologies, ICCCNT 2017},
  year      = {2017},
  month     = {12},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  doi       = {10.1109/ICCCNT.2017.8204106},
  isbn      = {9781509030385},
  keywords  = {Ant Colony Optimization, Artificial Bee Colony Optimization, CPU Time, Collaborative Filtering, Standard Functions}
}

@inproceedings{Shahrokhi2019,
  title     = {{Reshaping particle configurations by collisions with rigid objects}},
  author    = {Shahrokhi, Shiva and Zhao, Haoran and Becker, Aaron T.},
  booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
  year      = {2019},
  month     = {may},
  pages     = {4436--4443},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  volume    = {2019-May},
  abstract  = {Consider many particles actuated by a uniform global external field (e.g. gravitational or magnetic fields). This paper presents analytical results using workspace obstacles and global inputs to reshape such a group of particles. Shape control of many particles is necessary for conveying information, construction, and navigation. First we show how the particles' characteristic angle of repose can be used to reshape the particles by controlling angle of attack and the magnitude of the driving force. These can then be used to control the force and torque applied to a rectangular rigid body. Next, we examine the full set of stable, achievable mean and variance configurations for the shape of a particle group in two canonical environments: a square and a circular workspace. Finally, we show how workspaces with linear boundary layers can be used to achieve a more rich set of mean and variance configurations.},
  doi       = {10.1109/ICRA.2019.8794405},
  isbn      = {9781538660263},
  issn      = {10504729}
}

@inproceedings{Sharma2011FuzzyProcesses,
  title     = {{Fuzzy reinforcement learning control for decentralized partially observable Markov decision processes}},
  author    = {Sharma, Rajneesh and Spaan, Matthijs T.J.},
  booktitle = {IEEE International Conference on Fuzzy Systems},
  year      = {2011},
  pages     = {1422--1429},
  doi       = {10.1109/FUZZY.2011.6007675},
  isbn      = {9781424473175},
  issn      = {10987584},
  keywords  = {Cooperative multiagent systems, Decentralized POMDPs, Fuzzy systems, Reinforcement learning}
}

@article{Sharma2012,
  title    = {{Bayesian-game-based fuzzy reinforcement learning control for decentralized POMDPs}},
  author   = {Sharma, Rajneesh and Spaan, Matthijs T.J.},
  journal  = {IEEE Transactions on Computational Intelligence and AI in Games},
  year     = {2012},
  number   = {4},
  pages    = {309--328},
  volume   = {4},
  doi      = {10.1109/TCIAIG.2012.2212279},
  issn     = {1943068X},
  keywords = {Bayesian games (BGs), decentralized partially observable Markov decision, fuzzy systems, reinforcement learning (RL)}
}

@techreport{Shawe-Taylor,
  title    = {{A review of optimization methodologies in support vector machines}},
  author   = {Shawe-Taylor, John and Sun, Shiliang},
  keywords = {Decision support systems, Duality, Optimization methodology, Pattern classification, Support vector machine (SVM)},
  url      = {https://shiliangsun.github.io/pubs/ROMSVM.pdf}
}

@techreport{ShohamMultiagentFoundations,
  title    = {{Multiagent Systems: Algorithmic, Game-Theoretic, and Logical Foundations}},
  author   = {Shoham, Yoav and Leyton-Brown, Kevin},
  keywords = {algorithms, auctions, communication, competition, cooperation, distributed problem solving, game theory, learning, logic, mechanism design, social choice},
  url      = {http://www.masfoundations.org.}
}

@article{Singla2018,
  title   = {{Memory-based Deep Reinforcement Learning for Obstacle Avoidance in UAV with Limited Environment Knowledge}},
  author  = {Singla, Abhik and Padakandla, Sindhu and Bhatnagar, Shalabh},
  year    = {2018},
  month   = {11},
  arxivid = {1811.03307},
  url     = {http://arxiv.org/abs/1811.03307}
}

@inproceedings{Sirigineedi2010DecentralisedApproach,
  title     = {{Decentralised cooperative aerial surveillance for harbour security: A formal verification approach}},
  author    = {Sirigineedi, Gopinadh and Tsourdos, Antonios and White, Brian A. and Silson, Peter},
  booktitle = {2010 IEEE Globecom Workshops, GC'10},
  year      = {2010},
  pages     = {1831--1835},
  doi       = {10.1109/GLOCOMW.2010.5700258},
  isbn      = {9781424488650}
}

@article{Solihin2011,
  title   = {{Tuning of PID Controller Using Particle Swarm Optimization (PSO)}},
  author  = {Solihin, Mahmud Iwan and Tack, Lee Fook and Kean, Moey Leap},
  journal = {International Journal on Advanced Science, Engineering and Information Technology},
  year    = {2011},
  number  = {4},
  pages   = {458},
  volume  = {1},
  doi     = {10.18517/ijaseit.1.4.93},
  issn    = {2460-6952},
  url     = {http://ijaseit.insightsociety.org/index.php?option=com_content&view=article&id=9&Itemid=1&article_id=93}
}

@inproceedings{Spaan2006DecentralizedAgents,
  title     = {{Decentralized planning under uncertainty for teams of communicating agents}},
  author    = {Spaan, Matthijs T.J. and Gordon, Geoffrey J. and Vlassis, Nikos},
  booktitle = {Proceedings of the International Conference on Autonomous Agents},
  year      = {2006},
  pages     = {249--256},
  volume    = {2006},
  doi       = {10.1145/1160633.1160678},
  isbn      = {1595933034},
  keywords  = {Artificial intelligence, Cooperative multiagent systems, Decentralized POMDPs, Planning under uncertainty}
}

@inproceedings{Stancliff2009PlanningAllocation,
  title     = {{Planning to fail - Reliability needs to be considered a priori in multirobot task allocation}},
  author    = {Stancliff, Stephen B. and Dolan, John and Trebi-Ollennu, Ashitey},
  booktitle = {Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics},
  year      = {2009},
  pages     = {2362--2367},
  doi       = {10.1109/ICSMC.2009.5346359},
  isbn      = {9781424427949},
  issn      = {1062922X},
  keywords  = {Multirobot systems, Reliability, Task allocation}
}

@inproceedings{Subramanian2012,
  title     = {{Obstacle avoidance using multi-point potential field approach for an underactuated flat-fish type AUV in dynamic environment}},
  author    = {Subramanian, Saravanakumar and George, Thomas and Thondiyath, Asokan},
  booktitle = {Communications in Computer and Information Science},
  year      = {2012},
  pages     = {20--27},
  volume    = {330 CCIS},
  doi       = {10.1007/978-3-642-35197-6{\_}3},
  isbn      = {9783642351969},
  issn      = {18650929},
  keywords  = {AUV, dynamic model, obstacle avoidance, potential field, trajectory planning}
}

@article{Subramanian2019,
  title    = {{Reinforcement learning in stationary mean-field games}},
  author   = {Subramanian, Jayakumar},
  journal  = {Proceedings of the 18th International Conference of Autonomous Agents and Multi-Agent Systems, AAMAS'19},
  year     = {2019},
  number   = {Aamas},
  pages    = {251--259},
  volume   = {9},
  abstract = {Multi-agent reinforcement learning has made significant progress in recent years, but it remains a hard problem. Hence, one often resorts to developing learning algorithms for specific classes of multi-agent systems. In this paper we study reinforcement learning in a specific class of multi-agent systems systems called mean-field games. In particular, we consider learning in stationary mean-field games. We identify two different solution concepts—stationary mean-field equilibrium and stationary mean-field social-welfare optimal policy—for such games based on whether the agents are non-cooperative or cooperative, respectively. We then generalize these solution concepts to their local variants using bounded ra- tionality based arguments. For these two local solution concepts, we present two reinforcement learning algorithms. We show that the algorithms converge to the right solution under mild technical conditions and demonstrate this using two numerical examples.},
  file     = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Subramanian, Mahajan - 2019 - Reinforcement Learning in Stationary Mean-field Games.pdf:pdf},
  keywords = {bounded rationality,mean-field games,multi-agent reinforcement learning,stationary},
  url      = {www.ifaamas.org}
}

@book{Sutton2018,
  title     = {{Reinforcement Learning: An Introduction}},
  author    = {Sutton, R and Barto, A},
  publisher = {MIT Press},
  year      = {2018},
  url       = {http://incompleteideas.net/book/the-book-2nd.html}
}

@inproceedings{Symington2014,
  title     = {{Simulating quadrotor UAVs in outdoor scenarios}},
  author    = {Symington, Andrew and De Nardi, Renzo and Julier, Simon and Hailes, Stephen},
  booktitle = {2014 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  year      = {2014},
  month     = {9},
  pages     = {3382--3388},
  publisher = {IEEE},
  doi       = {10.1109/IROS.2014.6943033},
  isbn      = {978-1-4799-6934-0},
  url       = {http://ieeexplore.ieee.org/document/6943033/}
}

@article{Tai2016,
  title   = {{A Survey of Deep Network Solutions for Learning Control in Robotics: From Reinforcement to Imitation}},
  author  = {Tai, Lei and Zhang, Jingwei and Liu, Ming and Boedecker, Joschka and Burgard, Wolfram},
  year    = {2016},
  month   = {12},
  arxivid = {1612.07139},
  url     = {http://arxiv.org/abs/1612.07139}
}

@article{Tarapore2019FaultDetection,
  title     = {{Fault Detection in a Swarm of Physical Robots Based on Behavioral Outlier Detection}},
  author    = {Tarapore, Danesh and Timmis, Jon and Christensen, Anders Lyhne},
  journal   = {IEEE Transactions on Robotics},
  year      = {2019},
  month     = {8},
  pages     = {1--7},
  doi       = {10.1109/tro.2019.2929015},
  issn      = {1552-3098},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)}
}

@techreport{TheEquation,
  title = {{The Wave Equation}},
  url   = {http://ocw.mit.edu/terms.}
}

@misc{TheSpeed,
  title = {{The annual variability of wind speed}},
  url   = {https://www.wind-energy-the-facts.org/the-annual-variability-of-wind-speed.html}
}

@inproceedings{Thomas2005Multi-robotScenarios,
  title     = {{Multi-robot task allocation in lunar mission construction scenarios}},
  author    = {Thomas, George and Howard, Ayanna M. and Williams, Andrew B. and Moore-Alston, Aryen},
  booktitle = {Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics},
  year      = {2005},
  pages     = {518--523},
  volume    = {1},
  doi       = {10.1109/icsmc.2005.1571198},
  issn      = {1062922X},
  keywords  = {Multi-agent coordination, Multi-robot systems, Space exploration, Task allocation}
}

@techreport{Tomlin2000ASystems,
  title    = {{A Game Theoretic Approach to Controller Design for Hybrid Systems}},
  author   = {Tomlin, Claire J and Lygeros, John and Shankar Sastry, S},
  year     = {2000},
  keywords = {Aircraft control, air-traffic control, automated high-ways, game theory, hybrid automata, optimal control}
}

@article{Torreno2017CooperativeSurvey,
  title     = {{Cooperative multi-Agent planning: A survey}},
  author    = {Torreno, Alejandro and Onaindia, Eva and Komenda, Antoní N. and S Tolba, Michal},
  journal   = {ACM Computing Surveys},
  year      = {2017},
  month     = {11},
  number    = {6},
  volume    = {50},
  doi       = {10.1145/3128584},
  issn      = {15577341},
  keywords  = {Distribution, Multi-Agent heuristic functions, Planning and coordination strategies, Privacy preservation},
  publisher = {Association for Computing Machinery}
}

@techreport{Track2018ApprenticeshipTask,
  title    = {{Apprenticeship Bootstrapping: Inverse Reinforcement Learning in a Multi-Skill UAV-UGV Coordination Task}},
  author   = {Track, Robotics and Nguyen, Hung The and Garratt, Matthew and Bui, Lam Thu and Abbass, Hussein and Lam, Thu and Bui, Hussein Abbass},
  year     = {2018},
  keywords = {Apprenticeship Learning, Deep Q-learning, Ground-Air Interaction, Inverse Reinforcement Learning, UAVs, UGVs},
  url      = {www.ifaamas.org}
}

@techreport{TrackExplainableReview,
  title    = {{Explainable Agents and Robots: Results from a Systematic Literature Review}},
  author   = {Track, Robotics and Anjomshoae, Sule and Najjar, Amro and Calvaresi, Davide and Fr{\"{a}}mling, Kary},
  keywords = {Explainable AI, autonomous agents, goal-based XAI, human-robot interaction},
  url      = {www.ifaamas.org}
}

@misc{TrackingKingdom,
  title = {{Tracking a Green Ball - MATLAB {\&}amp; Simulink Example - MathWorks United Kingdom}},
  url   = {https://uk.mathworks.com/help/supportpkg/raspberrypiio/examples/track-a-green-ball.html}
}

@article{Tuyls2006AnGames,
  title    = {{An Evolutionary Dynamical Analysis of Multi-Agent Learning in Iterated Games}},
  author   = {Tuyls, Karl and Jan ', Pieter and Hoen, T and Nl, Hoen@cwi and Vanschoenwinkel, Bram},
  journal  = {Autonomous Agents and Multi-Agent Systems},
  year     = {2006},
  pages    = {115--153},
  volume   = {12},
  doi      = {10.1007/s10458-005-3783-9},
  keywords = {COllective INtelligence, Evolutionary Game Theory, iterated games, multi-agent systems, reinforcement learning}
}

@techreport{TuylsLectureScience,
  title  = {{Lecture Notes in Artificial Intelligence 3898 Subseries of Lecture Notes in Computer Science}},
  author = {Tuyls, Karl and Jan, Pieter and Verbeeck, Katja and Sen, Sandip}
}

@misc{UnderstandingRobotics,
  title = {{Understanding Euler Angles | CH Robotics}},
  url   = {http://www.chrobotics.com/library/understanding-euler-angles}
}

@misc{UsingKaggle,
  title = {{Using Categorical Data with One Hot Encoding | Kaggle}},
  url   = {https://www.kaggle.com/dansbecker/using-categorical-data-with-one-hot-encoding}
}

@misc{UsingKumar,
  title = {{Using Support Vector Machines Effectively | Neeraj Kumar}},
  url   = {https://neerajkumar.org/writings/svm/}
}

@techreport{VallamDynamicFormat,
  title     = {{Dynamic Particle Allocation to Solve Interactive POMDP Models for Social Decision Making AAMAS; ACM proceedings; L A T E X; text tagging ACM Reference Format}},
  author    = {Vallam, Rohith Dwarakanath and Ahuja, Sarthak and Shravan, Surya and Sajja, Kumar and Chaudhuri, Ritwik and Pimplikar, Rakesh and Mukherjee, Kushal and Narayanam, Ramasuri and Parija, Gyana and Dwarakanath Vallam, Rohith},
  keywords  = {AAMAS, ACM proceedings, LaTeX, text tagging},
  publisher = {AAMAS},
  url       = {www.ifaamas.org}
}

@article{VanParys2017,
  abstract  = {This work presents a novel distributed model predictive control (DMPC) strategy for controlling multi-vehicle systems moving in formation. The vehicles' motion trajectories are parameterized as polynomial splines and by exploiting the properties of the B-spline basis functions, constraints on the trajectories are efficiently enforced. The computations for solving the resulting optimization problem are distributed among the agents by the Alternating Direction Method of Multipliers (ADMM). In order to reduce the computation time and the amount of inter-vehicle interaction, only one ADMM iteration is performed per control update. In this way the method converges over the subsequent control updates. Simulations for various nonholonomic vehicle types and an experimental validation on in-house developed robotic platforms prove the capability of the proposed approach. A supporting software toolbox is provided that implements the proposed approach and that facilitates its use.},
  author    = {{Van Parys}, Ruben and Pipeleers, Goele},
  doi       = {10.1016/j.robot.2017.08.009},
  issn      = {09218890},
  journal   = {Robotics and Autonomous Systems},
  keywords  = {Alternating Direction Method of Multipliers (ADMM),B-spline,Distributed model predictive control (DMPC),Nonholonomic multi-vehicle system},
  month     = {nov},
  pages     = {144--152},
  publisher = {Elsevier B.V.},
  title     = {{Distributed MPC for multi-vehicle systems moving in formation}},
  volume    = {97},
  year      = {2017}
}

@article{Vaughan2008,
  title    = {{Massively multi-robot simulation in stage}},
  author   = {Vaughan, Richard},
  journal  = {Swarm Intell},
  year     = {2008},
  pages    = {189--208},
  volume   = {2},
  doi      = {10.1007/s11721-008-0014-4},
  keywords = {Multi-robot {\textperiodcentered}, Player/stage, Simulation {\textperiodcentered}, Stage {\textperiodcentered}, Swarm {\textperiodcentered}},
  url      = {http://dx.doi.org/10.1007/s11721-008-0014-4}
}

@article{Venkat2006,
  abstract = {Most standard model predictive control (MPC) implementations partition the plant into sev- eral units and apply MPC individually to these units. It is known that such a completely de- centralized control strategy may result in unacceptable control performance, especially if the units interact strongly. Completely centralized control of large, networked systems is viewed by most practitioners as impractical and unrealistic. In this dissertation, a new framework for distributed, linear MPC with guaranteed closed-loop stability and performance properties is presented. A modeling framework that quantifies the interactions among subsystems is em- ployed. One may think that modeling the interactions between subsystems and exchanging trajectory information among MPCs (communication) is sufficient to improve controller per- formance. We show that this idea is incorrect and may not provide even closed-loop stability. Acooperative distributedMPCframework, in which the objective functions of the local MPCs are modified to achieve systemwide control objectives is proposed. This approach allows prac- titioners to tackle large, interacting systems by building on localMPCsystems already in place. The iterations generated by the proposed distributed MPC algorithm are systemwide feasible, and the controller based on any intermediate termination of the algorithm is closed-loop stable. These two features allow the practitioner to terminate the distributed MPC algorithm at the end of the sampling interval, even if convergence is not achieved. If iterated to conver- gence, the distributed MPC algorithm achieves optimal, centralized MPC control. Building on results obtained under state feedback, we tackle next, distributed MPC under output feedback. Two distributed estimator design strategies are proposed. Each es- timator is stable and uses only local measurements to estimate subsystem states. Feasibility and closed-loop stability for all distributed MPC algorithm iteration numbers are established for the distributed estimator-distributed regulator assembly in the case of decaying estimate error. A subsystem-based disturbance modeling framework to eliminate steady-state offset due to modeling errors and unmeasured disturbances is presented. Conditions to verify suit- ability of chosen local disturbance models are provided. A distributed target calculation al- gorithm to compute steady-state targets locally is proposed. All iterates generated by the distributed target calculation algorithm are feasible steady states. Conditions under which the proposed distributed MPC framework, with distributed estimation, distributed target cal- culation and distributed regulation, achieves offset-free control at steady state are described. Finally, the distributed MPC algorithm is augmented to allow asynchronous optimization and asynchronous feedback. Asynchronous feedback distributed MPC enables the practitioner to achieve performance superior to centralized MPC operated at the slowest sampled rate. Ex- amples from chemical engineering, electrical engineering and civil engineering are examined and benefits of employing the proposed distributed MPC paradigm are demonstrated.},
  author   = {Venkat, Aswin},
  file     = {::},
  journal  = {Philosophy},
  pages    = {352},
  title    = {{Distributed model predictive control: Theory and applications}},
  url      = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.101.410{\&}rep=rep1{\&}type=pdf{\%}5Cnhttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.101.410{\%}7B{\&}{\%}7Drep=rep1{\%}7B{\&}{\%}7Dtype=pdf},
  year     = {2006}
}

@article{Virgili-Llop2019AttitudeShifting,
  title     = {{Attitude stabilization of spacecraft in very low earth orbit by center-of-mass shifting}},
  author    = {Virgili-Llop, Josep and Polat, Halis C. and Romano, Marcello},
  journal   = {Frontiers Robotics AI},
  year      = {2019},
  number    = {FEB},
  volume    = {6},
  doi       = {10.3389/frobt.2019.00007},
  issn      = {22969144},
  keywords  = {Aerodynamic disturbance, Attitude control, Attitude stabilization, CubeSat, Movable masses, Shifting masses, Spacecraft aerodynamics, Very Low Earth Orbit},
  publisher = {Frontiers Media S.A.}
}

@techreport{Vitelli,
  title  = {{CARMA: A Deep Reinforcement Learning Approach to Autonomous Driving}},
  author = {Vitelli, Matt and Nayebi, Aran}
}

@article{Wang2018,
  title   = {{Deep Reinforcement Learning for Autonomous Driving}},
  author  = {Wang, Sen and Jia, Daoyuan and Weng, Xinshuo},
  year    = {2018},
  month   = {11},
  arxivid = {1811.11329},
  url     = {http://arxiv.org/abs/1811.11329}
}

@techreport{Wang2019EvolvingBehavior,
  title     = {{Evolving Intrinsic Motivations for Altruistic Behavior}},
  author    = {Wang, Jane X and Hughes, Edward and Fernando, Chrisantha and Czarnecki, Wojciech M and Du{\'{e}}{\~{n}}ez-Guzm{\'{a}}n, Edgar A and Leibo, Joel Z and Czar-necki, Wojciech M},
  year      = {2019},
  booktitle = {IFAAMAS},
  keywords  = {altruism, evolution, multi-agent, social dilemmas},
  url       = {www.ifaamas.org},
  volume    = {10}
}

@article{Weisstein,
  title     = {{Green's Theorem}},
  author    = {Weisstein, Eric W.},
  keywords  = {15, 15A72, 26B, Mathematics:Algebra:Vector Algebra, Mathematics:Calculus and Analysis:Calculus:Multiva},
  publisher = {Wolfram Research, Inc.},
  url       = {http://mathworld.wolfram.com/GreensTheorem.html}
}

@techreport{Weyns2018EngineeringSystems,
  title     = {{Engineering Multi-Agent Systems}},
  author    = {Weyns, Danny and Mascardi, Viviana and Ricci, Alessandro},
  year      = {2018},
  booktitle = {EMAS},
  doi       = {10.1007/978-3-030-25693-7},
  url       = {http://www.springer.com/series/1244}
}

@incollection{Wingate2012,
  title     = {{Predictively defined representations of state}},
  author    = {Wingate, David},
  booktitle = {Adaptation, Learning, and Optimization},
  publisher = {Springer Verlag},
  year      = {2012},
  pages     = {415--439},
  volume    = {12},
  abstract  = {The concept of state is central to dynamical systems. In any timeseries problem—such as filtering, planning or forecasting—models and algorithms summarize important information from the past into some sort of state variable. In this chapter, we start with a broad examination of the concept of state, with emphasis on the fact that there are many possible representations of state for a given dynamical system, each with different theoretical and computational properties. We then focus on models with predictively defined representations of state that represent state as a set of statistics about the short-term future, as opposed to the classic approach of treating state as a latent, unobservable quantity. In other words, the past is summarized into predictions about the actions and observations in the short-term future, which can be used to make further predictions about the infinite future.While this representational idea applies to any dynamical system problem, it is particularly useful in a model-based RL context, when an agent must learn a representation of state and a model of system dynamics online: because the representation (and hence all of the model's parameters) are defined using only statistics of observable quantities, their learning algorithms are often straightforward and have attractive theoretical properties. Here, we survey the basic concepts of predictively defined representations of state, important auxiliary constructs (such as the systems dynamics matrix), and theoretical results on their representational power and learnability.},
  doi       = {10.1007/978-3-642-27645-3_13},
  issn      = {18674542},
  keywords  = {Covariance,Entropy,Posit,Tated,Transportation}
}

@inproceedings{Yagan2007CoordinatedControl,
  title     = {{Coordinated reinforcement learning for decentralized optimal control}},
  author    = {Yagan, Daniel and Tham, Chen Khong},
  booktitle = {Proceedings of the 2007 IEEE Symposium on Approximate Dynamic Programming and Reinforcement Learning, ADPRL 2007},
  year      = {2007},
  pages     = {296--302},
  doi       = {10.1109/ADPRL.2007.368202},
  isbn      = {1424407060}
}

@inproceedings{Yaghmaie2013,
  title     = {{A new method for mobile robot navigation in dynamic environment: Escaping algorithm}},
  author    = {Yaghmaie, F. Adib and Mobarhani, A. and Taghirad, H. D.},
  booktitle = {2013 First RSI/ISM International Conference on Robotics and Mechatronics (ICRoM)},
  year      = {2013},
  month     = {2},
  pages     = {212--217},
  publisher = {IEEE},
  doi       = {10.1109/ICRoM.2013.6510107},
  isbn      = {978-1-4673-5811-8},
  url       = {http://ieeexplore.ieee.org/document/6510107/}
}

@techreport{Yang2018,
  title         = {{Mean Field Multi-Agent Reinforcement Learning}},
  author        = {Yang, Yaodong and Luo, Rui and Li, Minne and Zhou, Ming and Zhang, Weinan and Wang, Jun},
  year          = {2018},
  abstract      = {Existing multi-agent reinforcement learning methods are limited typically to a small number of agents. When the agent number increases largely, the learning becomes intractable due to the curse of the dimensionality and the exponential growth of agent interactions. In this paper, we present Mean Field Reinforcement Learning where the interactions within the population of agents are approximated by those between a single agent and the average effect from the overall population or neighboring agents; the interplay between the two entities is mutually reinforced: the learning of the individual agent's optimal policy depends on the dynamics of the population, while the dynamics of the population change according to the collective patterns of the individual policies. We develop practical mean field Q-learning and mean field Actor-Critic algorithms and analyze the convergence of the solution to Nash equilibrium. Experiments on Gaussian squeeze, Ising model, and battle games justify the learning effectiveness of our mean field approaches. In addition, we report the first result to solve the Ising model via model-free reinforcement learning methods.},
  archiveprefix = {arXiv},
  arxivid       = {1802.05438v4},
  eprint        = {1802.05438v4},
  file          = {:home/aamalh/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2018 - Mean Field Multi-Agent Reinforcement Learning.pdf:pdf}
}

@techreport{YangNoRML:Learning,
  title     = {{NoRML: No-Reward Meta Learning}},
  author    = {Yang, Yuxiang and Caluwaerts, Ken and Iscen, Atil and Tan, Jie and Finn, Chelsea},
  booktitle = {IFAAMAS},
  keywords  = {Deep Learning, Meta-Learning, Reinforcement Learning},
  url       = {www.ifaamas.org},
  volume    = {9}
}

@article{Yin2014,
  abstract  = {A simplified model predictive control algorithm is designed for discrete-time Markov jump systems with mixed uncertainties. The mixed uncertainties include model polytope uncertainty and partly unknown transition probability. The simplified algorithm involves finite steps. Firstly, in the previous steps, a simplified mode-dependent predictive controller is presented to drive the state to the neighbor area around the origin. Then the trajectory of states is driven as expected to the origin by the final-step mode-independent predictive controller. The computational burden is dramatically cut down and thus it costs less time but has the acceptable dynamic performance. Furthermore, the polyhedron invariant set is utilized to enlarge the initial feasible area. The numerical example is provided to illustrate the efficiency of the developed results. {\textcopyright} 2014 Yanyan Yin et al.},
  author    = {Yin, Yanyan and Liu, Yanqing and Karimi, Hamid R.},
  doi       = {10.1155/2014/475808},
  file      = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Yin, Liu, Karimi - 2014 - A simplified predictive control of constrained Markov jump system with mixed uncertainties.pdf:pdf},
  issn      = {16870409},
  journal   = {Abstract and Applied Analysis},
  publisher = {Hindawi Publishing Corporation},
  title     = {{A simplified predictive control of constrained Markov jump system with mixed uncertainties}},
  volume    = {2014},
  year      = {2014}
}

@article{Zadeh1965,
  title     = {{Fuzzy sets}},
  author    = {Zadeh, L.A.},
  journal   = {Information and Control},
  year      = {1965},
  month     = {6},
  number    = {3},
  pages     = {338--353},
  volume    = {8},
  doi       = {10.1016/S0019-9958(65)90241-X},
  issn      = {0019-9958},
  publisher = {Academic Press},
  url       = {https://www.sciencedirect.com/science/article/pii/S001999586590241X}
}

@article{Zahadat2016DivisionInhibition,
  title     = {{Division of labor in a swarm of autonomous underwater robots by improved partitioning social inhibition}},
  author    = {Zahadat, Payam and Schmickl, Thomas},
  journal   = {Adaptive Behavior},
  year      = {2016},
  number    = {2},
  pages     = {87--101},
  volume    = {24},
  doi       = {10.1177/1059712316633028},
  issn      = {17412633},
  keywords  = {Swarm intelligence, adaptive division of labor, bio-inspired algorithm, distributed partitioning, social inhibition, swarm robotics},
  publisher = {SAGE Publications Ltd}
}

@inproceedings{Zhang2012AnTeams,
  title     = {{An efficient stochastic clustering auction for heterogeneous robot teams}},
  author    = {Zhang, Kai and Collins, Emmanuel G. and Barbu, Adrian},
  booktitle = {2012 IEEE International Conference on Robotics and Automation},
  year      = {2012},
  month     = {5},
  pages     = {4806--4813},
  publisher = {IEEE},
  doi       = {10.1109/ICRA.2012.6224588},
  isbn      = {978-1-4673-1405-3},
  url       = {http://ieeexplore.ieee.org/document/6224588/}
}

@techreport{Zhao2015,
  title    = {{3D Obstacle Avoidance for Unmanned Autonomous System (UAS)}},
  author   = {Zhao, Lin},
  year     = {2015},
  keywords = {Autonomous, Obstacle Aviodance, UAS, three-dimensional},
  url      = {http://digitalscholarship.unlv.edu/thesesdissertationshttp://digitalscholarship.unlv.edu/thesesdissertations/2507}
}

@article{Zheng2017,
  abstract  = {This paper presents a distributed model predictive control (DMPC) algorithm for heterogeneous vehicle platoons with unidirectional topologies and a priori unknown desired set point. The vehicles (or nodes) in a platoon are dynamically decoupled but constrained by spatial geometry. Each node is assigned a local open-loop optimal control problem only relying on the information of neighboring nodes, in which the cost function is designed by penalizing on the errors between the predicted and assumed trajectories. Together with this penalization, an equality-based terminal constraint is proposed to ensure stability, which enforces the terminal states of each node in the predictive horizon equal to the average of its neighboring states. By using the sum of local cost functions as a Lyapunov candidate, it is proved that asymptotic stability of such a DMPC can be achieved through an explicit sufficient condition on the weights of the cost functions. Simulations with passenger cars demonstrate the effectiveness of the proposed DMPC.},
  author    = {Zheng, Yang and Li, Shengbo Eben and Li, Keqiang and Borrelli, Francesco and Hedrick, J. Karl},
  doi       = {10.1109/TCST.2016.2594588},
  issn      = {10636536},
  journal   = {IEEE Transactions on Control Systems Technology},
  keywords  = {Autonomous vehicle,distributed control,graph theory heterogeneous platoon,model predictive control (MPC)},
  month     = {may},
  number    = {3},
  pages     = {899--910},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  title     = {{Distributed Model Predictive Control for Heterogeneous Vehicle Platoons under Unidirectional Topologies}},
  volume    = {25},
  year      = {2017}
}

