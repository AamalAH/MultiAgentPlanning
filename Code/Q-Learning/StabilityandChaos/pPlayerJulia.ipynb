{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using SparseArrays\n",
    "using PyCall\n",
    "using Plots\n",
    "using IterTools\n",
    "using Distributions\n",
    "using ProgressMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py\"\"\"\n",
    "def allActions(nAct, nPlayers):\n",
    "    import itertools\n",
    "    idX = list(itertools.product(list(range(1, nAct + 1)), repeat=nPlayers)) * nPlayers\n",
    "    return idX\n",
    "\"\"\"\n",
    "allActions(nAct, nPlayers) = py\"allActions\"(nAct, nPlayers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function generateCorrespondences(nActions, nPlayers)\n",
    "    nElements = nActions^nPlayers\n",
    "    Actions = allActions(nActions, nPlayers)\n",
    "    allCombos = [[findall(x -> x==tuple(circshift([j for j in Actions[i]], -1*(p))...), Actions)[p+1] for p=0:nPlayers-1] for i=1:nElements]\n",
    "    \n",
    "    return Actions, allCombos\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function generateGames(Gamma, nSim, allCombos, nActions, nPlayers)\n",
    "    \"\"\"\n",
    "    Create Covariance Matrix from Gamma\n",
    "    \n",
    "    Return Random Payoff Matrices: nPlayers*nElements x nSim\n",
    "    \n",
    "    \"\"\"\n",
    "    nElements = nActions^nPlayers\n",
    "    cov = Matrix(1.0I, nPlayers * nElements, nPlayers * nElements)\n",
    "    \n",
    "    \"\"\" Cycle through each of the combinations and assign them the appropriate Gamma \"\"\"\n",
    "    for c in allCombos\n",
    "        cov[c[1], c[2:end]] .= Gamma/(nPlayers-1)\n",
    "        cov[c[2:end], c[1]] .= Gamma/(nPlayers-1)\n",
    "    end\n",
    "        \n",
    "    \"\"\" draw from a Gaussian using this covariance matrix \"\"\"\n",
    "\n",
    "    return rand(MvNormal(zeros(nPlayers * nElements), cov), nSim)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function getActionProbs(qValues, agentParams)\n",
    "    \"\"\"\n",
    "    qValues: nPlayer x nActions x nSim\n",
    "    return: nPlayer x nActions x nSim\n",
    "    \"\"\"\n",
    "    alpha, tau, gamma = agentParams\n",
    "    \n",
    "    return exp.(tau * qValues)./sum(exp.(tau * qValues), dims=2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function chooseActions(actionProbs, gameParams)\n",
    "    \"\"\"\n",
    "    arg: actionProbs: nPlayer x nActions x nSim\n",
    "    return: nPlayer x nSim\n",
    "    \"\"\"\n",
    "    \n",
    "    nSim, nPlayers, nActions = gameParams\n",
    "\n",
    "    return [[rand(Bernoulli(actionProbs[p, 1, s])) + 1 for p=1:nPlayers] for s=1:nSim]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function findPayoffs(choices, gameParams, corr, actions, payoffs)\n",
    "    nSim, nPlayers, nActions = gameParams\n",
    "    \n",
    "    choiceIdx = [corr[findall(x -> x==tuple(choices[s]...), actions)[1]] for s=1:nSim]\n",
    "    return [payoffs[choiceIdx[s], s] for s=1:nSim]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function qUpdate!(qValues, payoffs, gameParams, agentParams, correlations, actions)\n",
    "\n",
    "    nSim, nPlayers, nActions = gameParams\n",
    "    alpha, tau, gamma = agentParams\n",
    "    \n",
    "    actionProbs = getActionProbs(qValues, agentParams)\n",
    "    bChoice = chooseActions(actionProbs, gameParams)\n",
    "    rewards = findPayoffs(bChoice, gameParams, correlations, actions, payoffs)\n",
    "\n",
    "    update = [rewards[s] - diag(qValues[:, bChoice[s], s]) + gamma * findmax(qValues[:, :, s], dims=2)[1] for s=1:nSim]\n",
    "    \n",
    "    for s = 1:nSim\n",
    "        for p = 1:nPlayers\n",
    "            qValues[p, bChoice[s][p], s] += alpha * update[s][p]\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function checkminMix(actionTracker, nSim, tol)\n",
    "    T = hcat([reshape(actionTracker[i], nPlayers * nSim * nActions) for i=1:length(actionTracker)]...)\n",
    "    relDiff = (findmax(T, dims=2)[1] - findmin(T, dims=2)[1])./findmin(T, dims=2)[1]\n",
    "\n",
    "    part = [relDiff[i*(nActions*nPlayers)+1:(i+1)*(nActions*nPlayers)] for i=0:nSim-1]\n",
    "    bRemove = [length(findall(x->x<0.01, p))>=length(p) for p in part]\n",
    "    \n",
    "    return bRemove\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "tau = 0.05\n",
    "gamma = 0.1\n",
    "\n",
    "initnSim = 15\n",
    "nPlayers = 3\n",
    "nActions = 5\n",
    "\n",
    "Gamma = -0.5\n",
    "\n",
    "# gameParams = (nSim, nPlayers, nActions)\n",
    "# agentParams = (alpha, tau, gamma)\n",
    "\n",
    "t0 = 5000\n",
    "actions, corr = generateCorrespondences(nActions, nPlayers)\n",
    "\n",
    "nIter = trunc(Int, 5e4)\n",
    "\n",
    "allconv = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@showprogress for a in LinRange(1e-2, 5e-2, 20)\n",
    "    global alpha = a\n",
    "    for Gamma in LinRange(-1, 0, 20)\n",
    "        global nSim = initnSim\n",
    "    \n",
    "        qValues = rand(nPlayers, nActions, nSim)\n",
    "        payoffs = generateGames(Gamma, nSim, corr, nActions, nPlayers)\n",
    "        actionTracker = []\n",
    "\n",
    "        converged = 0\n",
    "\n",
    "        for cIter = 1:nIter\n",
    "\n",
    "            if cIter==t0\n",
    "                actionTracker = []\n",
    "            end    \n",
    "\n",
    "            if cIter%t0==0 && cIter!=0 && cIter!=t0\n",
    "                bRemove = checkminMix(actionTracker, nSim, 1e-2)\n",
    "                removeIdx = findall(bRemove)\n",
    "                qValues = qValues[:, :, setdiff(1:end, removeIdx)]\n",
    "                payoffs = payoffs[:, setdiff(1:end, removeIdx)]\n",
    "                nSim -= length(removeIdx)\n",
    "                converged += length(removeIdx)\n",
    "\n",
    "                actionTracker = [] \n",
    "            end\n",
    "\n",
    "            if nSim <= 0\n",
    "                break\n",
    "            end\n",
    "\n",
    "            gameParams = (nSim, nPlayers, nActions)\n",
    "            agentParams = (alpha, tau, gamma)\n",
    "\n",
    "            qUpdate!(qValues, payoffs, gameParams, agentParams, corr, actions)\n",
    "            append!(actionTracker, [getActionProbs(qValues, agentParams)])\n",
    "\n",
    "        end\n",
    "        append!(allconv, [alpha, Gamma, converged/initnSim])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = reshape(allconv[3:3:end], 20, 20)[end:-1:1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py\"\"\"\n",
    "def plotHeatmap(a):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import numpy as np\n",
    "    ax = sns.heatmap(a, vmin=0, vmax=1, xticklabels=np.linspace(1, 5, num=20).round(2), yticklabels=np.linspace(-1, 0, num=20)[-1::-1].round(2))\n",
    "    ax.set(xlabel=\"α (x 1e-2)\", ylabel=\"Γ\")\n",
    "    plt.show()\n",
    "\"\"\"\n",
    "\n",
    "plotHeatmap(a) = py\"plotHeatmap\"(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot\n",
    "plotHeatmap(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qValues = rand(nPlayers, nActions, nSim)\n",
    "payoffs = generateGames(Gamma, nSim, corr, nActions, nPlayers)\n",
    "\n",
    "probs = getActionProbs(qValues, (0.05, 1, 1))\n",
    "bChoice = [[rand(Bernoulli(probs[p, 1, s])) + 1 for p=1:nPlayers] for s=1:nSim]\n",
    "\n",
    "choiceIdx = [corr[findall(x -> x==tuple(bChoice[s]...), actions)[1]] for s=1:nSim]\n",
    "\n",
    "rewards = [payoffs[choiceIdx[s], s] for s=1:nSim]\n",
    "\n",
    "update = [rewards[s] - diag(qValues[:, bChoice[s], s]) + gamma * findmax(qValues[:, :, s], dims=2)[1] for s=1:nSim]\n",
    "# [i for i in bChoice[1]]\n",
    "for s = 1:nSim\n",
    "    for p = 1:nPlayers\n",
    "        qValues[p, bChoice[s][p], s] += alpha * update[s][p]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 0.05\n",
    "alpha = 0.02\n",
    "gamma = 0.1\n",
    "\n",
    "initnSim = 20\n",
    "nActions = 2\n",
    "\n",
    "t0 = 25000\n",
    "\n",
    "nIter = trunc(Int, 5e4)\n",
    "\n",
    "allVars = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function getVariance(actionTracker)\n",
    "    \n",
    "\n",
    "    T = hcat([reshape(actionTracker[i], nPlayers * nSim * nActions) for i=1:length(actionTracker)]...)\n",
    "    var = ((1 /length(actionTracker)) * sum(T.^2, dims=2)) - ((1/length(actionTracker)) * sum(T, dims=2)).^2\n",
    "    part = [var[i*(nActions*nPlayers)+1:(i+1)*(nActions*nPlayers)] for i=0:nSim-1]\n",
    "\n",
    "    return mean([mean(p) for p in part])\n",
    "\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@showprogress for p = 3:12\n",
    "    global nPlayers = p\n",
    "    actions, corr = generateCorrespondences(nActions, nPlayers)\n",
    "    \n",
    "    varGamma = []\n",
    "        @show nPlayers\n",
    "    for Gamma in LinRange(-1, 0, 10)\n",
    "        \n",
    "        global nSim = initnSim\n",
    "\n",
    "        qValues = rand(nPlayers, nActions, nSim)\n",
    "        payoffs = generateGames(Gamma, nSim, corr, nActions, nPlayers)\n",
    "\n",
    "        actionTracker = []\n",
    "\n",
    "        for cIter = 1:nIter\n",
    "                \n",
    "            gameParams = (nSim, nPlayers, nActions)\n",
    "            agentParams = (alpha, tau, gamma)\n",
    "\n",
    "            qUpdate!(qValues, payoffs, gameParams, agentParams, corr, actions)\n",
    "            \n",
    "            if cIter > t0\n",
    "                append!(actionTracker, [getActionProbs(qValues, agentParams)])\n",
    "            end\n",
    "\n",
    "        end\n",
    "        append!(varGamma, getVariance(actionTracker))\n",
    "    end\n",
    "    \n",
    "    append!(allVars, [mean(varGamma), std(varGamma)])\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
