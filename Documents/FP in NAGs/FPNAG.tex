\documentclass{article}
\usepackage[margin=2cm]{geometry}
\usepackage{amsmath, amsfonts, amsthm}
\usepackage{xcolor}
\usepackage{enumerate}

\theoremstyle{definition}
\newtheorem*{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{assumption}{Assumption}

\newcommand{\ah}[1]{\textcolor{blue}{AH: \textit{#1}}}
\newcommand{\fb}[1]{\textcolor{red}{FB: \textit{#1}}}

\newcommand{\agentset}{\mathcal{N}}
\newcommand{\edgeset}{\mathcal{E}}
\newcommand{\weightset}{W}

\newcommand{\actionset}[1]{S^{#1}}
\newcommand{\utility}[1]{u^{#1}}

\newcommand{\wmunu}{w^{\mu \nu}}
\newcommand{\xmu}{x^{\mu}}
\newcommand{\xnu}{x^{\nu}}
\newcommand{\refmu}{\sigma^{\mu}}
\newcommand{\avgref}[1]{\alpha_\sigma^{#1}}
\newcommand{\NE}[1]{\bar{x}^{#1}}
\newcommand{\weightedsum}{ \sum_{\nu \in N^\mu} \wmunu \xnu}
\newcommand{\xnotmu}{x^{-\mu}}
\newcommand{\xmuaction}[1]{x^{\mu}_{#1}}


\title{Fictitious Play in Network Aggregative Games}
\author{AH, FB}

\begin{document}
	
	\maketitle

	\section{Paper Structure}

	\begin{enumerate}
		\item Introduction: Explain the notion of a Network Aggregative Game, and Fictitious Play
		with literature on the state of the art. Assumptions made as well as summary of results
		\item Maybe? Relation with the model of Grammatico
		\item Preliminaries \begin{itemize}
			\item The Network Aggregative Game model
			\item Fictitious Play, as well as the CTFP property
		\end{itemize}
		\item Convergence of Fictitious Play \begin{itemize}
			\item Existence of the Nash Equilibrium
			\item Existence of a CTFP
			\item Convergence of CTFP to a fixed point
			\item Corrolary: when $w_{ii} = 0$ (i.e. the interaction graph is simple) CTFP converges
			to a NE
			\item Convergence of CTFP to the NA-CCE set
		\end{itemize}
		\item Numerical Experiments \begin{itemize}
			\item Convergence rates w.r.t. connectivity and size
			\item Non-convergent examples
			\item Agent based simulations
		\end{itemize}
		\item Discussion of Experiments
		\item Concluding Remarks
	\end{enumerate}
	
	\newpage
	\section{Introduction}

	\section{Preliminaries}
	\subsection{Network Aggregative Games}
	\label{sec::NAG}

	The model we consider is that there is a set $\agentset = {1, ... ,
	N}$ of agents who are connected through an underlying interaction graph. This graph is given by
	the tuple $(\agentset, (\edgeset, \weightset))$ in which $\edgeset$ is the set of all pairs $(\mu,
	\nu) \in \agentset \times \agentset$ such that agent $\mu$ and agent $\nu$ are connected. Then,
	the set of neighbours of agent $\mu$ is denoted as $N^\mu = \{\nu \in \agentset \, : \, (\mu,
	\nu) \in \edgeset\}$. $\weightset
	\in M_N(\mathbb{R})$ is the weighted adjacency matrix whose elements $w^{\mu \nu}$ expresses the
	importance that agent $\mu$ places on agent $\nu$. Note that if $(\mu, \nu) \not \in \edgeset$
	then $w^{\mu \nu} = 0$ and $\wmunu \in (0, 1]$ otherwise.

	As a network game, each agent $\mu$ has an associated set of pure strategies $\actionset{\mu}$
	which has cardinality $|\actionset{\mu}| = n$. Then we can construct the unit-simplex on this
	action set as $\Delta_\mu := \{x \in \mathbb{R}^n \, : \, \sum_i \xmuaction{i} = 1\}$ where
	$\xmuaction{i}$ is the probability with which agent $\mu$ plays the pure strategy $i$. As such
	we refer to $\xmu$ as the \emph{state} of agent $\mu$ (this is often referred to as $\mu$'s
	mixed strategy). Also associated with each agent is a utility function $u^\mu(\xmu, \xnotmu)$ in
	which we use the standard notation $-\mu$ to refer to all agents other than $\mu$. Notice that
	this requires that each agent plays the same strategy against all of their neighbours. 

	With all of the above definitions, we can formalise the network aggregative (NA) game as the tuple
	$\Gamma = (\agentset, (\edgeset, \weightset), (\actionset{\mu}, \utility{\mu})_{\mu \in \mathcal{N}})$.

	What is unique about the NA game is the structure of the payoffs themselves. In this format,
	each agent is receives a reference $\sigma$ which is a weighted sum of each of their
	neighbours state. Formally 

	\begin{equation}
		\sigma^\mu = \sum_{\nu \in N^\mu} \wmunu \xnu.
	\end{equation}

	Then, the agent's must optimise their payoff with respect to this reference vector. Thus,
	instead of having to consider the actions of the entire population, or play individual games
	against each of their neighbours, the agent only has to consider $\sigma^\mu$ as a `measurement'
	of the local aggregate state and optimise with respect to this measurement. This allows us to
	make the reduction $u^\mu(\xmu, \xnotmu) = u^\mu(\xmu, \refmu)$. In particular, we consider that
	the agent is engaged in a matrix game against the reference vector so that

	\begin{equation}
		u^\mu(\xmu, \refmu) = \xmu \cdot A^\mu \refmu = \xmu \cdot A^\mu \weightedsum.
	\end{equation}

	where $A^\mu$ is the payoff matrix associated to agent $\mu$. Note that this means we could have
	written the game $\Gamma$ with the payoff matrices $A^mu$ in place of the utility functions
	$\utility{\mu}$. The NA game allows for the reduction of a
	multiplayer game into a series of two-player games. The agent's goal is to maximise their payoff
	with respect to the reference vector. As such, we define the best response correspondence
	$BR^\mu$ which maps any $\refmu$ the set $\arg \max_{y \in \Delta_\mu} {u^\mu(y, \refmu)}$. This
	leads naturally to the definition of a Nash Equilibrium in an NA Game as

	\begin{definition}(NE)
		The set of vectors $\{ \NE{\mu}\}_{\mu \in \agentset}$ is an NE if, for all $\mu$,
		
		\begin{equation*}
		\NE{\mu} \in BR_i( \sum_{\nu \in N^\mu} \wmunu \NE{\nu}).
		\end{equation*}
		
	\end{definition}

	We will show that such an equilibrium exists in ...

	\subsection{Continuous Time Fictitious Play}
	\label{sec::CTFP}

	\ah{For Francesco: is it worth giving a quick introduction to Fictitious Play by talking about two player games?}

	Fictitious Play requires that, at the current time, each agent considers the average behaviour
	of their opponent in the past and play a best response to that strategy. This is best
	illustrated in the two-player setting. Consider the two player normal form game $\Gamma_2 = (\{
	1, 2\}, ((S^1, A), (S^2, B)))$ so that $A$ and $B$ are the payoff matrices of agent $1$ and $2$
	respectively. As a remark, note that we can write the two player normal form game as an NA game
	simply by requiring that $\edgeset = \{(1, 2), (2, 1)\}$ and $\weightset$ is a 2x2 matrix with
	zeros on its leading diagonal and ones on the off diagonal. We write the time-average of both
	agents' strategies as 

	\begin{align}
		\alpha^1 = \frac{1}{t} \int_0^T x^1(t) \, dt \\
		\alpha^2 = \frac{1}{t} \int_0^T x^2(t) \, dt \\
	\end{align}

	In this manner, the $\alpha^\mu(t)$ denotes the time average of the strategies played by agent
	$\mu$ up to time $t$. Then, fictitious play requires that the agents update their strategy as
	$x^1(t) \in BR^1(\alpha^2(t))$ and $x^2(t) \in
	BR^2(\alpha^1(t))$. 

	We extend this naturally to the NA game $\Gamma$ by requiring that each agent update their
	strategy according to the time average of their reference vector $\refmu$. To formalise this, we
	write

	\begin{equation}
		\avgref{\mu} = \frac{1}{t} \int_0^t \refmu(s) \; ds.
	\end{equation}

	Using this, we follow in the footsteps of Ewerhart \cite{} and Harris \cite{} to define
	Fictitious Play in continuous time.

	\begin{definition}[Continuous Time Fictitious Play (CTFP)]
		A CTFP is defined as a measurable map $m$ with components $m_i$ such that for all $i$ and all $t \geq 1$, $m_i: [0, \infty) \rightarrow \Delta_i$ satisfies $m_i(t) \in BR_i(\alpha_{\sigma_i})$ for all $t \geq 1$.

		We can think of this definition as saying that the player plays some arbitrary strategy before $t = 1$, but beyond this it must play a best response to the time average of its reference signal.
	\end{definition}

	\subsection{Assumption}

	With the above preliminaries in place, we can state the assumptions that we make in this study.

	\begin{assumption}
		The weighted adjacency matrix $\weightset$ is constant and \emph{row stochastic} meaning
		that the sum elements in each row of $\weightset$ is equal to one.
	\end{assumption}

	\begin{assumption}
		The payoffs are given through matrix games and, therefore, are bilinear.
	\end{assumption}

	\begin{assumption}
		The cardinality of each action set $|\actionset{\mu}|$ is equal for all agents.
	\end{assumption}

	\begin{assumption}
		The NA game is zero-sum in the sense that $\sum_{\mu} u^\mu(\xmu, \weightedsum)$ for any set
		of states $(x^\mu)_{\mu \in N^\mu}$
	\end{assumption}

	\section{Convergence of Fictitious Play}

	\subsection{Existence of the Nash Equilibrium}
	
	Note that the NE Condition requires

	\begin{align}
		\NE{\mu} &\in \arg\max_{x \in \Delta_\mu} u^\mu(x, w^{\mu \mu}x + \sum_{\nu \in N^\mu} w^{\mu \nu} \NE{\nu}) \nonumber \\
		& =: \arg\max_{x \in \Delta_i} \bar{u}^\mu(x, \sum_{\nu \in N^\mu} w^{\mu \nu} \NE{\nu})
	\end{align}

	where we can find $\bar{u}_i$ through the following argument
	
	\begin{align}
		u^\mu(x, w^{\mu \mu} x + \sum_{\nu \in N^\nu} w_{\mu \nu} \NE{\nu}) & = x \cdot A^\mu (w^{\mu \mu} x + \sum_{\nu \in N^\mu} w_{\mu \nu} \NE{\nu}) \\
		 & = x \cdot (w^{\mu \mu} A^\mu)  x + \sum_{\nu \in N^\mu} u^{\mu \nu}(x, \NE{\nu}) \\
		 & =: \bar{u}^\mu(x, \sum_{\nu \in N^\mu} w^{\mu \nu} \NE{\nu}), \nonumber
	\end{align}
	
	where $u^{\mu \nu}(\xmu, x^\nu) = \xmu \cdot A^\mu x^\nu$. Note that, in order to get this
	formulation, we had to use the assumption of payoffs being bilinear so that we could separate
	out the term in the weighted sum involving $x$ from $\bar{x}^\nu$. 
	
	To show existence of an NE we will need the following definition and theorem.

	\begin{definition}[Upper Semi-Continuous]
		A compact-valued correspondence $\Phi: A \rightarrow B$ is \emph{upper semi-continuous} at a point $a$ if $g(a)$ is non-empty and if, for every sequence $a_n \rightarrow a$ and every sequence $(b_n)$ such that $b_n \in g(a_n)$ for all $n$, there exists a convergent subsequence of $(b_n)$ whose limit point $b$ is in $g(a)$.  
	\end{definition}

	\begin{theorem}[Kakutani]
		Let $K \subset \mathbb{R}^n$ be compact and convex and $\Phi: K \rightarrow K$ be closed or upper semi-continuous, with nonempty, convex and compact values. Then $\Phi$ has a fixed point.
	\end{theorem}

	Note that, when acting on a simplex, the function $\Phi: \Delta \rightarrow \textbf{P}(\Delta)$, where $\textbf{P}(\Delta)$ denotes the nonempty, closed and convex subsets of $\Delta$ only has to satisfy the upper-semi continuity condition to admit a fixed point.

	\begin{theorem}[Existence of NE]
		Under the assumption (II), namely that the payoff function achieves a bilinear property, a
		Nash Equilibrium $\{\bar{x}^\mu\}_{\mu \in \agentset}$ exists.
	\end{theorem}

	\begin{proof}
		We begin by rewriting the NE condition by concatenating the set of NE vectors into one long colunn vector. This gives

		\begin{equation}
			\begin{bmatrix}
				\bar{x}^1 \\ . \\ . \\ . \\ \bar{x}^N
			\end{bmatrix} \in
			\begin{bmatrix}
			\arg\max_{y \in \Delta_1} \bar{u}^1(y, \sum_{\nu \in N^1} w^{1 \nu} \bar{x}^\nu) \\ . \\ . \\ . \\ \arg\max_{y \in \Delta_N} \bar{u}^1(y, \sum_{\nu \in N^N} w^{N \nu} \bar{x}^\nu)
			\end{bmatrix}	.
		\end{equation}

		We can rewrite the weighted summation for $\mu$ as

		\begin{equation}
			\sum_{\nu \in N^\mu} w^{\mu \nu} \bar{x}^\nu = (w_{-\mu}^T \otimes I_n) \begin{bmatrix}
				\bar{x}^1 \\ . \\ . \\ . \\ \bar{x}^N
			\end{bmatrix},
		\end{equation}
	
		in which $w_{-\mu}$ is a column vector containing $w^{\mu \nu}$ in the $\nu$'th element for all $j \in N^\mu$ and 0 everywhere else (including in the $\mu$'th slot), $I_n$ is the $n \times n$ identity matrix and $\otimes$ is the kronecker product. For example, the form for agent 1, in the case of 2-action game is given by

		\begin{equation}
			(w_{-1}^T \otimes I_2) = [0, w_{12}, w_{13}, ..., w_{1n}] \otimes I_2 = 
			\begin{bmatrix}
				0 & 0 & w_{12} & 0 & ... & w_{1n} & 0 \\
				0 & 0 & 0 & w_{12} & ... & 0 & w_{1n} \\
			\end{bmatrix}
		\end{equation}
		
		Returning to the $N$-player NA game our condition becomes
		\begin{equation}
			\begin{bmatrix}
				\NE{1} \\ . \\ . \\ . \\ \bar{N}
			\end{bmatrix} \in
			\begin{bmatrix}
				\arg\max_{y \in \Delta_1} \bar{u}^1(y, (w_{-1}^T \otimes I_n) \begin{bmatrix}
					\NE{1} \\ . \\ . \\ . \\ \NE{N}
				\end{bmatrix}) \\ . \\ . \\ . \\ \arg\max_{y \in \Delta_N} \bar{u}_N(y, (w_{-N}^T \otimes I_n) \begin{bmatrix}
				\NE{1} \\ . \\ . \\ . \\ \NE{N}
			\end{bmatrix}))
			\end{bmatrix}	.
		\end{equation}

		This means that we achieve a Nash Equilibrium iff $(\NE{\mu})_{\mu \in \agentset}$ is a fixed point of the map
	
	
		\begin{equation}
			\begin{bmatrix}
				\arg\max_{y \in \Delta_1} \bar{u}^1(y, (w_{-1}^T \otimes I_n) ( \cdot )) \\ . \\ . \\ . \\ \arg\max_{y \in \Delta_N} \bar{u}^N(y, (w_{-N}^T \otimes I_n)( \cdot ))
			\end{bmatrix}	.
		\end{equation}


		Now, since the modified payoff $\bar{u}^\mu$ shares the same bilinear property as $u^\mu$, we can assert that it is continuous is its second argument. Therefore, the above vector valued map can be asserted to be continuous and so is upper semi-continuous. As such, we can apply Kakutani's Fixed Point Theorem to assert that the above map admits a fixed point.

	\end{proof}

	\newpage
	\subsection*{The Model}
	
	We have a set of agents $V = \{1, ..., N \}$ which can be thought of as nodes on a graph $\{V,
	E, W\}$ where $E$ is the edge-set (i.e. the set of pairs $(i, j)$ such that i and j are
	connected) and $W$ is a weighted adjacency matrix $[W]_{ij} = w_{ij}$. Let $N_i := \{j \in V :
	(i, j) \in E\}$ be the set of player $i's$ neighbours. Note $w_{ij} = 0$ if $(i, j) \not\in E$,
	$w_{ij} \in (0, 1]$ if $(i, j) \in E$. We impose the normalisation condition that $\sum_{j \in
	N_i} w_{ij} = 1$. This requirement ensures that the aggregate strategy $\sum_{j \in N_i} w_{ij}
	x_j$ (where $x$ is a probability vector) remains a probability vector. For example, in the 3
	player case:
	
	\begin{equation}
	\sigma_1 := w_{12} y + w_{13} z = 
	w_{12}
	\begin{bmatrix}
	y_1 \\ y_2 \\ 1 - y_1 - y_2
	\end{bmatrix}		
	+ 	w_{13}
	\begin{bmatrix}
	z_1 \\ z_2 \\ 1 - z_1 - z_2
	\end{bmatrix}	= 
	\begin{bmatrix}
	w_{12} y_1 + w_{13} z_1 \\ w_{12} y_2 + w_{13} z_2 \\ 1 - (w_{12} y_1 + w_{13} z_1) - (w_{12} y_2 + w_{13} z_2)
	\end{bmatrix}	
	\end{equation}
	
	In the continuous time case, we're also going to assume that each agent $i$ chooses a mixed strategy $x_i(t) \in \Delta_i$ at time $t$ from its strategy space $\Delta_i$ (which is an $N-$simplex). We assume that $i$ has just the one strategy that it can play against all of its neighbours.
	
	
	\subsection{Existence of a CTFP}
	
	We adapt the techniques of Ewerhart to show that any CTFP path converges 

	\subsection*{Starting Assumptions}
	
	\begin{enumerate}[I]
		\item The weights $w_{ij}$ are constant for all $i, j$.
		\item The payoffs $u_i$ are in matrix form, and so are bilinear.
		\item All agents update their strategies synchronously
		\item All agents have the same sized strategy space 
		\item The network is zero-sum in the sense that $\sum_i u_i(x_i, w_{ii} x_i + \sum_{j} w_{ij} x_j)$ for any set of strategies $(x_1, ..., x_N)$. 
	\end{enumerate}
	
	\subsection*{The Argument for Bilinear Payoffs}
	
	\textit{Zero-sum polymatrix games can model common situations in which nodes in a network interact pairwise and make decisions (for example, adopt one of many technologies, or choose one or more of their neighbors for preferential interaction)} (Cai et al (2016)))
	
	\ah{Need to find more references to put in here, most papers don't really give real world examples to justify this model.}
	
	\subsection*{Fictitious Play in Network Aggregative Games}
	
	For Fictitious Play (FP), we require that the agent plays a best response to the time average to a \emph{reference signal} $\sigma_i$ which is some convex combination of the agent's own strategy and that of its neighbours on the network. Under the above assumptions, this reference is given as
	
	\begin{equation*}
		\sigma_i (t) = \sum_{j} w_{ij} x_j (t).
	\end{equation*}
	
	Let us have the following definitions:
	
	\begin{align}
		\alpha_{\sigma_i}(t) = \frac{1}{t} \int_{0}^{t} \sigma_i(t') \, dt'\nonumber \\
		\alpha_i(t) = \frac{1}{t} \int_{0}^{t} x_i(t') \, dt', \nonumber
	\end{align}
	
	where $x_i(t')$ denotes the action played by $i$ at time $t'$. Now we notice
	
	\begin{align}
		\alpha_{\sigma_i}(t) = \frac{1}{t} \int_{0}^{t} \sigma_i(t') \, dt' = \frac{1}{t} \int_{0}^t \sum_{j} w_{ij} x_j(t') \, dt' = \sum_{j} w_{ij} \frac{1}{t} \int_{0}^t x_j(t') \, dt' = \sum_{j} w_{ij} \alpha_j(t) \nonumber \\
	\end{align}
	
	\paragraph{Continuous Time Fictitious Play (CTFP)} A CTFP is defined as a measurable map $m$ with components $m_i$ such that for all $i$ and all $t \geq 1$, $m_i: [0, \infty) \rightarrow \Delta_i$ satisfies $m_i(t) \in BR_i(\alpha_{\sigma_i})$ for all $t \geq 1$.
	
	We can think of this definition as saying that the player plays some generic strategy before $t = 1$, but beyond this it must play a best response to the time average of its reference signal.
	
	\paragraph{Discrete Time Fictitious Play (DTFP)} A DTFP is defined a sequence $\{x_{k}\}_{k=1}^{\infty}$ with components $x_{k, i}$ such that, for all $i$ and, for all $k \geq 1$, $x_{k, i} \in BR_i\left( \frac{1}{k} \sum_{t = 0}^{k - 1} \sigma_{k, i} \right)$.
	
	We can see that the DTFP is just the equivalent definition as the CTFP, except that the time domain is $\mathbb{Z}_+$ rather than $\mathbb{R}_+$. Nevertheless, the change from continuous to discrete is not trivial and we'll get to that soon.
	
	\paragraph{Convergence} We write $\alpha$ as the concatenation of all $\alpha_i$. Let $\Omega(\alpha)$ be  the set of all limit points for $\alpha$. Then, CTFP is said to have converged if any $\mu^* \in \Omega(\alpha)$ is contained in the set of Nash Equilibria of the game.
	
	With these definitions out of the way, we'll try to figure out whether, first, CTFP converges to a Nash Equilibrium. The process for doing this is as follows:
	
	\begin{enumerate}
		\item Show that a Nash equilibrium exists
		\item Show that a path satisfying the CTFP property exists
		\item Show that the associated $\Omega(\alpha)$ is contained in the set of NE.

	\end{enumerate}

	\newpage
	
	\subsection*{First Case: Aggregation is dependent only on its neighbours}
	
	We start with the following assumption
	
	\begin{assumption}[V]
	$w_{ii} = 0$ for all $i \in \{ 1, ..., N \}$
	\end{assumption}
	
	Under this assumption the $BR_i$ map becomes
	
	\begin{equation}
		BR_i(\sum_{j \in N_i} w_{ij} x_j) = \arg\max_{x \in \Delta_i} u_i(x_i,\sum_{j \in N_i} w_{ij} x_j)
	\end{equation}
	
	Under the assumption that the payoff function is bilinear and can be written as $u_i(x_i, \sigma_i) = x_i \cdot A^i \sigma_i$. Then 
	
	\begin{equation*}
		u_i(x_i, \sigma_i) = x_i \cdot A^i \sum_{j \in N_i} w_{ij} x_j = \sum_{j \in N_i} x_i \cdot A^{ij} x_j =: \sum_{j \in N_i} u_{ij}(x_i, x_j) 
	\end{equation*}
	
	where $A^{ij} := w_{ij} A^i$ and $u_{ij}$ is a bilinear payoff between $i$ and $j$ as defined by Ewerhart. Furthermore, the NE condition is now
	
	\begin{align}
			x_i^* & \in BR_i(\sum_{j \in N_i} w_{ij} x_j^*). \\
			& = \arg \max_{x \in \Delta_i} \sum_{j \in N_i} u_{ij}(x_i, x_j) 
	\end{align}
	
	 With this transformation, we can move from a network aggregative system to a network game formulation (as in Ewerhart) in which each agent $i$ plays a game $G_{ij}$ against $j$ with payoff $A^{ij}$ and with the added requirement that each agent plays the same strategy against each of its neighbours. With this change, we can apply Nash's Theorem to state that the Nash Equilibrium exists.
	
	Applying the same transformation, CTFP becomes the requirement that, in the equivalent network game, $m_i(t) \in \arg \max_{x \in \Delta_i} \sum_{j \in N_i} u_{ij}(x_i, \alpha_j)$ for all $t \geq 1$. Now, Ewerhart showed that, in a zero-sum network (where the sum of all $u_i$ is zero), such an $m$ exists and any such $m$ converges to an NE. This must therefore also be true of the network aggregative game.
	
	In any case, the fact that $m$ converges to an NE for the equivalent network game means that it converges for the NAG also. \ah{To make this precise, I'll follow through the proof of Ewerhart}
	
	\begin{theorem}
		For any zero-sum Network Aggregative Game which follows the above assumption, any CTFP $m$ has the property that $\Omega(\alpha)$ is contained within the set of NE of the game.
	\end{theorem}
	
	\begin{proof}
		Take the Lyapunov function
		\begin{align}
			L(\mu) & = \sum_i \max_{x \in \Delta_i} \{u_i(x, \sum_{j \in N_i} w_{ij} \mu_j) - u_i(\mu_i, \sum_{j \in N_i} w_{ij} \mu_j) \} \nonumber \\
			& = \sum_i \max_{x \in \Delta_i} \{u_i(x, \sum_{j \in N_i} w_{ij} \mu_j)\} - \sum_i u_i(\mu_i, \sum_{j \in N_i} w_{ij} \mu_j) \nonumber \\
			& = \sum_i \max_{x \in \Delta_i} \{u_i(x, \sum_{j \in N_i} w_{ij} \mu_j)\} \nonumber
		\end{align}
		
		where the last equality holds because we made the assumption of a zero sum game. Making the usual transformation, we consider that $i$ is now involved in a network game in which it plays the same strategy against each of its neighbours $j$ giving
		
		\begin{align}
			L(\mu) = \sum_i \max_{x \in \Delta_i} \sum_{j \in N_i}  u_{ij}(x, \mu_j) \nonumber \\
		\end{align}
		
		Now we take any CTFP $m$ and recall that it is found by playing the best response to $\alpha(t; m)$, which of course means that it maximises $\sum_{j \in N_i} u_{ij}$. Therefore
		
		\begin{align}
			L(\alpha(t)) & = \sum_i \sum_{j \in N_i} u_{ij}(m_i(t), \alpha_j(t)) \nonumber \\
			& = \sum_i \sum_{j \in N_i} m_i(t) A^{ij} \alpha_j(t)
		\end{align}
		 
		 Now if we were to follow on using Ewerhart's proof, we would find that any accumulation point of $\alpha(t; m)$ is an NE of the network game. I.e. if $\mu^*$ is this limit point, then it satisfies that, for any $x \in \Delta_i$
		 
		 \begin{align}
		 	\sum_{j \in N_i} u_{ij}(x, \mu_j^*) \leq 	\sum_{j \in N_i} u_{ij}(\mu_i^*, \mu_j^*) \nonumber
		 \end{align}
		 
		 Now if we reverse the transformation this means that, for the network aggregative game we have the condition that for any $x \in \Delta_i$
		 
		 \begin{align}
		 	u_{i}(x, \sum_{j \in N_i} w_{ij} \mu_j^*) \leq u_{i}(\mu_i^*, \sum_{j \in N_i} w_{ij} \mu_j^*)
		 \end{align}
		 
	\end{proof}
	\newpage
	
	\subsection*{Second Case}
	
	This case is much more complex and requires that we take into account all of the steps properly.
	
	\subsubsection*{Existence of the Nash Equilibrium}
	
	The NE condition here is the same as the original definition that we had, but I'll repeat it here for the sake of convenience. The set of vectors $\{ x_i^*\}_{i = 1}^N$ is an NE if, for all $i$,
	
	\begin{equation*}
		x_i^* \in BR_i( w_{ii} x_i^* + \sum_{j \in N_i} w_{ij} x_j^*).
	\end{equation*}
	
	Note that this requires
	
	\begin{align}
		x_i^* &\in \arg\max_{x \in \Delta_i} u_i(x_i, w_{ii} x_i + \sum_{j \in N_i} w_{ij} x_j^*) \nonumber\\
		&= \arg\max_{x \in \Delta_i} \bar{u}_i(x_i, \sum_{j \in N_i} w_{ij} x_j^*),
	\end{align}

	where we can find $\bar{u}_i$ through the following argument
	
	\begin{align}
		u_i(x_i, w_{ii} x_i + \sum_{j \in N_i} w_{ij} x_j^*) & = x_i \cdot A_i (w_{ii} x_i + \sum_{j \in N_i} w_{ij} x_j) \\
		 & = x_i \cdot (w_{ii} A_i)  x_i + \sum_{j \in N_i} u_{ij}(x_i, x_j) \\
		 & =: \bar{u}_i(x_i, \sum_{j \in N_i} w_{ij} x_j^*), \nonumber
	\end{align}
	
	where $u_{ij}$ is as previously defined. Note that, in order to get this formulation, we had to use the bilinear assumption (II) so that we could separate out the term involving $x_i$ easily. 
	
	To show existence of an NE we will need the following definition and Theorem.

	\begin{definition}[Upper Semi-Continuous]
		A compact-valued correspondence $\Phi: A \rightarrow B$ is \emph{upper semi-continuous} at a point $a$ if $g(a)$ is non-empty and if, for every sequence $a_n \rightarrow a$ and every sequence $(b_n)$ such that $b_n \in g(a_n)$ for all $n$, there exists a convergent subsequence of $(b_n)$ whose limit point $b$ is in $g(a)$.  
	\end{definition}

	\begin{theorem}[Kakutani]
		Let $K \subset \mathbb{R}^n$ be compact and convex and $\Phi: K \rightarrow K$ be closed or upper semi-continuous, with nonempty, convex and compact values. Then $\Phi$ has a fixed point.
	\end{theorem}

	Note that, when active on a simplex, the function $\Phi: \Delta \rightarrow \textbf{P}(\Delta)$, where $\textbf{P}(\Delta)$ denotes the nonempty, closed and convex subsets of $\Delta$ only has to satisfy the upper-semi continuity condition to admit a fixed point.

	\begin{theorem}[Existence of NE]
		Under the assumption (II), namely that the payoff function achieves a bilinear property, a Nash Equilibrium $\{x_i^*\}_{i = 1}^N$ exists.
	\end{theorem}

	\begin{proof}
		We begin by rewriting the NE condition by concatenating the set of NE vectors into one long colunn vector. This gives

		\begin{equation}
			\begin{bmatrix}
				x_1^* \\ . \\ . \\ . \\ x_N^*
			\end{bmatrix} \in
			\begin{bmatrix}
			\arg\max_{y \in \Delta_1} \bar{u}_1(y, \sum_{j \in N_i} w_{ij} x_j^*) \\ . \\ . \\ . \\ \arg\max_{y \in \Delta_N} \bar{u}_N(y, \sum_{j \in N_i} w_{ij} x_j^*)
			\end{bmatrix}	.
		\end{equation}

		We can rewrite the weighted summation in the $i$'th component of the right hand side as 

		\begin{equation}
			\sum_{j \in N_i} w_{ij} x_j^* = (w_{-i}^T \otimes I_n) \begin{bmatrix}
				x_1^* \\ . \\ . \\ . \\ x_N^*
			\end{bmatrix},
		\end{equation}
	
		in which $w_{-i}$ is a column vector containing $w_{ij}$ in the $j$'th element for all $j \in N(i)$ and 0 everywhere else (including in the $i$'th slot), $I_n$ is the $n \times n$ identity matrix and $\otimes$ is the kronecker product. For example, the form for agent 1, in the case of 2-action game is given by

		\begin{equation}
			(w_{-1}^T \otimes I_2) = [0, w_{12}, w_{13}, ..., w_{1n}] \otimes I_2 = 
			\begin{bmatrix}
				0 & 0 & w_{12} & 0 & ... & w_{1n} & 0 \\
				0 & 0 & 0 & w_{12} & ... & 0 & w_{1n} \\
			\end{bmatrix}
		\end{equation}
		
		So our condition becomes
		\begin{equation}
			\begin{bmatrix}
				x_1^* \\ . \\ . \\ . \\ x_N^*
			\end{bmatrix} \in
			\begin{bmatrix}
				\arg\max_{y \in \Delta_1} \bar{u}_1(y, (w_{-1}^T \otimes I_n) \begin{bmatrix}
					x_1^* \\ . \\ . \\ . \\ x_N^*
				\end{bmatrix}) \\ . \\ . \\ . \\ \arg\max_{y \in \Delta_N} \bar{u}_N(y, (w_{-N}^T \otimes I_n) \begin{bmatrix}
				x_1^* \\ . \\ . \\ . \\ x_N^*
			\end{bmatrix}))
			\end{bmatrix}	.
		\end{equation}

		This means that we achieve a Nash Equilibrium iff $\{ x_i^*\}_{i = 1}^N$ is a fixed point of the map
	
	
		\begin{equation}
			\begin{bmatrix}
				\arg\max_{y \in \Delta_1} \bar{u}_1(y, (w_{-1}^T \otimes I_n) ( \cdot )) \\ . \\ . \\ . \\ \arg\max_{y \in \Delta_N} \bar{u}_N(y, (w_{-N}^T \otimes I_n)( \cdot )))
			\end{bmatrix}	.
		\end{equation}


		Now, since the modified payoff $\bar{u}$ shares the same bilinear property as $u$, we can assert that it is continuous is its second argument. Therefore, the above vector valued map can be asserted to be continuous and so is upper semi-continuous. This continuity can be extended to the above concatenation of best responses. As such, we can apply Kakutani's Fixed Point Theorem to assert that the above map admits a fixed point.

	\end{proof}

	\subsubsection*{Existence of a CTFP}

	\begin{theorem}
		There exists a path $m$ which satisfies the property that, for all $i$, $m_i \in BR_i
		(\alpha_{\sigma_i})$ for almost all $t \geq 1$.
	\end{theorem}

	\begin{proof}
		Recall the definition of $\alpha_i(t)$

		\begin{equation*}
		\alpha_i(t) = \frac{1}{t} \int_{0}^{t} m_i(t') \, dt'
		\end{equation*}

		Then 

		\begin{align}
		\frac{d}{dt} \alpha_i(t) & = \frac{d}{dt} \frac{1}{t} \int_{0}^t m_i(t') dt' \nonumber \\
		& = \frac{1}{t} m_i(t) - \frac{1}{t} \alpha_i(t)
		\end{align}

		Now we assert that $m_i(t) \in BR_i(\alpha_{\sigma_t}) = \arg\max_{y \in \Delta_i} u_i(y,
		w_{ii} \alpha_i(t) + \sum_{j \in N(i)} w_{ij} \alpha_j(t))$. 

		Let us then define $\alpha(t)$ as the concatenation of all $\alpha_i(t)$

		\begin{equation}
			\alpha(t) = \begin{bmatrix}
				\alpha_1(t)^T, \ldots, \alpha_N(t)^T
			\end{bmatrix}^T \subset \mathbb{R}^{Nn}
		\end{equation}


		We can, therefore, write the aggregation as

		\begin{equation}
			(W \otimes I_n) \alpha(t) = \begin{bmatrix}
				\sum_{j \in N(1)} w_{1j} \alpha_j(t) \\
				.\\
				.\\
				.\\
				\sum_{j \in N(N)} w_{Nj} \alpha_j(t)
			\end{bmatrix} \subset \mathbb{R}^{Nn}
		\end{equation}

		I will write $(W \otimes I_n) \alpha(t)$ as $\alpha_W$ for convenience. Furthermore, using
		the bimatrix property of the game, we can say that

		\begin{equation}
			\begin{bmatrix}
				\arg\max_{y \in \Delta_1} y \cdot A_1 ( \alpha_W(t)_1) \\
				.\\
				.\\
				.\\
				\arg \max_{y \in \Delta_N} y \cdot A_n (\alpha_W(t)_N) 
			\end{bmatrix} = 
			\arg \max_{y \in \Delta} y \cdot \begin{bmatrix}
				A_1 & 0 & . & . & . & 0 \\
				0 & A_2 & . & . & . & 0 \\
				& & . & & & \\
				& & & . & & \\
				& & & & . & \\
				0 & 0 & . & . & . & A_N \\
			\end{bmatrix} \alpha_W(t) = \arg\max_{y \in \Delta} y \cdot \Lambda (W \otimes I_n)
			\alpha(t)
		\end{equation}

		in which $\Delta = \times_i \Delta_i$ and $\Lambda$ is the block diagonal matrix containing
		each $A_i$. 

		We can now write the differential inclusion as

		\begin{equation}
			\dot{\alpha(t)} \in \frac{1}{t} (\arg \max_{y \in \Delta}  \{y \cdot \Lambda (W \otimes
			I_n)
			\alpha(t) \}- \alpha(t))
		\end{equation}

		with the initial condition $\alpha(1) = \mu$. Then, the path $m$ is a CTFP if its
		corresponding $\alpha(t; m)$ is a solution to the above differential inclusion. Following
		the definition of (Harris 1998), a solution $\alpha(t)$ must satisfy

		\begin{enumerate}
			\item $\alpha(t)$ is locally Lipschitz
			\item $\alpha(1) = \mu$
			\item $\dot{\alpha}(t) \in \frac{1}{t} (\arg \max_{y \in \Delta}  \{y \cdot \Lambda (W \otimes
			I_n)
			\alpha(t) \}- \alpha(t))$ for almost all $t \in [1, \infty)$ 
		\end{enumerate}

		The question then remains, does the differential inclusion admit a solution? Using the
		results of Aubin and Cellina (see Harris 1998, paragraph below Prop. 6), can use the fact
		that the $\arg \max$ function is non-empty, compact and convex valued, bounded (all of
		these follow since the function acts from $\Delta$ to $\Delta$) and upper semi-continuous.
		With these facts in place, we can say that there is a CTFP for any initial value $\mu$.
		\ah{I believe this holds for any choice of $W$ as long as it is row stochastic so that
		the values remain inside $\Delta$ after aggregation}.
	\end{proof}
	
	\newpage
	
	\section*{Convergence Properties}

	In this section I will show that the NA-CTFP process converges to the set of coarse correlated
	equilibria. So first I will define what this means. \ah{For Francesco: Please forgive me for
	changing notation, I'll make everything consistent.}

	The notion of the CCE set is best considered through \emph{regret} which, for agent $\mu$ is given as

	\begin{equation}
		R^{\mu} = \max_{x_{i'}^\mu \in S^\mu} \Big\{ \frac{1}{T} \int_{0}^{T} u^{\mu}(x_{i'}^\mu(t), \sigma(t)) - u^{\mu}(m^\mu(t), \sigma(t)) \, dt \Big\}
	\end{equation}

	To illustrate this, let us consider the case where each agent has only two actions. Then $u^{\mu}(x^\mu(t), \sigma(t))$ is given by
	
	\begin{equation}
		u^{\mu}(x^\mu(t), \sigma(t)) = \sum_{ij} a_{ij} x_i^\mu \sigma_j^\mu = a_{11} x_1^\mu \sigma_1^\mu + a_{12} x_1^\mu \sigma_2^\mu + a_{21} x_2^\mu \sigma_1^\mu + a_{22} x_2^\mu \sigma_2^\mu
	\end{equation}

	On the other hand, let us consider that agent $\mu$'s first strategy maximises $u^{\mu}(x_{i'}^\mu(t), \sigma(t))$, then

	\begin{equation}
		\max_{x_{i'}^\mu \in S^\mu} u^{\mu}(x_{i'}^\mu(t), \sigma(t)) = \sum_{ij} a_{1j} x_i^\mu \sigma_j^\mu = a_{11} x_1^\mu \sigma_1^\mu + a_{12} x_1^\mu \sigma_2^\mu + a_{11} x_2^\mu \sigma_1^\mu + a_{12} x_2^\mu \sigma_2^\mu 
	\end{equation}

	By comparing the two expanded expressions, we can see that the latter gives the reward that agent $\mu$ would have received had they played action $1$ throughout the entire play, assuming that the behaviour of the other agents (encoded in $\sigma$) does not change. As such, this is a measure of agent $\mu$'s regret, in hindsight, for not playing action $1$ the entire time. An agent achives \emph{no regret} if $R^\mu$ is non-positive.
	% \begin{definition}[Coarse Correlated Equilibrium]
	% 	A distribution $D$ over action profiles $\times_{\mu} A^{\mu}$ is a \emph{coarse correlated
	% 	equilibrium} if, for
	% 	all players $\mu$ and
	% 	all
	% 	actions $i' \in A^{\mu}$

	% 	\begin{equation}
	% 		\mathbb{E}_{a \sim D}[u^{\mu}(a)] \geq \mathbb{E}_{a \sim D}[u^{\mu}(a^\mu_{i'}, a
	% 		^{- \mu})]
	% 	\end{equation}

	% \end{definition}
	\begin{theorem}
		Assuming that $w_{ii} = 0$, then for any choice of payoff matrix, agents following the NA-FP process achieve zero regret in the limit, i.e.
		\begin{equation}
			\lim_{T \rightarrow \infty} \max_{x_{i'}^\mu \in S^\mu} \Big\{ \frac{1}{T} \int_{0}^{T} u^{\mu}(x_{i'}^\mu(t), \sigma(t)) - u^{\mu}(m^\mu(t), \sigma(t)) \, dt \Big\} = 0
		\end{equation}

	\end{theorem}
	
	\begin{proof}
		We will adapt the techniques of Ostrovski and van Strein for this proof. Their result was found for a two player game, we will leverage the fact that the NA process means that we can reduce an $N$ player game down to a series of two player games. 
		
		For any agent $\mu$ define
		\begin{equation}
			\bar{u}^\mu (\alpha_\sigma^\mu) := max_{y \in \Delta_\mu} u^\mu(y, \alpha_\sigma^\mu)
		\end{equation}

		Now, if the agents are following the NA-FP process, then we know that $m^\mu (t) \in \Delta_\mu$ is the strategy which maximises $u^\mu( \cdot, \alpha_\sigma^\mu)$ so we can write 

		\begin{equation}
			\bar{u}^\mu (\alpha_\sigma^\mu) := max_{y \in \Delta_\mu} u^\mu(y, \alpha_\sigma^\mu) = m^\mu(t) \cdot A^\mu (\alpha_\sigma^\mu)
		\end{equation}

		Then, applying the \emph{envelope theorem} we have

		\begin{equation}
			\frac{d}{d \alpha_\sigma^\mu} \bar{u}^\mu (\alpha_\sigma^\mu) = \frac{d}{d \alpha_\sigma^\mu} x^\mu \cdot A^\mu (\alpha_\sigma^\mu) \Big |_{x^\mu = m^\mu} = m^\mu \cdot A^\mu
		\end{equation}

		Which gives that 

		\begin{equation}
			\frac{d}{dt} \bar{u}^\mu (\alpha_\sigma^\mu (t)) = m^\mu \cdot A^\mu \frac{d \alpha_\sigma^\mu (t)}{dt}
		\end{equation}

		Then, 

		\begin{align}
			\frac{d}{dt} (t \bar{u}^\mu (\alpha_\sigma^\mu (t))) & =  \bar{u}^\mu (\alpha_\sigma^\mu (t)) + t m^\mu \cdot A^\mu \frac{d \alpha_\sigma^\mu (t)}{dt} \\
			& = m^\mu \cdot A^\mu (\sum_{\nu \in N(\mu)} w^{\mu \nu} \alpha^\nu (t) + t (m^\mu \cdot A^\mu \sum_{\nu \in N(\mu)} w^{\mu \nu} \frac{d}{dt} \alpha^\nu(t))
		\end{align} 

		Now, we know that the differential inclusion for the NA-FP process can be written as

		\begin{equation}
			\frac{d}{dt} \alpha^\mu (t) = \frac{1}{t} (m^\mu(t) - \alpha^\mu (t))
		\end{equation}

		We insert this into the previous equation to yield

		\begin{align}
			\frac{d}{dt} (t \bar{u}^\mu (\alpha_\sigma^\mu (t))) & = m^\mu \cdot A^\mu (\sum_{\nu \in N(\mu)} w^{\mu \nu} \alpha^\nu (t)) + t(m^\mu \cdot A^\mu \sum_{\nu \in N(\mu)} w^{\mu \nu} \frac{1}{t} (m^\nu(t) - \alpha^\nu (t))) \\
			& = m^\mu \cdot A^\mu (\sum_{\nu \in N(\mu)} w^{\mu \nu} \alpha^\nu (t) + m^\mu \cdot A^\mu \sum_{\nu \in N(\mu)} w^{\mu \nu} (m^\nu(t) - \alpha^\nu (t)) \\
			& = m^\mu \cdot A^\mu \sum_{\nu \in N(\mu)} w^{\mu \nu} m^\nu(t) = m^\mu \cdot A^\mu \sigma^\mu(t) 
		\end{align}


		Now if we integrate both sides with respect to $t$ in the bound $[1, T]$ (on which the NA-FP) process is defined, we get

		\begin{align}
			&  T \bar{u}^\mu (\alpha_\sigma^\mu (T)) - \bar{u}^\mu (\alpha_\sigma^\mu (1)) = \int_1^T u^\mu (m^\mu(t), \sigma^\mu(t)) \; dt \\
			& \implies \bar{u}^\mu (\alpha_\sigma^\mu (T)) - \frac{1}{T} \bar{u}^\mu (\alpha_\sigma^\mu (1)) = \frac{1}{T} \int_1^T u^\mu (m^\mu(t), \sigma^\mu(t)) \; dt \\
			& \implies \lim_{T \rightarrow \infty} \bar{u}^\mu (\alpha_\sigma^\mu (T)) - \frac{1}{T} \int_0^T u^\mu (m^\mu(t), \sigma^\mu(t)) \; dt = 0
		\end{align}

		Now notice

		\begin{align}
			\bar{u}^\mu (\alpha_\sigma^\mu (T)) = \max_{x^\mu_{i'} \in S^\mu} \sum_{j} a_{i'j} (\alpha_{\sigma}^\mu (T))_j & = \max_{x^\mu_{i'} \in S^\mu} \sum_{j} a_{i'j} (\frac{1}{T} \int_{0}^{T} \sigma^\mu(t) \; dt)_j \\
			& = \max_{x^\mu_{i'} \in S^\mu} \sum_{j} a_{i'j} \frac{1}{T} \int_{0}^{T} \sum_i (m^\mu (t))_i (\sigma^\mu(t))_j \; dt\\
			& = \max_{x^\mu_{i'} \in S^\mu} \frac{1}{T} \int_0^T \sum_{ij} a_{i'j} (m^\mu (t))_i (\sigma^\mu(t))_j \; dt\\
			& = \max_{x^\mu_{i'} \in S^\mu} \frac{1}{T} \int_0^T u^\mu(x^\mu_{i'}, \sigma^\mu(t))
		\end{align}

		So we recover

		\begin{equation}
			\lim_{T \rightarrow \infty} \max_{x_{i'}^\mu \in S^\mu} \Big\{ \frac{1}{T} \int_{0}^{T} u^{\mu}(x_{i'}^\mu(t), \sigma(t)) - u^{\mu}(m^\mu(t), \sigma(t)) \, dt \Big\} = 0
		\end{equation}

		which was precisely the regret condition that we required.

		\ah{Note: I think that this means that the NA-FP process converges to the coarse correlated equilibrium (CCE) set, but I'm a little hesitant to write it just because I'm not sure if the terminology lines up}
	\end{proof}

	\newpage

	\begin{equation}
		x_i(t) \in BR_i \left( \frac{1}{t} \int_{0}^{t} \sigma_i(t') dt' \right).
	\end{equation}
	
	By the definition of Continuous Time Fictitious Play (CTFP) given by Ewerhart, we require that $m: [0, \infty) \rightarrow \times_i \Delta_i$ is a measurable mapping such that, for each $i$, $m_i(t) \in BR_i \left( \frac{1}{t} \int_{0}^{t} \sigma_i(t') dt' \right)$. Now notice,
	
	\begin{equation*}
		x_i \in BR_i \left( \frac{1}{t} \int_{0}^{t} \sigma_i(t') dt' \right) \iff  \in x_i\in BR_i \left( \frac{1}{t} \int_{0}^{t} [w_{ii} m_i(t') + \sum_{j \in N_i} w_{ij} m_j(t')] \, dt' \right)
	\end{equation*}
	
	Let us assume that $u_i$ takes the form $x \cdot A_i \sigma_i$ where $A_i$ is the payoff matrix associated with agent $i$. Then,
	
	\begin{align}
		& x_i \in \arg\max_{x \in \Delta_i} u_i(x,\frac{1}{t} \int_{0}^{t} [w_{ii} m_i(t') + \sum_{j \in N_i} w_{ij} m_j(t')] \, dt') \nonumber \\
		\iff & x_i \in \arg\max_{x \in \Delta_i} x \cdot A_i \left(\frac{1}{t} \int_{0}^{t} [w_{ii} m_i(t') + \sum_{j \in N_i} w_{ij} m_j(t')] \, dt' \right) \nonumber \\
		\iff & x_i \in \arg \max_{x \in \Delta_i} x \cdot (w_{ii} A_i) \left( \frac{1}{t} \int_{0}^{t} m_i(t')\right) + \sum_{j \in N_i} x \cdot (w_{ij} A_i) \left( \frac{1}{t} \int_{0}^{t} m_j(t')\right) \nonumber \\
		\iff & x_i \in \arg \max_{x \in \Delta_i} x \cdot A_{ii} \alpha_i(t; m) + \sum_{j \in N_i} x \cdot A_{ij} \alpha_j(t; m).
	\end{align}
	
	where each $A_{ij} = w_{ij} A_i$ and $\alpha_i(t; m) =\frac{1}{t} \int_{0}^{t} m_i(t') dt'$ as defined by Ewerhart. We can, therefore, think of the network aggregative game as a network game in which each agent plays the same strategy against each of its neighbours, itself included. As such, any $m$ which satisfies the CTFP property for the equivalent network game also satisfies the CTFP requirement for the network aggregative game. 
	
	Continuing with this approach, let us look at the case where $\sum_i A_i = \textbf{0}_{n\times n}$ (i.e. a zero sum game). This means that $\sum_i u_i = 0$. Let $\mu_i^* = \lim_{t \rightarrow \infty} \alpha_i(t; m)$. More specifically, $\mu_i^*$ belongs to the set of accumulation points of $\alpha_i(\cdot; m)$ (which is set valued since the $BR_i$ map is set valued). To say that the game has `converged' we require that every $\mu^* = (\mu_1^*, ... \mu_p^*)$ is an NE. \ah{I'll follow through the proof of Ewerhart for the sake of completeness: }
	
	Let us take the Lyapunov function
	
	\begin{equation}
		L(\mu) = \sum_i \max_{e_i \in \Delta_i} \{u_i(e_i, w_{ii} \mu_i + \sum_{j \in N_i} w_{ij} \mu_j) - u_i(\mu_i, w_{ii} \mu_i + \sum_{j \in N_i} w_{ij} \mu_j) \}
	\end{equation}
	
	Using the same transformation as before:
	
	\begin{align}
		 u_i(e_i, w_{ii} \mu_i + \sum_{j \in N_i} w_{ij} \mu_j) & =  e_i \cdot A_i (w_{ii} \mu_i + \sum_{j \in N_i} w_{ij} \mu_j) \nonumber \\
		 & =  e_i \cdot (w_{ii} A_i) \mu_i + \sum_{j \in N_i} e_i \cdot (w_{ij} A_i) \mu_j \nonumber \\
		  & =  \sum_{j \in N_i \cup \{i\}} e_i \cdot A_{ij} \mu_j \nonumber 
	\end{align}
	
	Then
	
	\begin{align}
	L(\mu) &= \sum_i \max_{e_i \in \Delta_i}\sum_{j \in N_i \cup \{i\}} e_i \cdot A_{ij} \mu_j  - u_i(\mu_i, w_{ii} \mu_i + \sum_{j \in N_i} w_{ij} \mu_j) \} \nonumber \\
	&= \sum_i \max_{e_i \in \Delta_i} \{\sum_{j \in N_i \cup \{i\}} e_i \cdot A_{ij} \mu_j  \} - \sum_i  u_i(\mu_i, w_{ii} \mu_i + \sum_{j \in N_i} w_{ij} \mu_j) \nonumber \\
	&= \sum_i \max_{e_i \in \Delta_i} \{\sum_{j \in N_i \cup \{i\}} e_i \cdot A_{ij} \mu_j  \} \nonumber 
	\end{align}
	
	where the last equality holds because $\sum_i u_i = 0$. Again, if we were to relate this to a network game, in which each agent plays the same strategy against all its neighbours (itself included), then with the definition $ \tilde{u}_i (e_i, \mu_{-i}) := \sum_{j \in N_i \cup \{i\}} e_i \cdot A_{ij} \mu_j$, we still satisfy the zero sum condition for $\tilde{u}$. Now, we take a CTFP $m$ according to Ewerhart, with the condition that each agent plays the same strategy across all of its neighbours. This was shown by Ewerhart to converge. I.e. for any $\mu^*$ in the accumulation points of $\alpha(\cdot; m)$
	
	\begin{equation*}
		\tilde{u}_i(e_i, \mu_{-i}^*) \leq \tilde{u}_i(\mu_i^*, \mu_{-i}^*)
	\end{equation*}
	
	which, as we know, means that $\mu^*$ satisfies
	
	\begin{equation*}
		u_i(e_i, w_{ii} \mu_i^* + \sum_{j \in N_i} w_{ij} \mu_j^*) \leq  u_i(\mu_i^*, w_{ii} \mu_i^* + \sum_{j \in N_i} w_{ij} \mu_j^*)
	\end{equation*}

\end{document}