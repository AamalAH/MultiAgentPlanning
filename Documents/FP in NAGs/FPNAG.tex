\documentclass{article}
\usepackage[margin=2cm]{geometry}
\usepackage{amsmath, amsfonts, amsthm}
\usepackage{xcolor}
\usepackage{enumerate}

\theoremstyle{definition}
\newtheorem*{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem*{assumption}{Assumption}

\newcommand{\ah}[1]{\textcolor{blue}{AH: \textit{#1}}}
\newcommand{\svs}[1]{\textcolor{red}{FB: \textit{#1}}}

\title{Fictitious Play in Network Aggregative Games}
\author{AH, FB}

\begin{document}
	
	\maketitle
	
	
	\subsection*{The Model}
	
	We have a set of agents $V = \{1, ..., N \}$ which can be thought of as nodes on a graph $\{V, E, W\}$ where $E$ is the edge-set (i.e. the set of pairs $(i, j)$ such that i and j are connected) and $W$ is a weighted adjacency matrix $[W]_{ij} = w_{ij}$. Let $N_i := \{j \in V : (i, j) \in E\}$ be the set of player $i's$ neighbours. Note $w_{ij} = 0$ if $(i, j) \not\in E$, $w_{ij} \in (0, 1]$ if $(i, j) \in E$. We impose the normalisation condition that $\sum_{j \in N_i} w_{ij} = 1$. This requirement ensures that the aggregate strategy $\sum_{j \in N_i} w_{ij} x_j$ (where $x$ is a probability vector) remains a probability vector. For example, in the 3 player case:
	
	\begin{equation}
	\sigma_1 := w_{12} y + w_{13} z = 
	w_{12}
	\begin{bmatrix}
	y_1 \\ y_2 \\ 1 - y_1 - y_2
	\end{bmatrix}		
	+ 	w_{13}
	\begin{bmatrix}
	z_1 \\ z_2 \\ 1 - z_1 - z_2
	\end{bmatrix}	= 
	\begin{bmatrix}
	w_{12} y_1 + w_{13} z_1 \\ w_{12} y_2 + w_{13} z_2 \\ 1 - (w_{12} y_1 + w_{13} z_1) - (w_{12} y_2 + w_{13} z_2)
	\end{bmatrix}	
	\end{equation}
	
	In the continuous time case, we're also going to assume that each agent $i$ chooses a mixed strategy $x_i(t) \in \Delta_i$ at time $t$ from its strategy space $\Delta_i$ (which is an $N-$simplex). We assume that $i$ has just the one strategy that it can play against all of its neighbours.
	
	Once the strategy is chosen, the agent plays the game and receives payoff $u_i (x_i, \sigma_i)$, where $\sigma_i$ is the aggregate strategy vector that $i$ perceives. The best response map $BR_i$ maps any $\sigma_i$ to the set $\arg\max_{x \in \Delta_i} u_i (x, \sigma_i)$. Then $x_i$ is a `best response' to $\sigma_i$ if $x_i \in BR_i(\sigma_i)$.
	
	\begin{definition}(NE)
		The set of vectors $\{ x_i^*\}_{i = 1}^N$ is an NE if, for all $i$,
		
		\begin{equation*}
		x_i^* \in BR_i( w_{ii} x_i^* + \sum_{j \in N_i} w_{ij} x_j^*).
		\end{equation*}
		
	\end{definition}

	\subsection*{Starting Assumptions}
	
	\begin{enumerate}[I]
		\item The weights $w_{ij}$ are constant for all $i, j$.
		\item The payoffs $u_i$ are in matrix form, and so are bilinear.
		\item All agents update their strategies synchronously
		\item All agents have the same sized strategy space 
		\item The network is zero-sum in the sense that $\sum_i u_i(x_i, w_{ii} x_i + \sum_{j} w_{ij} x_j)$ for any set of strategies $(x_1, ..., x_N)$. 
	\end{enumerate}
	
	\subsection*{The Argument for Bilinear Payoffs}
	
	\textit{Zero-sum polymatrix games can model common situations in which nodes in a network interact pairwise and make decisions (for example, adopt one of many technologies, or choose one or more of their neighbors for preferential interaction)} (Cai et al (2016)))
	
	\ah{Need to find more references to put in here, most papers don't really give real world examples to justify this model.}
	
	\subsection*{Fictitious Play in Network Aggregative Games}
	
	For Fictitious Play (FP), we require that the agent plays a best response to the time average to a \emph{reference signal} $\sigma_i$ which is some convex combination of the agent's own strategy and that of its neighbours on the network. Under the above assumptions, this reference is given as
	
	\begin{equation*}
		\sigma_i (t) = \sum_{j} w_{ij} x_j (t).
	\end{equation*}
	
	Let us have the following definitions:
	
	\begin{align}
		\alpha_{\sigma_i}(t) = \frac{1}{t} \int_{0}^{t} \sigma_i(t') \, dt'\nonumber \\
		\alpha_i(t) = \frac{1}{t} \int_{0}^{t} x_i(t') \, dt', \nonumber
	\end{align}
	
	where $x_i(t')$ denotes the action played by $i$ at time $t'$. Now we notice
	
	\begin{align}
		\alpha_{\sigma_i}(t) = \frac{1}{t} \int_{0}^{t} \sigma_i(t') \, dt' = \frac{1}{t} \int_{0}^t \sum_{j} w_{ij} x_j(t') \, dt' = \sum_{j} w_{ij} \frac{1}{t} \int_{0}^t x_j(t') \, dt' = \sum_{j} w_{ij} \alpha_j(t) \nonumber \\
	\end{align}
	
	\paragraph{Continuous Time Fictitious Play (CTFP)} A CTFP is defined as a measurable map $m$ with components $m_i$ such that for all $i$ and all $t \geq 1$, $m_i: [0, \infty) \rightarrow \Delta_i$ satisfies $m_i(t) \in BR_i(\alpha_{\sigma_i})$ for all $t \geq 1$.
	
	We can think of this definition as saying that the player plays some generic strategy before $t = 1$, but beyond this it must play a best response to the time average of its reference signal.
	
	\paragraph{Discrete Time Fictitious Play (DTFP)} A DTFP is defined a sequence $\{x_{k}\}_{k=1}^{\infty}$ with components $x_{k, i}$ such that, for all $i$ and, for all $k \geq 1$, $x_{k, i} \in BR_i\left( \frac{1}{k} \sum_{t = 0}^{k - 1} \sigma_{k, i} \right)$.
	
	We can see that the DTFP is just the equivalent definition as the CTFP, except that the time domain is $\mathbb{Z}_+$ rather than $\mathbb{R}_+$. Nevertheless, the change from continuous to discrete is not trivial and we'll get to that soon.
	
	\paragraph{Convergence} We write $\alpha$ as the concatenation of all $\alpha_i$. Let $\Omega(\alpha)$ be  the set of all limit points for $\alpha$. Then, CTFP is said to have converged if any $\mu^* \in \Omega(\alpha)$ is contained in the set of Nash Equilibria of the game.
	
	With these definitions out of the way, we'll try to figure out whether, first, CTFP converges to a Nash Equilibrium. The process for doing this is as follows:
	
	\begin{enumerate}
		\item Show that a Nash equilibrium exists
		\item Show that a path satisfying the CTFP property exists
		\item Show that the associated $\Omega(\alpha)$ is contained in the set of NE.

	\end{enumerate}
	
	\subsection*{First Case: Aggregation is dependent only on its neighbours}
	
	We start with the following assumption
	
	\begin{assumption}[V]
	$w_{ii} = 0$ for all $i \in \{ 1, ..., N \}$
	\end{assumption}
	
	Under this assumption the $BR_i$ map becomes
	
	\begin{equation}
		BR_i(\sum_{j \in N_i} w_{ij} x_j) = \arg\max_{x \in \Delta_i} u_i(x_i,\sum_{j \in N_i} w_{ij} x_j)
	\end{equation}
	
	Under the assumption that the payoff function is bilinear and can be written as $u_i(x_i, \sigma_i) = x_i \cdot A^i \sigma_i$. Then 
	
	\begin{equation*}
		u_i(x_i, \sigma_i) = x_i \cdot A^i \sum_{j \in N_i} w_{ij} x_j = \sum_{j \in N_i} x_i \cdot A^{ij} x_j =: \sum_{j \in N_i} u_{ij}(x_i, x_j) 
	\end{equation*}
	
	where $A^{ij} := w_{ij} A^i$ and $u_{ij}$ is a bilinear payoff between $i$ and $j$ as defined by Ewerhart. Furthermore, the NE condition is now
	
	\begin{align}
			x_i^* & \in BR_i(\sum_{j \in N_i} w_{ij} x_j^*). \\
			& = \arg \max_{x \in \Delta_i} \sum_{j \in N_i} u_{ij}(x_i, x_j) 
	\end{align}
	
	 With this transformation, we can move from a network aggregative system to a network game formulation (as in Ewerhart) in which each agent $i$ plays a game $G_{ij}$ against $j$ with payoff $A^{ij}$ and with the added requirement that each agent plays the same strategy against each of its neighbours. With this change, we can apply Nash's Theorem to state that the Nash Equilibrium exists.
	
	Applying the same transformation, CTFP becomes the requirement that, in the equivalent network game, $m_i(t) \in \arg \max_{x \in \Delta_i} \sum_{j \in N_i} u_{ij}(x_i, \alpha_j)$ for all $t \geq 1$. Now, Ewerhart showed that, in a zero-sum network (where the sum of all $u_i$ is zero), such an $m$ exists and any such $m$ converges to an NE. This must therefore also be true of the network aggregative game.
	
	In any case, the fact that $m$ converges to an NE for the equivalent network game means that it converges for the NAG also. \ah{To make this precise, I'll follow through the proof of Ewerhart}
	
	\begin{theorem}
		For any zero-sum Network Aggregative Game which follows the above assumption, any CTFP $m$ has the property that $\Omega(\alpha)$ is contained within the set of NE of the game.
	\end{theorem}
	
	\begin{proof}
		Take the Lyapunov function
		\begin{align}
			L(\mu) & = \sum_i \max_{x \in \Delta_i} \{u_i(x, \sum_{j \in N_i} w_{ij} \mu_j) - u_i(\mu_i, \sum_{j \in N_i} w_{ij} \mu_j) \} \nonumber \\
			& = \sum_i \max_{x \in \Delta_i} \{u_i(x, \sum_{j \in N_i} w_{ij} \mu_j)\} - \sum_i u_i(\mu_i, \sum_{j \in N_i} w_{ij} \mu_j) \nonumber \\
			& = \sum_i \max_{x \in \Delta_i} \{u_i(x, \sum_{j \in N_i} w_{ij} \mu_j)\} \nonumber
		\end{align}
		
		where the last equality holds because we made the assumption of a zero sum game. Making the usual transformation, we consider that $i$ is now involved in a network game in which it plays the same strategy against each of its neighbours $j$ giving
		
		\begin{align}
			L(\mu) = \sum_i \max_{x \in \Delta_i} \sum_{j \in N_i}  u_{ij}(x, \mu_j) \nonumber \\
		\end{align}
		
		Now we take any CTFP $m$ and recall that it is found by playing the best response to $\alpha(t; m)$, which of course means that it maximises $\sum_{j \in N_i} u_{ij}$. Therefore
		
		\begin{align}
			L(\alpha(t)) & = \sum_i \sum_{j \in N_i} u_{ij}(m_i(t), \alpha_j(t)) \nonumber \\
			& = \sum_i \sum_{j \in N_i} m_i(t) A^{ij} \alpha_j(t)
		\end{align}
		 
		 Now if we were to follow on using Ewerhart's proof, we would find that any accumulation point of $\alpha(t; m)$ is an NE of the network game. I.e. if $\mu^*$ is this limit point, then it satisfies that, for any $x \in \Delta_i$
		 
		 \begin{align}
		 	\sum_{j \in N_i} u_{ij}(x, \mu_j^*) \leq 	\sum_{j \in N_i} u_{ij}(\mu_i^*, \mu_j^*) \nonumber
		 \end{align}
		 
		 Now if we reverse the transformation this means that, for the network aggregative game we have the condition that for any $x \in \Delta_i$
		 
		 \begin{align}
		 	u_{i}(x, \sum_{j \in N_i} w_{ij} \mu_j^*) \leq u_{i}(\mu_i^*, \sum_{j \in N_i} w_{ij} \mu_j^*)
		 \end{align}
		 
	\end{proof}
	\newpage
	
	\subsection*{Second Case}
	
	This case is much more complex and requires that we take into account all of the steps properly.
	
	\subsubsection*{Existence of the Nash Equilibrium}
	
	The NE condition here is the same as the original definition that we had, but I'll repeat it here for the sake of convenience. The set of vectors $\{ x_i^*\}_{i = 1}^N$ is an NE if, for all $i$,
	
	\begin{equation*}
		x_i^* \in BR_i( w_{ii} x_i^* + \sum_{j \in N_i} w_{ij} x_j^*).
	\end{equation*}
	
	Note that this requires
	
	\begin{align}
		x_i^* &\in \arg\max_{x \in \Delta_i} u_i(x_i, w_{ii} x_i + \sum_{j \in N_i} w_{ij} x_j^*) \nonumber\\
		&= \arg\max_{x \in \Delta_i} \bar{u}_i(x_i, \sum_{j \in N_i} w_{ij} x_j^*),
	\end{align}

	where we can find $\bar{u}_i$ through the following argument
	
	\begin{align}
		u_i(x_i, w_{ii} x_i + \sum_{j \in N_i} w_{ij} x_j^*) & = x_i \cdot A_i (w_{ii} x_i + \sum_{j \in N_i} w_{ij} x_j) \\
		 & = x_i \cdot (w_{ii} A_i)  x_i + \sum_{j \in N_i} u_{ij}(x_i, x_j) \\
		 & =: \bar{u}_i(x_i, \sum_{j \in N_i} w_{ij} x_j^*), \nonumber
	\end{align}
	
	where $u_{ij}$ is as previously defined. Note that, in order to get this formulation, we had to use the bilinear assumption (II) so that we could separate out the term involving $x_i$ easily. 
	
	To show existence of an NE we will need the following definition and Theorem.

	\begin{definition}[Upper Semi-Continuous]
		A compact-valued correspondence $\Phi: A \rightarrow B$ is \emph{upper semi-continuous} at a point $a$ if $g(a)$ is non-empty and if, for every sequence $a_n \rightarrow a$ and every sequence $(b_n)$ such that $b_n \in g(a_n)$ for all $n$, there exists a convergent subsequence of $(b_n)$ whose limit point $b$ is in $g(a)$.  
	\end{definition}

	\begin{theorem}[Kakutani]
		Let $K \subset \mathbb{R}^n$ be compact and convex and $\Phi: K \rightarrow K$ be closed or upper semi-continuous, with nonempty, convex and compact values. Then $\Phi$ has a fixed point.
	\end{theorem}

	Note that, when active on a simplex, the function $\Phi: \Delta \rightarrow \textbf{P}(\Delta)$, where $\textbf{P}(\Delta)$ denotes the nonempty, closed and convex subsets of $\Delta$ only has to satisfy the upper-semi continuity condition to admit a fixed point.

	\begin{theorem}[Existence of NE]
		Under the assumption (II), namely that the payoff function achieves a bilinear property, a Nash Equilibrium $\{x_i^*\}_{i = 1}^N$ exists.
	\end{theorem}

	\begin{proof}
		We begin by rewriting the NE condition by concatenating the set of NE vectors into one long colunn vector. This gives

		\begin{equation}
			\begin{bmatrix}
				x_1^* \\ . \\ . \\ . \\ x_N^*
			\end{bmatrix} \in
			\begin{bmatrix}
			\arg\max_{y \in \Delta_1} \bar{u}_1(y, \sum_{j \in N_i} w_{ij} x_j^*) \\ . \\ . \\ . \\ \arg\max_{y \in \Delta_N} \bar{u}_N(y, \sum_{j \in N_i} w_{ij} x_j^*)
			\end{bmatrix}	.
		\end{equation}

		We can rewrite the weighted summation in the $i$'th component of the right hand side as 

		\begin{equation}
			\sum_{j \in N_i} w_{ij} x_j^* = (w_{-i}^T \otimes I_n) \begin{bmatrix}
				x_1^* \\ . \\ . \\ . \\ x_N^*
			\end{bmatrix},
		\end{equation}
	
		in which $w_{-i}$ is a column vector containing $w_{ij}$ in the $j$'th element for all $j \in N(i)$ and 0 everywhere else (including in the $i$'th slot), $I_n$ is the $n \times n$ identity matrix and $\otimes$ is the kronecker product. For example, the form for agent 1, in the case of 2-action game is given by

		\begin{equation}
			(w_{-1}^T \otimes I_2) = [0, w_{12}, w_{13}, ..., w_{1n}] \otimes I_2 = 
			\begin{bmatrix}
				0 & 0 & w_{12} & 0 & ... & w_{1n} & 0 \\
				0 & 0 & 0 & w_{12} & ... & 0 & w_{1n} \\
			\end{bmatrix}
		\end{equation}
		
		So our condition becomes
		\begin{equation}
			\begin{bmatrix}
				x_1^* \\ . \\ . \\ . \\ x_N^*
			\end{bmatrix} \in
			\begin{bmatrix}
				\arg\max_{y \in \Delta_1} \bar{u}_1(y, (w_{-1}^T \otimes I_n) \begin{bmatrix}
					x_1^* \\ . \\ . \\ . \\ x_N^*
				\end{bmatrix}) \\ . \\ . \\ . \\ \arg\max_{y \in \Delta_N} \bar{u}_N(y, (w_{-N}^T \otimes I_n) \begin{bmatrix}
				x_1^* \\ . \\ . \\ . \\ x_N^*
			\end{bmatrix}))
			\end{bmatrix}	.
		\end{equation}

		This means that we achieve a Nash Equilibrium iff $\{ x_i^*\}_{i = 1}^N$ is a fixed point of the map
	
	
		\begin{equation}
			\begin{bmatrix}
				\arg\max_{y \in \Delta_1} \bar{u}_1(y, (w_{-1}^T \otimes I_n) ( \cdot )) \\ . \\ . \\ . \\ \arg\max_{y \in \Delta_N} \bar{u}_N(y, (w_{-N}^T \otimes I_n)( \cdot )))
			\end{bmatrix}	.
		\end{equation}


		Now, since the modified payoff $\bar{u}$ shares the same bilinear property as $u$, we can assert that it is continuous is its second argument. Therefore, the above vector valued map can be asserted to be continuous and so is upper semi-continuous. This continuity can be extended to the above concatenation of best responses. As such, we can apply Kakutani's Fixed Point Theorem to assert that the above map admits a fixed point.

	\end{proof}

	\subsubsection*{Existence of a CTFP}

	\begin{theorem}
		There exists a path $m$ which satisfies the property that, for all $i$, $m_i \in BR_i
		(\alpha_{\sigma_i})$ for almost all $t \geq 1$.
	\end{theorem}

	\begin{proof}
		Recall the definition of $\alpha_i(t)$

		\begin{equation*}
		\alpha_i(t) = \frac{1}{t} \int_{0}^{t} m_i(t') \, dt'
		\end{equation*}

		Then 

		\begin{align}
		\frac{d}{dt} \alpha_i(t) & = \frac{d}{dt} \frac{1}{t} \int_{0}^t m_i(t') dt' \nonumber \\
		& = \frac{1}{t} m_i(t) - \frac{1}{t} \alpha_i(t)
		\end{align}

		Now we assert that $m_i(t) \in BR_i(\alpha_{\sigma_t}) = \arg\max_{y \in \Delta_i} u_i(y,
		w_{ii} \alpha_i(t) + \sum_{j \in N(i)} w_{ij} \alpha_j(t))$. 

		Let us then define $\alpha(t)$ as the concatenation of all $\alpha_i(t)$

		\begin{equation}
			\alpha(t) = \begin{bmatrix}
				\alpha_1(t)^T, \ldots, \alpha_N(t)^T
			\end{bmatrix}^T \subset \mathbb{R}^{Nn}
		\end{equation}


		We can, therefore, write the aggregation as

		\begin{equation}
			(W \otimes I_n) \alpha(t) = \begin{bmatrix}
				\sum_{j \in N(1)} w_{1j} \alpha_j(t) \\
				.\\
				.\\
				.\\
				\sum_{j \in N(N)} w_{Nj} \alpha_j(t)
			\end{bmatrix} \subset \mathbb{R}^{Nn}
		\end{equation}

		I will write $(W \otimes I_n) \alpha(t)$ as $\alpha_W$ for convenience. Furthermore, using
		the bimatrix property of the game, we can say that

		\begin{equation}
			\begin{bmatrix}
				\arg\max_{y \in \Delta_1} y \cdot A_1 ( \alpha_W(t)_1) \\
				.\\
				.\\
				.\\
				\arg \max_{y \in \Delta_N} y \cdot A_n (\alpha_W(t)_N) 
			\end{bmatrix} = 
			\arg \max_{y \in \Delta} y \cdot \begin{bmatrix}
				A_1 & 0 & . & . & . & 0 \\
				0 & A_2 & . & . & . & 0 \\
				& & . & & & \\
				& & & . & & \\
				& & & & . & \\
				0 & 0 & . & . & . & A_N \\
			\end{bmatrix} \alpha_W(t) = \arg\max_{y \in \Delta} y \cdot \Lambda (W \otimes I_n)
			\alpha(t)
		\end{equation}

		in which $\Delta = \times_i \Delta_i$ and $\Lambda$ is the block diagonal matrix containing
		each $A_i$. 

		We can now write the differential inclusion as

		\begin{equation}
			\dot{\alpha(t)} \in \frac{1}{t} (\arg \max_{y \in \Delta}  \{y \cdot \Lambda (W \otimes
			I_n)
			\alpha(t) \}- \alpha(t))
		\end{equation}

		with the initial condition $\alpha(1) = \mu$. Then, the path $m$ is a CTFP if its
		corresponding $\alpha(t; m)$ is a solution to the above differential inclusion. Following
		the definition of (Harris 1998), a solution $\alpha(t)$ must satisfy

		\begin{enumerate}
			\item $\alpha(t)$ is locally Lipschitz
			\item $\alpha(1) = \mu$
			\item $\dot{\alpha}(t) \in \frac{1}{t} (\arg \max_{y \in \Delta}  \{y \cdot \Lambda (W \otimes
			I_n)
			\alpha(t) \}- \alpha(t))$ for almost all $t \in [1, \infty)$ 
		\end{enumerate}

		The question then remains, does the differential inclusion admit a solution? Using the
		results of Aubin and Cellina (see Harris 1998, paragraph below Prop. 6), can use the fact
		that the $\arg \max$ function is non-empty, compact and convex valued, bounded (all of
		these follow since the function acts from $\Delta$ to $\Delta$) and upper semi-continuous.
		With these facts in place, we can say that there is a CTFP for any initial value $\mu$.
		\ah{I believe this holds for any choice of $W$ as long as it is row stochastic so that
		the values remain inside $\Delta$ after aggregation}.
	\end{proof}
	
	\newpage
	
	\section*{Convergence Properties}

	I've spent some time trying to show convergence of the CTFP to a Nash Equilibrium, without the
	requirement that $w_{ii} = 0$. Unfortunately, it doesn't look like that is the case in general,
	at least with the other assumptions that we have made. Perhaps changing the requirement of the
	payoff functions or the aggregation method (e.g. to a non-linear one) would influence this, but
	for the bimatrix games that we've looked at so far, no luck.
	We can, however, say that there is a fixed point since the solution $\alpha(t; m)$, for any CTFP
	$m$ maps from a compact space to itself. Therefore, any sequence $\{\alpha(\tau_q; m)\}$ where
	$\tau_q \rightarrow \infty$ as $q \rightarrow \infty$ has all of its elements inside a compact
	set. Therefore, by the Bolzano-Wierstrass Theorem, this sequence has at least one limit point.
	We can say that this limit point corresponds to an NE when $w_{ii} = 0$, but I am trying to
	determine any other structure of the limit point for when this does not hold. For example, is it
	part of the `no regret' set?

	\newpage

	\begin{equation}
		x_i(t) \in BR_i \left( \frac{1}{t} \int_{0}^{t} \sigma_i(t') dt' \right).
	\end{equation}
	
	By the definition of Continuous Time Fictitious Play (CTFP) given by Ewerhart, we require that $m: [0, \infty) \rightarrow \times_i \Delta_i$ is a measurable mapping such that, for each $i$, $m_i(t) \in BR_i \left( \frac{1}{t} \int_{0}^{t} \sigma_i(t') dt' \right)$. Now notice,
	
	\begin{equation*}
		x_i \in BR_i \left( \frac{1}{t} \int_{0}^{t} \sigma_i(t') dt' \right) \iff  \in x_i\in BR_i \left( \frac{1}{t} \int_{0}^{t} [w_{ii} m_i(t') + \sum_{j \in N_i} w_{ij} m_j(t')] \, dt' \right)
	\end{equation*}
	
	Let us assume that $u_i$ takes the form $x \cdot A_i \sigma_i$ where $A_i$ is the payoff matrix associated with agent $i$. Then,
	
	\begin{align}
		& x_i \in \arg\max_{x \in \Delta_i} u_i(x,\frac{1}{t} \int_{0}^{t} [w_{ii} m_i(t') + \sum_{j \in N_i} w_{ij} m_j(t')] \, dt') \nonumber \\
		\iff & x_i \in \arg\max_{x \in \Delta_i} x \cdot A_i \left(\frac{1}{t} \int_{0}^{t} [w_{ii} m_i(t') + \sum_{j \in N_i} w_{ij} m_j(t')] \, dt' \right) \nonumber \\
		\iff & x_i \in \arg \max_{x \in \Delta_i} x \cdot (w_{ii} A_i) \left( \frac{1}{t} \int_{0}^{t} m_i(t')\right) + \sum_{j \in N_i} x \cdot (w_{ij} A_i) \left( \frac{1}{t} \int_{0}^{t} m_j(t')\right) \nonumber \\
		\iff & x_i \in \arg \max_{x \in \Delta_i} x \cdot A_{ii} \alpha_i(t; m) + \sum_{j \in N_i} x \cdot A_{ij} \alpha_j(t; m).
	\end{align}
	
	where each $A_{ij} = w_{ij} A_i$ and $\alpha_i(t; m) =\frac{1}{t} \int_{0}^{t} m_i(t') dt'$ as defined by Ewerhart. We can, therefore, think of the network aggregative game as a network game in which each agent plays the same strategy against each of its neighbours, itself included. As such, any $m$ which satisfies the CTFP property for the equivalent network game also satisfies the CTFP requirement for the network aggregative game. 
	
	Continuing with this approach, let us look at the case where $\sum_i A_i = \textbf{0}_{n\times n}$ (i.e. a zero sum game). This means that $\sum_i u_i = 0$. Let $\mu_i^* = \lim_{t \rightarrow \infty} \alpha_i(t; m)$. More specifically, $\mu_i^*$ belongs to the set of accumulation points of $\alpha_i(\cdot; m)$ (which is set valued since the $BR_i$ map is set valued). To say that the game has `converged' we require that every $\mu^* = (\mu_1^*, ... \mu_p^*)$ is an NE. \ah{I'll follow through the proof of Ewerhart for the sake of completeness: }
	
	Let us take the Lyapunov function
	
	\begin{equation}
		L(\mu) = \sum_i \max_{e_i \in \Delta_i} \{u_i(e_i, w_{ii} \mu_i + \sum_{j \in N_i} w_{ij} \mu_j) - u_i(\mu_i, w_{ii} \mu_i + \sum_{j \in N_i} w_{ij} \mu_j) \}
	\end{equation}
	
	Using the same transformation as before:
	
	\begin{align}
		 u_i(e_i, w_{ii} \mu_i + \sum_{j \in N_i} w_{ij} \mu_j) & =  e_i \cdot A_i (w_{ii} \mu_i + \sum_{j \in N_i} w_{ij} \mu_j) \nonumber \\
		 & =  e_i \cdot (w_{ii} A_i) \mu_i + \sum_{j \in N_i} e_i \cdot (w_{ij} A_i) \mu_j \nonumber \\
		  & =  \sum_{j \in N_i \cup \{i\}} e_i \cdot A_{ij} \mu_j \nonumber 
	\end{align}
	
	Then
	
	\begin{align}
	L(\mu) &= \sum_i \max_{e_i \in \Delta_i}\sum_{j \in N_i \cup \{i\}} e_i \cdot A_{ij} \mu_j  - u_i(\mu_i, w_{ii} \mu_i + \sum_{j \in N_i} w_{ij} \mu_j) \} \nonumber \\
	&= \sum_i \max_{e_i \in \Delta_i} \{\sum_{j \in N_i \cup \{i\}} e_i \cdot A_{ij} \mu_j  \} - \sum_i  u_i(\mu_i, w_{ii} \mu_i + \sum_{j \in N_i} w_{ij} \mu_j) \nonumber \\
	&= \sum_i \max_{e_i \in \Delta_i} \{\sum_{j \in N_i \cup \{i\}} e_i \cdot A_{ij} \mu_j  \} \nonumber 
	\end{align}
	
	where the last equality holds because $\sum_i u_i = 0$. Again, if we were to relate this to a network game, in which each agent plays the same strategy against all its neighbours (itself included), then with the definition $ \tilde{u}_i (e_i, \mu_{-i}) := \sum_{j \in N_i \cup \{i\}} e_i \cdot A_{ij} \mu_j$, we still satisfy the zero sum condition for $\tilde{u}$. Now, we take a CTFP $m$ according to Ewerhart, with the condition that each agent plays the same strategy across all of its neighbours. This was shown by Ewerhart to converge. I.e. for any $\mu^*$ in the accumulation points of $\alpha(\cdot; m)$
	
	\begin{equation*}
		\tilde{u}_i(e_i, \mu_{-i}^*) \leq \tilde{u}_i(\mu_i^*, \mu_{-i}^*)
	\end{equation*}
	
	which, as we know, means that $\mu^*$ satisfies
	
	\begin{equation*}
		u_i(e_i, w_{ii} \mu_i^* + \sum_{j \in N_i} w_{ij} \mu_j^*) \leq  u_i(\mu_i^*, w_{ii} \mu_i^* + \sum_{j \in N_i} w_{ij} \mu_j^*)
	\end{equation*}
	
	
\end{document}