% This file was created with JabRef 2.10.
% Encoding: UTF-8

@book{ZinnJustin2009,
  added-at = {2009-01-24T05:37:19.000+0100},
  asin = {0198509235},
  author = {Zinn-Justin, Jean},
  biburl = {https://www.bibsonomy.org/bibtex/2bdb1f0fc1fa77c70c13eefdbffbfcd92/random3f},
  description = {Quantum Field Theory and Critical Phenomena…Amazon.co.uk: Jean Zinn-Justin: Books},
  dewey = {530.143},
  ean = {9780198509233},
  edition = 4,
  interhash = {e2513a79fbd9036892f311c4d95fabf1},
  intrahash = {bdb1f0fc1fa77c70c13eefdbffbfcd92},
  isbn = {0198509235},
  keywords = {},
  publisher = {Clarendon Press},
  timestamp = {2009-06-27T12:18:11.000+0200},
  title = {Quantum Field Theory and Critical Phenomena (International Series of Monographs on Physics)},
  year = 2002
}

@book{Coolen2005,
author = {Coolen, A.C.C.},
title = {The Mathematical Theory of Minority Games: Statistical Mechanics of Interacting Agents  (Oxford Finance Series)},
year = {2005},
isbn = {0198520808},
publisher = {Oxford University Press, Inc.},
address = {USA}

@Article{Abukhalil2016DeploymentRobots,
  Title                    = {{Deployment environment for a swarm of heterogeneous robots}},
  Author                   = {Abukhalil, Tamer and Patil, Madhav and Patel, Sarosh and Sobh, Tarek},
  Journal                  = {Robotics},
  Year                     = {2016},

  Doi                      = {10.3390/robotics5040022},
  ISSN                     = {22186581},
  Keywords                 = {Dynamic robotic coordination, Heterogeneous swarm agents, Reconfigurable robotic agents, Robotics interactive software, Robots deployment environment}
}

@InProceedings{Adhvaryu2017,
  Title                    = {{Design of fuzzy based intelligent controller for autonomous mobile robot navigation}},
  Author                   = {Adhvaryu, Aniket D. and Adarsh, S. and Ramchandran, K. I.},
  Booktitle                = {2017 International Conference on Advances in Computing, Communications and Informatics, ICACCI 2017},
  Year                     = {2017},
  Month                    = {11},
  Pages                    = {841--846},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.},
  Volume                   = {2017-Janua},

  Doi                      = {10.1109/ICACCI.2017.8125946},
  ISBN                     = {9781509063673},
  Keywords                 = {Autonomous mobile robot, Data fusion, Fuzzy inference system, LiDAR, Obstacle avoidance, Ultrasonic}
}

@TechReport{Ahmed2015,
  Title                    = {{Path Planning of Mobile Robot by using Modified Optimized Potential Field Method}},
  Author                   = {Ahmed, Alaa A and Abdalla, Turki Y and Abed, Ali A},
  Year                     = {2015},
  Number                   = {4},

  Booktitle                = {International Journal of Computer Applications},
  Keywords                 = {Artificial Potential Fields, PID Controller, Particle swarm optimization, Path Planning},
  Pages                    = {975--8887},
  Url                      = {https://pdfs.semanticscholar.org/8c7c/3c723514b338a09deb589da80c093d9dc116.pdf},
  Volume                   = {113}
}

@Article{Alkafaween2017,
  Title                    = {{On enhancing genetic algorithms using new crossovers}},
  Author                   = {Alkafaween, Esra'a and Hassanat, Ahmad B.A.},
  Journal                  = {International Journal of Computer Applications in Technology},
  Year                     = {2017},
  Number                   = {3},
  Pages                    = {202},
  Volume                   = {55},

  Doi                      = {10.1504/ijcat.2017.10005868},
  ISSN                     = {0952-8091},
  Publisher                = {Inderscience Publishers}
}

@InProceedings{Alsaab2014,
  Title                    = {{Improving velocity obstacle approach for obstacle avoidance in indoor environments}},
  Author                   = {Alsaab, Ahmad and Bicker, Robert},
  Booktitle                = {2014 UKACC International Conference on Control, CONTROL 2014 - Proceedings},
  Year                     = {2014},
  Month                    = {10},
  Pages                    = {325--330},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.},

  Doi                      = {10.1109/CONTROL.2014.6915161},
  ISBN                     = {9781479950119},
  Keywords                 = {Velocity obstacle, collision time, non-circular objects}
}

@TechReport{Amato2017Decision-MakingLearning,
  Title                    = {{Decision-Making Under Uncertainty in Multi-Agent and Multi-Robot Systems: Planning and Learning}},
  Author                   = {Amato, Christopher},
  Year                     = {2017},

  Keywords                 = {Agent-based and Multi-agent Systems: Multi-agent Learning, Agent-based and Multi-agent Systems: Multi-agent Planning, Machine Learning: Reinforcement Learning, Robotics: Multi-Robot Systems},
  Url                      = {https://youtu.be/34xHxXrnPHw,}
}

@InProceedings{Amato2015,
  Title                    = {{Planning for decentralized control of multiple robots under uncertainty}},
  Author                   = {Amato, Christopher and Konidaris, George and Cruz, Gabriel and Maynor, Christopher A. and How, Jonathan P. and Kaelbling, Leslie P.},
  Booktitle                = {2015 IEEE International Conference on Robotics and Automation (ICRA)},
  Year                     = {2015},
  Month                    = {5},
  Pages                    = {1241--1248},
  Publisher                = {IEEE},

  Doi                      = {10.1109/ICRA.2015.7139350},
  ISBN                     = {978-1-4799-6923-4},
  Url                      = {http://ieeexplore.ieee.org/document/7139350/}
}

@InProceedings{Amato2015PlanningUncertainty,
  Title                    = {{Planning for decentralized control of multiple robots under uncertainty}},
  Author                   = {Amato, Christopher and Konidaris, George and Cruz, Gabriel and Maynor, Christopher A. and How, Jonathan P. and Kaelbling, Leslie P.},
  Booktitle                = {Proceedings - IEEE International Conference on Robotics and Automation},
  Year                     = {2015},
  Number                   = {June},
  Pages                    = {1241--1248},
  Volume                   = {2015-June},

  Arxivid                  = {1402.2871},
  Doi                      = {10.1109/ICRA.2015.7139350},
  ISSN                     = {10504729},
  Url                      = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7139350&tag=1}
}

@Article{Amir2019SummarizingStrategies,
  Title                    = {{Summarizing agent strategies}},
  Author                   = {Amir, Ofra and Doshi-Velez, Finale and Sarne, David},
  Journal                  = {Autonomous Agents and Multi-Agent Systems},
  Year                     = {2019},

  Month                    = {9},
  Number                   = {5},
  Pages                    = {628--644},
  Volume                   = {33},

  Doi                      = {10.1007/s10458-019-09418-w},
  ISSN                     = {1387-2532},
  Publisher                = {Springer Science and Business Media LLC}
}

@Article{Aras2010AnPOMDPs,
  Title                    = {{An investigation into mathematical programming for finite horizon decentralized POMDPs}},
  Author                   = {Aras, Raghav and Dutech, Alain},
  Journal                  = {Journal of Artificial Intelligence Research},
  Year                     = {2010},

  Month                    = {1},
  Pages                    = {329--396},
  Volume                   = {37},

  Doi                      = {10.1613/jair.2915},
  ISSN                     = {10769757}
}

@Article{Arbanas2018DecentralizedTeams,
  Title                    = {{Decentralized planning and control for UAV-UGV cooperative teams}},
  Author                   = {Arbanas, Barbara and Ivanovic, Antun and Car, Marko and Orsag, Matko and Petrovic, Tamara and Bogdan, Stjepan},
  Journal                  = {Autonomous Robots},
  Year                     = {2018},
  Pages                    = {1601--1618},
  Volume                   = {42},

  Doi                      = {10.1007/s10514-018-9712-y},
  Keywords                 = {Aerial manipulation, Decentralized planning, Heterogeneous robotics systems, Unmanned aerial system},
  Url                      = {https://doi.org/10.1007/s10514-018-9712-y}
}

@TechReport{Arora2019OnlineOcclusion,
  Title                    = {{Online Inverse Reinforcement Learning Under Occlusion}},
  Author                   = {Arora, Saurabh and Doshi, Prashant and Banerjee, Bikramjit},
  Year                     = {2019},

  Keywords                 = {Inverse Reinforcement Learning, Online Learning, Reinforcement Learning, Robot Learning, Robotics},
  Publisher                = {AAMAS},
  Url                      = {www.ifaamas.org}
}

@Article{Ayanian2019DART:Teams,
  Title                    = {{DART: Diversity-enhanced Autonomy in Robot Teams}},
  Author                   = {Ayanian, Nora},
  Journal                  = {International Journal of Robotics Research},
  Year                     = {2019},

  Month                    = {10},

  Doi                      = {10.1177/0278364919839137},
  ISSN                     = {17413176},
  Keywords                 = {Multi-robot systems, multi-agent systems},
  Publisher                = {SAGE Publications Inc.}
}

@Article{Borgers1997,
  Title                    = {{Learning through reinforcement and replicator dynamics}},
  Author                   = {B{\"{o}}rgers, Tilman and Sarin, Rajiv},
  Journal                  = {Journal of Economic Theory},
  Year                     = {1997},

  Month                    = {nov},
  Number                   = {1},
  Pages                    = {1--14},
  Volume                   = {77},

  Abstract                 = {This paper considers a version of R. R. Bush and F. Mosteller's (1951,Psych. Rev.58, 313-323; 1955, "Stochastic Models for Learning," Wiley, New York) stochastic learning theory in the context of games. We show that in a continuous time limit the learning model converges to the replicator dynamics of evolutionary game theory. Thus we provide a non-biological interpretation of evolutionary game theory.Journal of Economic LiteratureClassification Numbers: C72, D83. {\textcopyright} 1997 Academic Press.},
  Doi                      = {10.1006/jeth.1997.2319},
  File                     = {:home/aamalh/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/B{\"{o}}rgers, Sarin - 1997 - Learning through reinforcement and replicator dynamics.pdf:pdf},
  ISSN                     = {00220531},
  Mendeley-groups          = {STAI/Literature Review/MARL}
}

@Article{Bailey2019FiniteDescent-Ascent,
  Title                    = {{Finite Regret and Cycles with Fixed Step-Size via Alternating Gradient Descent-Ascent}},
  Author                   = {Bailey, James P and Gidel, Gauthier},
  Year                     = {2019},
  Pages                    = {1--15},

  Arxivid                  = {arXiv:1907.04392v1}
}

@TechReport{Bailey2019Multi-AgentSystem,
  Title                    = {{Multi-Agent Learning in Net-work Zero-Sum Games is a Hamiltonian System}},
  Author                   = {Bailey, James P and Piliouras, Georgios},
  Year                     = {2019},

  Booktitle                = {IFAAMAS},
  Url                      = {www.ifaamas.org},
  Volume                   = {9}
}

@InProceedings{Baklouti2015,
  Title                    = {{Autonomous mobile robot navigation coupling fuzzy logic and reactive DVZ 3D obstacle avoidance control}},
  Author                   = {Baklouti, Emna and Jallouli, Mohamed and Ben Amor, Nader and Titi, Sondes and Nafti, Ahlem},
  Booktitle                = {INISTA 2015 - 2015 International Symposium on Innovations in Intelligent SysTems and Applications, Proceedings},
  Year                     = {2015},
  Month                    = {9},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.},

  Doi                      = {10.1109/INISTA.2015.7276748},
  ISBN                     = {9781467390965},
  Keywords                 = {3D obstacle, Autonomous robot, DVZ, FLC, Obstacle avoidance, Reactive control}
}

@Book{Barber2012,
  Title                    = {{Bayesian Reasoning and Machine Learning}},
  Author                   = {Barber, D},
  Publisher                = {Cambridge University Press},
  Year                     = {2012}
}

@InProceedings{Bardi1991DifferentialDisturbances,
  Title                    = {{Differential games and totally risk-averse optimal control of systems with small disturbances}},
  Author                   = {Bardi, Martino and Sartori, Caterina},
  Booktitle                = {Lecture Notes in Control and Information Sciences},
  Year                     = {1991},
  Pages                    = {91--99},
  Publisher                = {Publ by Springer-Verlag Berlin},
  Volume                   = {156},

  Doi                      = {10.1007/bfb0040230},
  ISSN                     = {01708643}
}

@Misc{Beauregard,
  Title                    = {{Improving the Beginner’s PID – Introduction « Project Blog}},

  Author                   = {Beauregard, Brett},

  Url                      = {http://brettbeauregard.com/blog/2011/04/improving-the-beginners-pid-introduction/?fbclid=IwAR0THEfOHcZrEy6XChFd-4apMfGsoOZ1KC1iLWEcK-LUvhERLpxJROuOiq8}
}

@Article{Bellomo2017,
  Title                    = {{A quest toward a mathematical theory of the dynamics of swarms}},
  Author                   = {Bellomo, Nicola and Ha, Seung Yeal},
  Journal                  = {Mathematical Models and Methods in Applied Sciences},
  Year                     = {2017},

  Month                    = {apr},
  Number                   = {4},
  Pages                    = {745--770},
  Volume                   = {27},

  Abstract                 = {This paper addresses some preliminary steps toward the modeling and qualitative analysis of swarms viewed as living complex systems. The approach is based on the methods of kinetic theory and statistical mechanics, where interactions at the microscopic scale are nonlocal, nonlinearly additive and modeled by theoretical tools of stochastic game theory. Collective learning theory can play an important role in the modeling approach. We present a kinetic equation incorporating the Cucker-Smale flocking force and stochastic game theoretic interactions in collision operators. We also present a sufficient framework leading to the asymptotic velocity alignment and global existence of smooth solutions for the proposed kinetic model with a special kernel. Analytic results on the global existence and flocking dynamics are presented, while the last part of the paper looks ahead to research perspectives.},
  Doi                      = {10.1142/S0218202517500154},
  ISSN                     = {02182025},
  Keywords                 = {Collective dynamics,Cucker-Smale flocking,collective behavior,learning,living complex systems,nonlinear interactions,self-organization,swarming},
  Publisher                = {World Scientific Publishing Co. Pte Ltd}
}

@InProceedings{Berkenkamp2017,
  Title                    = {{Safe model-based reinforcement learning with stability guarantees}},
  Author                   = {Berkenkamp, Felix and Turchetta, Matteo and Schoellig, Angela P and Krause, Andreas},
  Booktitle                = {Advances in Neural Information Processing Systems},
  Year                     = {2017},
  Pages                    = {909--919},
  Volume                   = {2017-Decem},

  Abstract                 = {Reinforcement learning is a powerful paradigm for learning optimal policies from experimental data. However, to find optimal policies, most reinforcement learning algorithms explore all possible actions, which may be harmful for real-world systems. As a consequence, learning algorithms are rarely applied on safety-critical systems in the real world. In this paper, we present a learning algorithm that explicitly considers safety, defined in terms of stability guarantees. Specifically, we extend control-theoretic results on Lyapunov stability verification and show how to use statistical models of the dynamics to obtain high-performance control policies with provable stability certificates. Moreover, under additional regularity assumptions in terms of a Gaussian process prior, we prove that one can effectively and safely collect data in order to learn about the dynamics and thus both improve control performance and expand the safe region of the state space. In our experiments, we show how the resulting algorithm can safely optimize a neural network policy on a simulated inverted pendulum, without the pendulum ever falling down.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1705.08551},
  Eprint                   = {1705.08551},
  File                     = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Berkenkamp et al. - Unknown - Safe Model-based Reinforcement Learning with Stability Guarantees.pdf:pdf},
  ISSN                     = {10495258}
}

@InProceedings{Berkenkamp2017SafeGuarantees,
  Title                    = {{Safe model-based reinforcement learning with stability guarantees}},
  Author                   = {Berkenkamp, Felix and Turchetta, Matteo and Schoellig, Angela P and Krause, Andreas},
  Booktitle                = {Advances in Neural Information Processing Systems},
  Year                     = {2017},
  Pages                    = {909--919},
  Volume                   = {2017-Decem},

  Arxivid                  = {1705.08551},
  ISSN                     = {10495258}
}

@Misc{BernardineDias2006Market-basedAnalysis,
  Title                    = {{Market-based multirobot coordination: A survey and analysis}},

  Author                   = {Bernardine Dias, M. and Zlot, Robert and Kalra, Nidhi and Stentz, Anthony},
  Month                    = {7},
  Year                     = {2006},

  Booktitle                = {Proceedings of the IEEE},
  Doi                      = {10.1109/JPROC.2006.876939},
  ISSN                     = {00189219},
  Keywords                 = {Auctions, Market-based coordination, Multirobot teams, Resource allocation, Task allocation},
  Number                   = {7},
  Pages                    = {1257--1270},
  Volume                   = {94}
}

@TechReport{Bhalla2019TrainingLearning,
  Title                    = {{Training Cooperative Agents for Multi-Agent Reinforcement Learning}},
  Author                   = {Bhalla, Sushrut and Subramanian, Sriram G and Crowley, Mark},
  Year                     = {2019},

  Arxivid                  = {1606.01540},
  Keywords                 = {Autonomous Driving, MARL, Multi-Agent Reinforcement Learning, MultiAgent Systems, Reinforcement Learning},
  Url                      = {www.ifaamas.org}
}

@InProceedings{Blackmore2007,
  Title                    = {{Robust, optimal predictive control of jump Markov Linear Systems using particles}},
  Author                   = {Blackmore, Lars and Bektassov, Askar and Ono, Masahiro and Williams, Brian C.},
  Booktitle                = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2007},
  Pages                    = {104--117},
  Volume                   = {4416 LNCS},

  Abstract                 = {Hybrid discrete-continuous models, such as Jump Markov Linear Systems, are convenient tools for representing many real-world systems; in the case of fault detection, discrete jumps in the continuous dynamics are used to model system failures. Stochastic uncertainty in hybrid systems arises in both the continuous dynamics, in the form of uncertain state estimation, disturbances or uncertain modeling, and in the discrete dynamics, which are themselves stochastic. In this paper we present a novel method for optimal predictive control of Jump Markov Linear Systems that is robust to both continuous and discrete uncertainty. The approach extends our previous 'particle control' approach, which approximates the predicted distribution of the system state using a finite number of particles. Here, we present a weighted particle control approach, which uses importance weighting to ensure that low probability events such as failures are considered. We demonstrate the method with a car braking scenario. {\textcopyright} Springer-Verlag Berlin Heidelberg 2007.},
  Doi                      = {10.1007/978-3-540-71493-4_11},
  ISBN                     = {9783540714927},
  ISSN                     = {03029743}
}

@TechReport{BlochInterdisciplinaryEdition,
  Title                    = {{Interdisciplinary Applied Mathematics 24 Nonholonomic Mechanics and Control Second Edition}},
  Author                   = {Bloch, A M and Baillieul, J and Crouch, P and Marsden, J E and Zenkov, D},

  Url                      = {http://www.springer.com/series/1390}
}

@Misc{Bloembergen2015,
  Title                    = {{Evolutionary dynamics of multi-agent learning: A survey}},

  Author                   = {Bloembergen, Daan and Tuyls, Karl and Hennes, Daniel and Kaisers, Michael},
  Month                    = {aug},
  Year                     = {2015},

  Abstract                 = {The interaction of multiple autonomous agents gives rise to highly dynamic and nondeterministic environments, contributing to the complexity in applications such as automated financial markets, smart grids, or robotics. Due to the sheer number of situations that may arise, it is not possible to foresee and program the optimal behaviour for all agents beforehand. Consequently, it becomes essential for the success of the system that the agents can learn their optimal behaviour and adapt to new situations or circumstances. The past two decades have seen the emergence of reinforcement learning, both in single and multiagent settings, as a strong, robust and adaptive learning paradigm. Progress has been substantial, and a wide range of algorithms are now available. An important challenge in the domain of multi-agent learning is to gain qualitative insights into the resulting system dynamics. In the past decade, tools and methods from evolutionary game theory have been successfully employed to study multi-agent learning dynamics formally in strategic interactions. This article surveys the dynamical models that have been derived for various multi-agent reinforcement learning algorithms, making it possible to study and compare them qualitatively. Furthermore, new learning algorithms that have been introduced using these evolutionary game theoretic tools are reviewed. The evolutionary models can be used to study complex strategic interactions. Examples of such analysis are given for the domains of automated trading in stock markets and collision avoidance in multi-robot systems. The paper provides a roadmap on the progress that has been achieved in analysing the evolutionary dynamics of multi-agent learning by highlighting the main results and accomplishments.},
  Booktitle                = {Journal of Artificial Intelligence Research},
  Doi                      = {10.1613/jair.4818},
  File                     = {:home/aamalh/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bloembergen et al. - 2015 - Evolutionary dynamics of multi-agent learning A survey.pdf:pdf},
  ISSN                     = {10769757},
  Mendeley-groups          = {STAI/Literature Review/MARL},
  Pages                    = {659--697},
  Publisher                = {AI Access Foundation},
  Volume                   = {53}
}

@Article{Boone2019FromTheory,
  Title                    = {{From Darwin to Poincar{\textbackslash}'e and von Neumann: Recurrence and Cycles in Evolutionary and Algorithmic Game Theory}},
  Author                   = {Boone, Victor and Piliouras, Georgios},
  Year                     = {2019},

  Arxivid                  = {1910.01334},
  Url                      = {http://arxiv.org/abs/1910.01334}
}

@TechReport{Borenstein1991,
  Title                    = {{THE VECTOR FIELD HISTOGRAM-FAST OBSTACLE AVOIDANCE FOR MOBILE ROBOTS}},
  Author                   = {Borenstein, by J and Koren, Y and Member, Senior},
  Year                     = {1991},
  Number                   = {3},

  Booktitle                = {IEEE Journal of Robotics and Automation},
  Pages                    = {278--288},
  Url                      = {http://www-personal.umich.edu/~johannb/Papers/paper16.pdf},
  Volume                   = {7}
}

@Article{Borzi2015,
  Title                    = {{Modeling and control through leadership of a refined flocking system}},
  Author                   = {Borz{\`{i}}, Alfio and Wongkaew, Suttida},
  Journal                  = {Mathematical Models and Methods in Applied Sciences},
  Year                     = {2015},

  Month                    = {feb},
  Number                   = {2},
  Pages                    = {255--282},
  Volume                   = {25},

  Abstract                 = {A new refined flocking model that includes self-propelling, friction, attraction and repulsion, and alignment features is presented. This model takes into account various behavioral phenomena observed in biological and social systems. In addition, the presence of a leader is included in the system in order to develop a control strategy for the flocking model to accomplish desired objectives. Specifically, a model predictive control scheme is proposed that requires the solution of a sequence of open-loop optimality systems. An accurate Runge-Kutta scheme to discretize the optimality systems and a nonlinear conjugate gradient solver are implemented and discussed. Numerical experiments are performed that investigate the properties of the refined flocking model and demonstrate the ability of the control strategy to drive the flocking system to attain a desired target configuration and to follow a given trajectory.},
  Doi                      = {10.1142/S0218202515500098},
  ISSN                     = {02182025},
  Keywords                 = {Optimal control theory,Runge-Kutta method.,Swarming systems},
  Publisher                = {World Scientific Publishing Co. Pte Ltd}
}

@Article{Bowling2002,
  Title                    = {{Multiagent learning using a variable learning rate}},
  Author                   = {Bowling, Michael and Veloso, Manuela},
  Journal                  = {Artificial Intelligence},
  Year                     = {2002},

  Month                    = {apr},
  Number                   = {2},
  Pages                    = {215--250},
  Volume                   = {136},

  Abstract                 = {Learning to act in a multiagent environment is a difficult problem since the normal definition of an optimal policy no longer applies. The optimal policy at any moment depends on the policies of the other agents. This creates a situation of learning a moving target. Previous learning algorithms have one of two shortcomings depending on their approach. They either converge to a policy that may not be optimal against the specific opponents' policies, or they may not converge at all. In this article we examine this learning problem in the framework of stochastic games. We look at a number of previous learning algorithms showing how they fail at one of the above criteria. We then contribute a new reinforcement learning technique using a variable learning rate to overcome these shortcomings. Specifically, we introduce the WoLF principle, "Win or Learn Fast", for varying the learning rate. We examine this technique theoretically, proving convergence in self-play on a restricted class of iterated matrix games. We also present empirical results on a variety of more general stochastic games, in situations of self-play and otherwise, demonstrating the wide applicability of this method. {\textcopyright} 2002 Published by Elsevier Science B.V.},
  Doi                      = {10.1016/S0004-3702(02)00121-2},
  ISSN                     = {00043702},
  Keywords                 = {Game theory,Multiagent learning,Reinforcement learning}
}

@InProceedings{Brafman2013QualitativeDomains,
  Title                    = {{Qualitative planning under partial observability in multi-agent domains}},
  Author                   = {Brafman, Ronen I. and Shani, Guy and Zilberstein, Shlomo},
  Booktitle                = {Proceedings of the 27th AAAI Conference on Artificial Intelligence, AAAI 2013},
  Year                     = {2013},
  Pages                    = {130--137},

  ISBN                     = {9781577356158}
}

@TechReport{Bredereck2019HedonicGames,
  Title                    = {{Hedonic Diversity Games}},
  Author                   = {Bredereck, Robert and Elkind, Edith and Igarashi, Ayumi},
  Year                     = {2019},

  Keywords                 = {Hedonic games, Schelling segregation, fractional hedonic games},
  Url                      = {www.ifaamas.org}
}

@InCollection{Breitner1994ReentryGame,
  Title                    = {{Reentry Trajectory Optimization under Atmospheric Uncertainty as a Differential Game}},
  Author                   = {Breitner, Michael H. and Pesch, H. Joseph},
  Booktitle                = {Advances in Dynamic Games and Applications},
  Publisher                = {Birkh{\"{a}}user Boston},
  Year                     = {1994},
  Pages                    = {70--86},

  Doi                      = {10.1007/978-1-4612-0245-5{\_}4}
}

@Article{Brunton2019MachineMechanics,
  Title                    = {{Machine Learning for Fluid Mechanics}},
  Author                   = {Brunton, Steven L and Noack, Bernd R and Koumoutsakos, Petros},
  Year                     = {2019},

  Arxivid                  = {1905.11075v2},
  Doi                      = {10.1146/((please)},
  Keywords                 = {control, data-driven modeling, machine learning, optimization},
  Url                      = {https://doi.org/10.1146/}
}

@Article{Burger2019,
  Title                    = {{Instantaneous control of interacting particle systems in the mean-field limit}},
  Author                   = {Burger, Martin and Pinnau, Rene and Totzeck, Claudia and Tse, Oliver and Roth, Andreas},
  Year                     = {2019},

  Month                    = {mar},

  Abstract                 = {Controlling large particle systems in collective dynamics by a few agents is a subject of high practical importance, e.g., in evacuation dynamics. In this paper we study an instantaneous control approach to steer an interacting particle system into a certain spatial region by repulsive forces from a few external agents, which might be interpreted as shepherd dogs leading sheep to their home. We introduce an appropriate mathematical model and the corresponding optimization problem. In particular, we are interested in the interaction of numerous particles, which can be approximated by a mean-field equation. Due to the high-dimensional phase space this will require a tailored optimization strategy. The arising control problems are solved using adjoint information to compute the descent directions. Numerical results on the microscopic and the macroscopic level indicate the convergence of optimal controls and optimal states in the mean-field limit,i.e., for an increasing number of particles.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1903.12407},
  Doi                      = {10.1016/j.jcp.2019.109181},
  Eprint                   = {1903.12407},
  File                     = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Burger et al. - 2019 - Instantaneous control of interacting particle systems in the mean-field limit.pdf:pdf},
  Url                      = {http://arxiv.org/abs/1903.12407 http://dx.doi.org/10.1016/j.jcp.2019.109181}
}

@TechReport{Busoniu2006Multi-agentSurvey,
  Title                    = {{Multi-agent reinforcement learning: A survey * "Multi-agent reinforcement learning: A survey Multi-Agent Reinforcement Learning: A Survey}},
  Author                   = {Bus¸oniu, L Bus¸oniu and Babu{\v{s}}ka, R and De Schutter, B and Bus¸oniu, Lucian Bus¸oniu and Babu{\v{s}}ka, Robert and De Schutter, Bart},
  Year                     = {2006},

  ISBN                     = {3115278.66.7},
  Keywords                 = {distributed control, game theory, multi-agent systems, reinforcement learning},
  Pages                    = {527--532}
}

@InProceedings{Cacitti,
  Title                    = {{Reactive behaviours of mobile manipulators based on the DVZ approach}},
  Author                   = {Cacitti, A. and Zapata, R.},
  Booktitle                = {Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164)},
  Pages                    = {680--685},
  Publisher                = {IEEE},
  Volume                   = {1},

  Doi                      = {10.1109/ROBOT.2001.932629},
  ISBN                     = {0-7803-6576-3},
  Url                      = {http://ieeexplore.ieee.org/document/932629/}
}

@Book{Camerer2009,
  Title                    = {Behavioral game theory},
  Author                   = {Camerer, {Colin F.}},
  Publisher                = {Princeton Univ. Press [u.a.]},
  Year                     = {2003},

  Address                  = {Princeton, NJ [u.a.]},
  Series                   = {The roundtable series in behavioral economics},

  Added-at                 = {2009-08-21T12:12:59.000+0200},
  Biburl                   = {https://www.bibsonomy.org/bibtex/2d45f56603a7d4c62e50c737732aa2df5/fbw_hannover},
  Interhash                = {2cd22eb68a0aec4a3cd84006e788ff6a},
  Intrahash                = {d45f56603a7d4c62e50c737732aa2df5},
  ISBN                     = {978-0-691-09039-9},
  Keywords                 = {Decision_making Entscheidungstheorie Game_theory Human_behavior Mathematical_models Methoden_und_Techniken_der_Betriebswirtschaft Methoden_und_Techniken_der_Volkswirtschaft Social_interaction Spieltheorie Statistische_Entscheidungstheorie Theorie Verhaltenswissenschaften Verhaltensökonomik},
  Pagetotal                = {XV, 550},
  Ppn_gvk                  = {353560901},
  Subtitle                 = {experiments in strategic interaction},
  Timestamp                = {2009-08-21T12:13:18.000+0200}
}

@Article{Cao2015MixedUAV,
  Title                    = {{Mixed dynamic task allocation for multiple UAV}},
  Author                   = {Cao, Lei and Tan, Heshun and Peng, Hui and Pan, Mingcong},
  Journal                  = {Nanjing Li Gong Daxue Xuebao/Journal of Nanjing University of Science and Technology},
  Year                     = {2015},

  Doi                      = {10.14177/j.cnki.32-1397n.2015.39.02.014},
  ISSN                     = {10059830},
  Keywords                 = {Decentralized auction algorithm, Dynamic task allocation, Particle swarm optimizer-fish swarm algorithm, State information}
}

@Article{Carcassi2018FromMechanics,
  Title                    = {{From physical assumptions to classical and quantum Hamiltonian and Lagrangian particle mechanics}},
  Author                   = {Carcassi, Gabriele and Aidala, Christine and Baker, David John and Bieri, Lydia},
  Journal                  = {Journal of Physics Communications},
  Year                     = {2018},

  Arxivid                  = {1702.07052},
  Doi                      = {10.1088/2399-6528/aaba25},
  ISSN                     = {2399-6528}
}

@Book{CarrerasPerez2004,
  Title                    = {{A Proposal of a behavior-based control architecture with reinforcement learning for an autonomous underwater robot}},
  Author                   = {Carreras Pérez, Marc. and Ridao Rodríguez, Pere. and Universitat de Girona. Departament d'Electrònica, Informàtica i Automàtica.},
  Publisher                = {Universitat de Girona},
  Year                     = {2004},

  ISBN                     = {8468852546}
}

@Misc{Cerarsouza2010,
  Title                    = {{Kernel Functions for Machine Learning Applications – C{\'{e}}sar Souza}},

  Author                   = {{Cerarsouza}},
  Year                     = {2010},

  Url                      = {http://crsouza.com/2010/03/17/kernel-functions-for-machine-learning-applications/}
}

@Article{Chakravarthy2012,
  Title                    = {{Generalization of the collision cone approach for motion safety in 3-D environments}},
  Author                   = {Chakravarthy, Animesh and Ghose, Debasish},
  Journal                  = {Autonomous Robots},
  Year                     = {2012},

  Month                    = {4},
  Number                   = {3},
  Pages                    = {243--266},
  Volume                   = {32},

  Doi                      = {10.1007/s10514-011-9270-z},
  ISSN                     = {09295593},
  Keywords                 = {Collision cone, Dynamic environments, Obstacle avoidance, Path planning, Quadric surfaces}
}

@Article{Chakravarthy1998,
  Title                    = {{Obstacle avoidance in a dynamic environment: A collision cone approach}},
  Author                   = {Chakravarthy, Animesh and Ghose, Debasish},
  Journal                  = {IEEE Transactions on Systems, Man, and Cybernetics Part A:Systems and Humans.},
  Year                     = {1998},
  Number                   = {5},
  Pages                    = {562--574},
  Volume                   = {28},

  Doi                      = {10.1109/3468.709600},
  ISSN                     = {10834427},
  Keywords                 = {Collision cone, Dynamic environments, Obstacle avoidance, Path planning}
}

@TechReport{CheatSheet2019,
  Title                    = {{ML Cheatsheet Documentation Team}},
  Author                   = {{CheatSheet}},
  Year                     = {2019},

  Url                      = {https://buildmedia.readthedocs.org/media/pdf/ml-cheatsheet/latest/ml-cheatsheet.pdf}
}

@Article{Chen2010ACollaboration,
  Title                    = {{A Multi-Robots Task Allocation Algorithm Based on Relevance and Ability With Group Collaboration}},
  Author                   = {Chen, Jian and Yang, Xiangguo and Hu, Yuxi and Han, Yanyan and Li, Deshi and Zhang, Guangmin},
  Journal                  = {Article in International Journal of Intelligent Engineering and Systems},
  Year                     = {2010},

  Doi                      = {10.22266/ijies2010.0630.05},
  Keywords                 = {Group Collaboration, Mobile Agent, Multi-Robots, Task Allocation, ：Mobile Robots Team},
  Url                      = {https://www.researchgate.net/publication/267968475}
}

@InCollection{Cherkassky2002,
  Title                    = {{Selection of Meta-parameters for Support Vector Regression}},
  Author                   = {Cherkassky, Vladimir and Ma, Yunqian},
  Year                     = {2002},
  Pages                    = {687--693},

  Doi                      = {10.1007/3-540-46084-5{\_}112},
  Url                      = {http://link.springer.com/10.1007/3-540-46084-5_112}
}

@Article{Christofides2013,
  Title                    = {{Distributed model predictive control: A tutorial review and future research directions}},
  Author                   = {Christofides, Panagiotis D. and Scattolini, Riccardo and {Mu{\~{n}}oz de la Pe{\~{n}}a}, David and Liu, Jinfeng},
  Journal                  = {Computers and Chemical Engineering},
  Year                     = {2013},

  Month                    = {apr},
  Pages                    = {21--41},
  Volume                   = {51},

  Abstract                 = {In this paper, we provide a tutorial review of recent results in the design of distributed model predictive control systems. Our goal is to not only conceptually review the results in this area but also to provide enough algorithmic details so that the advantages and disadvantages of the various approaches can become quite clear. In this sense, our hope is that this paper would complement a series of recent review papers and catalyze future research in this rapidly evolving area. We conclude discussing our viewpoint on future research directions in this area. {\textcopyright} 2012 Elsevier Ltd.},
  Doi                      = {10.1016/j.compchemeng.2012.05.011},
  File                     = {::},
  ISSN                     = {00981354}
}

@Article{Clerc2005,
  Title                    = {{Library design using genetic algorithms for catalyst discovery and optimization}},
  Author                   = {Clerc, Frederic and Lengliz, Mourad and Farrusseng, David and Mirodatos, Claude and Pereira, Sílvia R. M. and Rakotomalala, Ricco},
  Journal                  = {Review of Scientific Instruments},
  Year                     = {2005},

  Month                    = {6},
  Number                   = {6},
  Pages                    = {062208},
  Volume                   = {76},

  Doi                      = {10.1063/1.1906086},
  ISSN                     = {0034-6748},
  Url                      = {http://aip.scitation.org/doi/10.1063/1.1906086}
}

@TechReport{ConitzerAWESOME:,
  Title                    = {{AWESOME: A General Multiagent Learning Algorithm that Converges in Self-Play and Learns a Best Response Against Stationary Opponents *}},
  Author                   = {Conitzer, Vincent and Sandholm, Tuomas}
}

@PhdThesis{Conte2014,
  Title                    = {{Stability and Computations in Cooperative Distributed Model Predictive Control}},
  Author                   = {Conte, Christian},
  Year                     = {2014},

  Abstract                 = {The main theme of this thesis is the development of cooperative distributed model predictive control (MPC) methods for large-scale networks of constrained dynamic systems. MPC is a modern control methodology, which is particularly suited for constrained systems and has proven successful in practice. For large-scale networks of systems, which are often subject to communication constraints, MPC controllers have to be operated in a distributed way, i.e. each system in the network has to take local control decisions based on local measurements and communication with neighboring systems. Moreover, for networks of systems with a common objective function, it is desirable for the systems to take their control decisions cooperatively, which implies the need for cooperative distributed MPC. Distributed optimization is a well-established methodology which allows the combination of the cooperative and the distributed aspect within the MPC framework. Specifically, one finite-horizon optimal control problem, in the following referred to as MPC problem, can be formulated for the whole network of systems, and it can be solved by a distributed optimization method at each time step. This thesis is concerned with issues arising from the use of distributed optimization in MPC. In the first part of the thesis, distributed optimization based cooperative distributed MPC controllers for networks of linear systems are presented. All controllers guarantee stability and feasibility in closed-loop. The first controller presented is a nominal MPC controller. Closed-loop stability and feasibility are guaranteed by adapting well-established methodologies from the centralized MPC literature. Specifically, the global MPC problem is equipped with a suitably designed terminal cost, which is a Lyapunov function for the unconstrained system, and a terminal set, which is positively invariant (PI). In order to make the MPC problem amenable to distributed optimization algorithms, the terminal cost is designed as a separable function and the terminal set is a Cartesian product of local sets, which are time-varying. Specific synthesis methods for terminal cost and set are presented, where these methods can be executed in a distributed fashion themselves. In the following, two cooperative distributed MPC controller are presented, which extend the nominal one described above. The first is a robust MPC controller for networks of linear systems subject to bounded additive noise, the second is an MPC controller for reference tracking. In both cases, well established methodologies from the centralized MPC literature x Abstract ￼￼are adapted for the use in a cooperative distributed setup, where the MPC problem is solved by distributed optimization. For distributed robust MPC, the main additional ingredients are structured robust positive invariant (RPI) sets, as well as constraint tightening methods, which can be executed in a distributed way. For distributed reference tracking MPC, the main additional ingredient is an invariant set for tracking, again designed as a Cartesian product, and again equipped with a synthesis method that can be carried out in a distributed fashion. In the second part of the thesis, computational aspects of specific distributed optimization methods in MPC are investigated. In particular, the performance of these methods on the MPC problem, i.e. the number of iterations to convergence, is computationally analyzed under various system setups and operational modes. A first study contains computational results for general networks of linear systems, which are controlled by standard nominal cooperative distributed MPC controllers. In the computational scenarios considered, various system properties, such as the strength of the dynamic coupling between the systems or the network topology, are varied. The results show that the performance of distributed optimization is sensitive to changes in these properties. In particular, as a general qualitative observation, the performance decreases in cases where coordination among the systems in the network is crucial, which usually manifests in Lagrange multipliers of large magnitude. These observations could be confirmed in a wind farm application study. In particular, it is shown that the performance of the distributed optimization methods decreases in operational conditions where the power production has to be dynamically reallocated across the wind farm. This is the case for example when there is not enough wind to fulfill the farm-wide power production requirements.},
  Booktitle                = {Thesis},
  Doi                      = {10.3929/ETHZ-A-010194426},
  ISBN                     = {9783906031668},
  Keywords                 = {COMPUTER APPLICATIONS IN AUTOMATIC CONTROL (CONTRO,COMPUTERANWENDUNGEN/AUTOMATISCHE REGELUNG (REGELUN,DYNAMIC PROGRAMMING (OPERATIONS RESEARCH),DYNAMISCHE OPTIMIERUNG (OPERATIONS RESEARCH)},
  Publisher                = {ETH-Z{\"{u}}rich},
  Url                      = {https://control.ee.ethz.ch/index.cgi?page=publications{\&}action=details{\&}id=4809}
}

@InProceedings{Couceiro2015,
  Title                    = {{Towards a predictive model of an evolutionary swarm robotics algorithm}},
  Author                   = {Couceiro, Micael S. and Rocha, R. P. and Martins, Fernando M. L.},
  Booktitle                = {2015 IEEE Congress on Evolutionary Computation (CEC)},
  Year                     = {2015},
  Month                    = {5},
  Pages                    = {2090--2096},
  Publisher                = {IEEE},

  Doi                      = {10.1109/CEC.2015.7257142},
  ISBN                     = {978-1-4799-7492-4},
  Url                      = {http://ieeexplore.ieee.org/document/7257142/}
}

@Misc{Coumans,
  Title                    = {{Bullet Real-Time Physics Simulation | Home of Bullet and PyBullet: physics simulation for games, visual effects, robotics and reinforcement learning.}},

  Author                   = {Coumans, Erwin},

  Url                      = {https://pybullet.org/wordpress/}
}

@Article{Crane2017,
  Title                    = {{The heat method for distance computation}},
  Author                   = {Crane, Keenan and Weischedel, Clarisse and Wardetzky, Max},
  Journal                  = {Communications of the ACM},
  Year                     = {2017},

  Month                    = {10},
  Number                   = {11},
  Pages                    = {90--99},
  Volume                   = {60},

  Doi                      = {10.1145/3131280},
  ISSN                     = {00010782},
  Url                      = {http://dl.acm.org/citation.cfm?doid=3154816.3131280}
}

@Article{Dai2017,
  Title                    = {{Distributed Stochastic MPC of Linear Systems with Additive Uncertainty and Coupled Probabilistic Constraints}},
  Author                   = {Dai, Li and Xia, Yuanqing and Gao, Yulong and Cannon, Mark},
  Journal                  = {IEEE Transactions on Automatic Control},
  Year                     = {2017},
  Number                   = {7},
  Pages                    = {3474--3481},
  Volume                   = {62},

  Abstract                 = {This technical note develops a new form of distributed stochastic model predictive control (DSMPC) algorithm for a group of linear stochastic subsystems subject to additive uncertainty and coupled probabilistic constraints. We provide an appropriate way to design the DSMPC algorithm by extending a centralized SMPC (CSMPC) scheme. To achieve the satisfaction of coupled probabilistic constraints in a distributed manner, only one subsystem is permitted to optimize at each time step. In addition, by making explicit use of the probabilistic distribution of the uncertainties, probabilistic constraints are converted into a set of deterministic constraints for the predictions of nominal models. The distributed controller can achieve recursive feasibility and ensure closed-loop stability for any choice of update sequence. Numerical examples illustrate the efficacy of the algorithm.},
  Doi                      = {10.1109/TAC.2016.2612822},
  File                     = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Xx, Xxxx - 2016 - Distributed Stochastic MPC of Linear Systems with Additive Uncertainty and Coupled Probabilistic Constraints.pdf:pdf},
  ISSN                     = {00189286},
  Keywords                 = {Distributed control,model predictive control (MPC),probabilistic constraints,stochastic systems},
  Url                      = {http://www.ieee.org/publications{\_}standards/publications/rights/index.html}
}

@Misc{Dai2018,
  Title                    = {{Task Allocation Without Communication Based on Incomplete Information Game Theory for Multi-robot Systems}},

  Author                   = {Dai, Wei and Lu, Huimin and Xiao, Junhao and Zheng, Zhiqiang},
  Month                    = {2},
  Year                     = {2018},

  Booktitle                = {Journal of Intelligent and Robotic Systems: Theory and Applications},
  Doi                      = {10.1007/s10846-018-0783-y},
  ISSN                     = {15730409},
  Keywords                 = {Incomplete information game, Soccer robots, Task allocation, Without communication},
  Pages                    = {1--16},
  Publisher                = {Springer Netherlands}
}

@Misc{DeepTut,
  Title                    = {{Unsupervised Feature Learning and Deep Learning Tutorial}},

  Author                   = {{DeepTut}},

  Url                      = {http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/}
}

@Article{DeSimone2015,
  Title                    = {{Influence of Aerodynamics on Quadrotor Dynamics}},
  Author                   = {DeSimone, Marco C. and Serena, Russo and Alessandro, Ruggiero},
  Journal                  = {Recent Researches in Mechanical and Transportation Systems Influence},
  Year                     = {2015},
  Pages                    = {111--118},

  Doi                      = {10.13140/RG.2.1.5099.3128},
  ISBN                     = {9781618043160},
  Keywords                 = {Key-Words: UAV, PID Control, Quadcopter, Under-Actuated System},
  Url                      = {http://www.wseas.us/e-library/conferences/2015/Salerno/ICTA/ICTA-16.pdf}
}

@Article{Diaconis1993ComparisonChains,
  Title                    = {{Comparison Theorems for Reversible Markov Chains}},
  Author                   = {Diaconis, Persi and Saloff-Coste, Laurent},
  Journal                  = {The Annals of Applied Probability},
  Year                     = {1993},
  Number                   = {3},
  Pages                    = {696--730},
  Volume                   = {3},

  Doi                      = {10.1214/aoap/1177005359},
  ISSN                     = {1050-5164},
  Url                      = {https://doi.org/10.1007/978-3-642-24106-2_23}
}

@Article{Dias2000ASystem,
  Title                    = {{A Free Market Architecture for Distributed Control of a Multirobot System}},
  Author                   = {Dias, M. Bernardine and Stentz, Anthony},
  Year                     = {2000},

  Month                    = {1},

  Doi                      = {10.1184/R1/6550274.V1},
  Keywords                 = {Robotics},
  Publisher                = {Carnegie Mellon University}
}

@InProceedings{Dibangoye2015ExploitingMDPs,
  Title                    = {{Exploiting separability in multiagent planning with continuous-state MDPs}},
  Author                   = {Dibangoye, Jilles S. and Amato, Christopher and Buffet, Olivier and Charpillet, François},
  Booktitle                = {IJCAI International Joint Conference on Artificial Intelligence},
  Year                     = {2015},
  Pages                    = {4254--4260},
  Publisher                = {International Joint Conferences on Artificial Intelligence},
  Volume                   = {2015-Janua},

  ISBN                     = {9781577357384},
  ISSN                     = {10450823}
}

@Article{Dibangoye2014OptimallyAlgorithms,
  Title                    = {{Optimally solving Dec-POMDPs as continuous-state MDPs: Theory and algorithms}},
  Author                   = {Dibangoye, Jilles Steeve and Amato, Christopher and Buffet, Olivier and Charpillet, François},
  Journal                  = {Journal of Artificial Intelligence Research},
  Year                     = {2014},
  Pages                    = {443--497},
  Volume                   = {55},

  ISBN                     = {9781577356332},
  ISSN                     = {0249-6399},
  Keywords                 = {concurrent, dec-pomdp, decentralized, enhancement, lim-com, nondet-outcomes, partial-obs}
}

@TechReport{DickensTheLearning,
  Title                    = {{The Dynamics of Multi-Agent Reinforcement Learning}},
  Author                   = {Dickens, Luke and Broda, Krysia and Russo, Alessandra}
}

@TechReport{Djugash,
  Title                    = {{Neural Networks for Obstacle Avoidance}},
  Author                   = {Djugash, Joseph and Hamner, Bradley}
}

@InProceedings{Doerr2019,
  Title                    = {{Random finite set theory and optimal control of large spacecraft swarms}},
  Author                   = {Doerr, Bryce and Linares, Richard and Zhu, Pingping and Ferrari, Silvia},
  Booktitle                = {Advances in the Astronautical Sciences},
  Year                     = {2019},
  Pages                    = {3729--3748},
  Volume                   = {168},

  Abstract                 = {Controlling large swarms of robotic agents has many challenges including, but not limited to, computational complexity due to the number of agents, uncertainty in the functionality of each agent in the swarm, and uncertainty in the swarm's configuration. This work generalizes the swarm state using Random Finite Set (RFS) theory and solves the control problem using Model Predictive Control (MPC) to overcome the aforementioned challenges. Computationally efficient solutions are obtained via the Iterative Linear Quadratic Regulator (ILQR). Information divergence is used to define the distance between the swarm RFS and the desired swarm configuration. Then, a stochastic optimal control problem is formulated using a modified L22 distance. Simulation results using MPC and ILQR show that swarm intensities converge to a target destination, and the RFS control formulation can vary in the number of target destinations. ILQR also provides a more computationally efficient solution to the RFS swarm problem when compared to the MPC solution. Lastly, the RFS control solution is applied to a spacecraft relative motion problem showing the viability for this real-world scenario.},
  File                     = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Linares - 2019 - Optimal Estimation and Control of Large Collaborative Swarms using Random Finite Set Theory.pdf:pdf},
  ISBN                     = {9780877036593},
  ISSN                     = {00653438},
  Keywords                 = {Multi,Optimal Control,Random Finite Sets,Target State Estimation,agent systems,centralized control,decentralized control,multi},
  Mendeley-groups          = {STAI/Literature Review},
  Url                      = {http://conservancy.umn.edu/handle/11299/209054}
}

@Article{Dong2008QuantumLearning,
  Title                    = {{Quantum reinforcement learning}},
  Author                   = {Dong, Daoyi and Chen, Chunlin and Li, Hanxiong and Tarn, Txyh Jong},
  Journal                  = {IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics},
  Year                     = {2008},
  Number                   = {5},
  Pages                    = {1207--1220},
  Volume                   = {38},

  Arxivid                  = {0810.3828},
  Doi                      = {10.1109/TSMCB.2008.925743},
  ISSN                     = {10834419},
  Keywords                 = {Collapse, Grover iteration, Probability amplitude, Quantum reinforcement learning (QRL), State superposition}
}

@Article{Dorigo2008SwarmExperiment,
  Title                    = {{Swarm intelligence and swarm robotics. The swarm-bot experiment}},
  Author                   = {Dorigo, M},
  Journal                  = {ICINCO 2008 Proceedings of the Fifth International Conference on Informatics in Control Automation and Robotics},
  Year                     = {2008}
}

@InProceedings{Dosilovic2018ExplainableSurvey,
  Title                    = {{Explainable artificial intelligence: A survey}},
  Author                   = {Dosilovic, Filip Karlo and Brcic, Mario and Hlupic, Nikica},
  Booktitle                = {2018 41st International Convention on Information and Communication Technology, Electronics and Microelectronics, MIPRO 2018 - Proceedings},
  Year                     = {2018},
  Month                    = {6},
  Pages                    = {210--215},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.},

  Doi                      = {10.23919/MIPRO.2018.8400040},
  ISBN                     = {9789532330977},
  Keywords                 = {comprehensibility, explainability, explainable artificial intelligence, interpretability}
}

@InCollection{Du2014,
  Title                    = {{Recurrent Neural Networks}},
  Author                   = {Du, Ke-Lin and Swamy, M. N. S.},
  Booktitle                = {Neural Networks and Statistical Learning},
  Publisher                = {Springer London},
  Year                     = {2014},

  Address                  = {London},
  Pages                    = {337--353},

  Doi                      = {10.1007/978-1-4471-5571-3{\_}11},
  Url                      = {http://link.springer.com/10.1007/978-1-4471-5571-3_11}
}

@TechReport{DucatelleSelf-organizedSwarms,
  Title                    = {{Self-organized Cooperation between Robotic Swarms}},
  Author                   = {Ducatelle, Frederick and Caro, Gianni A Di and Pinciroli, Carlo and Gambardella, uca},

  Keywords                 = {Swarm robotics, ant foraging, heterogeneous robot swarms, multi-robot systems, robot navigation, self-organization, stigmergy, swarm intelligence},
  Url                      = {http://www.swarmanoid.org}
}

@Article{Egerstedt2016SwarmingRobots,
  Title                    = {{Swarming robots}},
  Author                   = {Egerstedt, Magnus},
  Journal                  = {Snapshot of Modern Mathematics},
  Year                     = {2016},
  Number                   = {1},
  Pages                    = {1--9},
  Volume                   = {1}
}

@book{Mezard1986,
  added-at = {2015-04-16T09:05:10.000+0200},
  address = {Teaneck, NJ},
  author = {Mezard, N.},
  biburl = {https://www.bibsonomy.org/bibtex/28e91430a8d1c714fc8c5d03078c719dc/ytyoun},
  interhash = {3a8af67679aac87ce7d94a45b18e6464},
  intrahash = {8e91430a8d1c714fc8c5d03078c719dc},
  isbn = {9971501155 9789971501150 9971501163 9789971501167},
  keywords = {no.pdf physics spin.glass textbook},
  publisher = {World Scientific},
  refid = {14929802},
  timestamp = {2015-12-13T12:55:23.000+0100},
  title = {Spin Glass Theory and Beyond},
  year = 1987
}


@InProceedings{Eker2011,
  Title                    = {{A finite horizon DEC-POMDP approach to multi-robot task learning}},
  Author                   = {Eker, Baris and Ozkucur, Ergin and Mericli, Cetin and Mericli, Tekin and Akin, H. Levent},
  Booktitle                = {2011 5th International Conference on Application of Information and Communication Technologies (AICT)},
  Year                     = {2011},
  Month                    = {10},
  Pages                    = {1--5},
  Publisher                = {IEEE},

  Doi                      = {10.1109/ICAICT.2011.6111001},
  ISBN                     = {978-1-61284-832-7},
  Url                      = {http://ieeexplore.ieee.org/document/6111001/}
}

@Article{Elamvazhuthi2019b,
  Title                    = {{Mean-field models in swarm robotics: a survey}},
  Author                   = {Elamvazhuthi, Karthik and Berman, Spring},
  Journal                  = {Bioinspiration {\&} biomimetics},
  Year                     = {2019},

  Month                    = {nov},
  Number                   = {1},
  Pages                    = {015001},
  Volume                   = {15},

  Abstract                 = {We present a survey on the application of fluid approximations, in the form of mean-field models, to the design of control strategies in swarm robotics. Mean-field models that consist of ordinary differential equations, partial differential equations, and difference equations have been used in the swarm robotics literature, depending on whether the state of each agent and the time variable take values from a discrete or continuous set. These macroscopic models are independent of the number of agents in the swarm, and hence can be used to synthesize robot control strategies in a scalable manner, in contrast to individual-based microscopic models of swarms that represent finite numbers of discrete agents. Moreover, mean-field models are amenable to rigorous investigation using tools from dynamical systems theory, control theory, stochastic processes, and analysis of partial differential equations, enabling new insights and provable guarantees on the dynamics of collective behaviors. In this paper, we survey the applications of these models to problems in swarm robotics that include coverage, task allocation, self-assembly, consensus, and environmental mapping.},
  Doi                      = {10.1088/1748-3190/ab49a4},
  ISSN                     = {17483190},
  Publisher                = {NLM (Medline)}
}

@PhdThesis{Elamvazhuthi2019,
  Title                    = {{Controllability and Stabilization of Kolmogorov Forward Equations for Robotic Swarms}},
  Author                   = {Elamvazhuthi, Karthik and Berman, Spring and Kawski, Matthias and Kuiper, Hendrik and Mignolet, Marc and Peet, Matthew},
  Year                     = {2019},

  File                     = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Elamvazhuthi et al. - 2019 - Controllability and Stabilization of Kolmogorov Forward Equations for Robotic Swarms.pdf:pdf}
}

@TechReport{Emery-Montemerlo,
  Title                    = {{Approximate Solutions For Partially Observable Stochastic Games with Common Payoffs}},
  Author                   = {Emery-Montemerlo, Rosemary and Gordon, Geoff and Schneider, Jeff and Thrun, Sebastian}
}

@Article{Env2018,
  Title                    = {{A Survey on Obstacles Avoidance Mobile Robot in Static Unknown Environment}},
  Author                   = {{Env}},
  Journal                  = {International Journal of Computer (IJC)},
  Year                     = {2018},
  Number                   = {1},
  Pages                    = {160--173},
  Volume                   = {28},

  ISSN                     = {2307-4523},
  Keywords                 = {Autonomous navigation., Mobile robot, Obstacle avoidance, Static environment}
}

@InProceedings{Eraqi2016,
  Title                    = {{Reactive collision avoidance using evolutionary neural networks}},
  Author                   = {Eraqi, Hesham M. and Eldin, Youssef Emad and Moustafa, Mohamed N.},
  Booktitle                = {IJCCI 2016 - Proceedings of the 8th International Joint Conference on Computational Intelligence},
  Year                     = {2016},
  Pages                    = {251--257},
  Publisher                = {SciTePress},
  Volume                   = {1},

  ISBN                     = {9789897582011},
  Keywords                 = {Collision avoidance, Evolutionary neural networks, Genetic algorithm, Lane keeping}
}

@Article{Faisal2013,
  Title                    = {{Fuzzy logic navigation and obstacle avoidance by a mobile robot in an unknown dynamic environment}},
  Author                   = {Faisal, Mohammed and Hedjar, Ramdane and Al Sulaiman, Mansour and Al-Mutib, Khalid},
  Journal                  = {International Journal of Advanced Robotic Systems},
  Year                     = {2013},

  Month                    = {1},
  Volume                   = {10},

  Doi                      = {10.5772/54427},
  ISSN                     = {17298806},
  Keywords                 = {Fuzzy logic control, Navigation and obstacles, Wheeled mobile robot, Wireless communication}
}

@TechReport{FaulknerActiveLearning,
  Title                    = {{Active Attention-Modified Policy Shaping Socially Interactive Agents Track Human-robot interaction; reinforcement learning; active learning}},
  Author                   = {Faulkner, Taylor Kessler and Gutierrez, Reymundo A and Short, Elaine Schaertl and Hoffman, Guy and Thomaz, Andrea L},

  Keywords                 = {Human-robot interaction, active learning, reinforcement learning},
  Url                      = {www.ifaamas.org}
}

@TechReport{Fiorini,
  Title                    = {{Motion Planning in Dynamic Environments using Velocity Obstacles}},
  Author                   = {Fiorini, Paolo and Shiller, Zvi}
}

@Article{Fleig,
  Title                    = {{Optimal Control of the Fokker–Planck Equation with Space-Dependent Controls}},
  Author                   = {Fleig, Arthur and Guglielmi, Roberto},

  File                     = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - Optimal Control of the Fokker–Planck Equation with Space-Dependent Controls.pdf:pdf},
  Mendeley-groups          = {STAI/Literature Review/Swarm Control}
}

@TechReport{Fletcher2008,
  Title                    = {{Support Vector Machines Explained}},
  Author                   = {Fletcher, Tristan},
  Year                     = {2008},

  Url                      = {www.cs.ucl.ac.uk/staff/T.Fletcher/}
}

@TechReport{Foerster2018LearningAwareness,
  Title                    = {{Learning with Opponent-Learning Awareness}},
  Author                   = {Foerster, Jakob and Chen, Richard Y and Maruan Al-Shedivat, OpenAI and Whiteson, Shimon and Abbeel, Pieter and Mordatch OpenAI, Igor and Al-Shedivat, Maruan},
  Year                     = {2018},

  Keywords                 = {deep reinforcement learning, game theory, multi-agent learning},
  Url                      = {www.ifaamas.org}
}

@TechReport{Foerster2018LearningAwarenessb,
  Title                    = {{Learning with Opponent-Learning Awareness}},
  Author                   = {Foerster, Jakob and Chen, Richard Y and Maruan Al-Shedivat, OpenAI and Whiteson, Shimon and Abbeel, Pieter and Mordatch OpenAI, Igor and Al-Shedivat, Maruan},
  Year                     = {2018},

  Keywords                 = {deep reinforcement learning, game theory, multi-agent learning},
  Url                      = {www.ifaamas.org}
}

@article{Opper1992,
abstract = {We study a population of interacting species, described by the replicator model well established in theoretical biology. Using methods of statistical physics we present an exact steady-state solution to the model as a function of the populations cooperation pressure u when the number of species is large and the interactions are taken as random. When u is lowered to a critical value uc, the solution becomes unstable. This phase transition manifests itself by a 1/f behavior in the power spectrum of the systems response against weak external noise. {\textcopyright} 1992 The American Physical Society.},
author = {Opper, Manfred and Diederich, Sigurd},
doi = {10.1103/PhysRevLett.69.1616},
file = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Opper, Diederich - Unknown - Phase Transition and 1f Noise in a Game Dynamical Model.pdf:pdf},
issn = {00319007},
journal = {Physical Review Letters},
mendeley-groups = {STAI/Literature Review},
number = {10},
pages = {1616--1619},
title = {{Phase transition and 1/f noise in a game dynamical model}},
volume = {69},
year = {1992}
}


@TechReport{Foerster2018DeepLearning,
  Title                    = {{Deep Multi-Agent Reinforcement Learning}},
  Author                   = {Foerster, Jakob N},
  Year                     = {2018}
}

@Article{Foerster,
  Title                    = {{Bayesian Action Decoder for Deep Multi-Agent Reinforcement Learning}},
  Author                   = {Foerster, Jakob N and Song, Francis and Hughes, Edward and Burch, Neil and Dunning, Iain and Whiteson, Shimon and Botvinick, Matthew and Bowling, Michael},
  Year                     = {2018},

  Abstract                 = {When observing the actions of others, humans make inferences about why they acted as they did, and what this implies about the world; humans also use the fact that their actions will be interpreted in this manner, allowing them to act informatively and thereby communicate efficiently with others. Although learning algorithms have recently achieved superhuman performance in a number of two-player, zero-sum games, scalable multi-agent reinforcement learning algorithms that can discover effective strategies and conventions in complex, partially observable settings have proven elusive. We present the Bayesian action decoder (BAD), a new multi-agent learning method that uses an approximate Bayesian update to obtain a public belief that conditions on the actions taken by all agents in the environment. BAD introduces a new Markov decision process, the public belief MDP, in which the action space consists of all deterministic partial policies, and exploits the fact that an agent acting only on this public belief state can still learn to use its private information if the action space is augmented to be over all partial policies mapping private information into environment actions. The Bayesian update is closely related to the theory of mind reasoning that humans carry out when observing others' actions. We first validate BAD on a proof-of-principle two-step matrix game, where it outperforms policy gradient methods; we then evaluate BAD on the challenging, cooperative partial-information card game Hanabi, where, in the two-player setting, it surpasses all previously published learning and hand-coded approaches, establishing a new state of the art.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1811.01458},
  Eprint                   = {1811.01458},
  File                     = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Foerster et al. - Unknown - Bayesian Action Decoder for Deep Multi-Agent Reinforcement Learning.pdf:pdf},
  Url                      = {http://arxiv.org/abs/1811.01458}
}

@Article{Foster2001,
  Title                    = {{On the impossibility of predicting the behavior of rational agents}},
  Author                   = {Foster, Dean P. and {Peyton Young}, H.},
  Journal                  = {Proceedings of the National Academy of Sciences of the United States of America},
  Year                     = {2001},

  Month                    = {oct},
  Number                   = {22},
  Pages                    = {12848--12853},
  Volume                   = {98},

  Abstract                 = {A foundational assumption in economics is that people are rational: they choose optimal plans of action given their predictions about future states of the world. In games of strategy this means that each player's strategy should be optimal given his or her prediction of the opponents' strategies. We demonstrate that there is an inherent tension between rationality and prediction when players are uncertain about their opponents' payoff functions. Specifically, there are games in which it is impossible for perfectly rational players to learn to predict the future behavior of their opponents (even approximately) no matter what learning rule they use. The reason is that in trying to predict the next-period behavior of an opponent, a rational player must take an action this period that the opponent can observe. This observation may cause the opponent to alter his next-period behavior, thus invalidating the first player's prediction. The resulting feedback loop has the property that, a positive fraction of the time, the predicted probability of some action next period differs substantially from the actual probability with which the action is going to occur. We conclude that there are strategic situations in which it is impossible in principle for perfectly rational agents to learn to predict the future behavior of other perfectly rational agents based solely on their observed actions.},
  Doi                      = {10.1073/pnas.211534898},
  File                     = {:home/aamalh/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Foster, Peyton Young - 2001 - On the impossibility of predicting the behavior of rational agents.pdf:pdf},
  ISSN                     = {00278424},
  Mendeley-groups          = {STAI/Literature Review/MARL},
  Pmid                     = {11675512}
}

@Book{Fradkov2009,
  Title                    = {{Cybernetical Physics: From Control of Chaos to Quantum Control}},
  Author                   = {Fradkov, A. L.},
  Publisher                = {Springer},
  Year                     = {2007},

  Added-at                 = {2009-03-03T17:19:04.000+0100},
  Biburl                   = {https://www.bibsonomy.org/bibtex/2c5e97ca1bc08b7cb8afba63f1f946298/bronckobuster},
  Interhash                = {c424459fae514254e519b3ae66998c29},
  Intrahash                = {c5e97ca1bc08b7cb8afba63f1f946298},
  Keywords                 = {imported},
  Timestamp                = {2009-03-03T17:19:57.000+0100}
}

@Misc{Fridman2019,
  Title                    = {{Intro to Deep Reinforcement Learning}},

  Author                   = {Fridman, L},
  Year                     = {2019},

  Publisher                = {MIT Press}
}

@Article{Frison2010Self-organizedPartitioning,
  Title                    = {{Self-organized Task Partitioning}},
  Author                   = {Frison, Marco and Tran, Nam-luc and Baiboun, Nadir and Brutschy, Arne and Pini, Giovanni and Roli, Andrea and Dorigo, Marco and Birattari, Mauro},
  Journal                  = {Lecture Notes in Computer Science},
  Year                     = {2010},

  Doi                      = {10.1007/978-3-642-15461-4{\_}25}
}

@TechReport{Fung,
  Title                    = {{A Feature Selection Newton Method for Support Vector Machine Classification}},
  Author                   = {Fung, Glenn and Mangasarian, O L},

  Keywords                 = {Newton, classification, feature selection, lin-ear programming},
  Url                      = {https://pdfs.semanticscholar.org/6687/4b845c72834a11c63cfa62714bf2d0b4c663.pdf?fbclid=IwAR3yNRMBSDjyMp9qfrJDhtw659th4qKDfBqE1ir2Z9kcqCb4s2XzOoD4ydE}
}

@Article{Gabbard2019ARResearch,
  Title                    = {{AR DriveSim: An Immersive Driving Simulator for Augmented Reality Head-Up Display Research}},
  Author                   = {Gabbard, Joseph L. and Smith, Missie and Tanous, Kyle and Kim, Hyungil and Jonas, Bryan},
  Journal                  = {Frontiers in Robotics and AI},
  Year                     = {2019},

  Month                    = {10},
  Volume                   = {6},

  Doi                      = {10.3389/frobt.2019.00098},
  ISSN                     = {2296-9144},
  Url                      = {https://www.frontiersin.org/article/10.3389/frobt.2019.00098/full}
}

@Article{Galla2011,
  Title                    = {{Cycles of cooperation and defection in imperfect learning}},
  Author                   = {Galla, Tobias},
  Journal                  = {Journal of Statistical Mechanics: Theory and Experiment},
  Year                     = {2011},

  Month                    = {aug},
  Number                   = {8},
  Volume                   = {2011},

  Abstract                 = {We investigate a model of learning the iterated prisoner's dilemma game. Players have the choice between three strategies: always defect (ALLD), always cooperate (ALLC) and tit-for-tat (TFT). The only strict Nash equilibrium in this situation is ALLD. When players learn to play this game convergence to the equilibrium is not guaranteed, for example we find cooperative behaviour if players discount observations in the distant past. When agents use small samples of observed moves to estimate their opponent's strategy the learning process is stochastic, and sustained oscillations between cooperation and defection can emerge. These cycles are similar to those found in stochastic evolutionary processes, but the origin of the noise sustaining the oscillations is different and lies in the imperfect sampling of the opponent's strategy. Based on a systematic expansion technique, we are able to predict the properties of these learning cycles, providing an analytical tool with which the outcome of more general stochastic adaptation processes can be characterised. {\textcopyright} 2011 IOP Publishing Ltd and SISSA.},
  Doi                      = {10.1088/1742-5468/2011/08/P08007},
  File                     = {:home/aamalh/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Galla - 2011 - Cycles of cooperation and defection in imperfect learning.pdf:pdf},
  ISSN                     = {17425468},
  Keywords                 = {applications to game theory and mathematical econo,game-theory (theory),stochastic processes},
  Mendeley-groups          = {STAI/Literature Review/MARL}
}

@Article{Galstyan2013,
  Title                    = {{Continuous strategy replicator dynamics for multi-agent Q-learning}},
  Author                   = {Galstyan, Aram},
  Journal                  = {Autonomous Agents and Multi-Agent Systems},
  Year                     = {2013},
  Number                   = {1},
  Pages                    = {37--53},
  Volume                   = {26},

  Abstract                 = {The problem of multi-agent learning and adaptation has attracted a great deal of attention in recent years. It has been suggested that the dynamics of multi agent learning can be studied using replicator equations from population biology. Most existing studies so far have been limited to discrete strategy spaces with a small number of available actions. In many cases, however, the choices available to agents are better characterized by continuous spectra. This paper suggests a generalization of the replicator framework that allows to study the adaptive dynamics of Q-learning agents with continuous strategy spaces. Instead of probability vectors, agents' strategies are now characterized by probability measures over continuous variables. As a result, the ordinary differential equations for the discrete case are replaced by a system of coupled integral-differential replicator equations that describe the mutual evolution of individual agent strategies. We derive a set of functional equations describing the steady state of the replicator dynamics, examine their solutions for several two-player games, and confirm our analytical results using simulations. {\textcopyright} 2011 The Author(s).},
  Archiveprefix            = {arXiv},
  Arxivid                  = {0904.4717},
  Doi                      = {10.1007/s10458-011-9181-6},
  Eprint                   = {0904.4717},
  File                     = {:Users/aamalh/Downloads/0904.4717.pdf:pdf},
  ISSN                     = {13872532},
  Keywords                 = {Continuous strategies,Multi-agent reinforcement learning,Replicator dynamics},
  Mendeley-groups          = {STAI/Literature Review,STAI/Literature Review/MARL}
}

@InProceedings{Gao2018,
  Title                    = {{An improved hybrid group intelligent algorithm based on artificial bee colony and particle swarm optimization}},
  Author                   = {Gao, Yuxi},
  Booktitle                = {Proceedings - 2018 International Conference on Virtual Reality and Intelligent Systems, ICVRIS 2018},
  Year                     = {2018},
  Month                    = {11},
  Pages                    = {160--163},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.},

  Doi                      = {10.1109/ICVRIS.2018.00046},
  ISBN                     = {9781538680315},
  Keywords                 = {Artificial Bee Colony, Hybrid algorithm, Particle Swarm Optimization, Swarm Intelligence}
}

@InCollection{Garapati2018AMissions,
  Title                    = {{A game of drones: Game theoretic approaches for multi-robot task allocation in security missions}},
  Author                   = {Garapati, Kala and Rold{\'{a}}n, Juan Jesús and Garz{\'{o}}n, Mario and del Cerro, Jaime and Barrientos, Antonio},
  Booktitle                = {Advances in Intelligent Systems and Computing},
  Publisher                = {Springer Verlag},
  Year                     = {2018},
  Pages                    = {855--866},
  Volume                   = {693},

  Doi                      = {10.1007/978-3-319-70833-1{\_}69},
  ISSN                     = {21945357},
  Keywords                 = {Game theory, Multi-robot mission, Security, Swarm, Task allocation}
}

@Misc{GAVIN,
  Title                    = {{LIDAR-Lite 3 Laser Rangefinder - RobotShop}},

  Author                   = {{GAVIN}},

  Url                      = {https://www.robotshop.com/uk/lidar-lite-3-laser-rangefinder.html}
}

@InProceedings{Gavran2017Antlab:Server,
  Title                    = {{Antlab: A multi-robot task server}},
  Author                   = {Gavran, Ivan and Majumdar, Rupak and Saha, Indranil},
  Booktitle                = {ACM Transactions on Embedded Computing Systems},
  Year                     = {2017},

  Doi                      = {10.1145/3126513},
  ISSN                     = {15583465},
  Keywords                 = {Cyber-physical systems, Multi-robot systems, Planning, Programming abstractions for robotics}
}

@Article{Gerkey2002Sold:Coordination,
  Title                    = {{Sold!: Auction methods for multirobot coordination}},
  Author                   = {Gerkey, Brian P. and Matari{\'{c}}, Maja J.},
  Journal                  = {IEEE Transactions on Robotics and Automation},
  Year                     = {2002},

  Month                    = {10},
  Number                   = {5},
  Pages                    = {758--768},
  Volume                   = {18},

  Doi                      = {10.1109/TRA.2002.803462},
  ISSN                     = {1042296X},
  Keywords                 = {Auctions, Contract nets, Coordination, Multirobot systems, Task allocation}
}

@TechReport{Gibiansky,
  Title                    = {{Quadcopter Dynamics, Simulation, and Control}},
  Author                   = {Gibiansky, Andrew}
}

@TechReport{Gilonis2014,
  Title                    = {{Aeronautics {\&} Astronautics Third Year Individual Project IP Number: 960 IP Title: Low-complexity controller design for an unmanned helicopter}},
  Author                   = {Gilonis, Samuel and Shu, Zhan},
  Year                     = {2014}
}

@Article{Giulioni2015,
  Title                    = {{Stochastic Model Predictive Control with Application to Distributed Control Systems}},
  Author                   = {Giulioni, Luca},
  Year                     = {2015},
  Pages                    = {1--208},

  File                     = {:Users/aamalh/Downloads/thesis (1).pdf:pdf}
}

@InProceedings{Guha2018Multi-playerGames,
  Title                    = {{Multi-player flow games}},
  Author                   = {Guha, Shibashis and Kupferman, Orna and Vardi, Gal},
  Booktitle                = {Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS},
  Year                     = {2018},
  Pages                    = {104--112},
  Volume                   = {1},

  Doi                      = {10.1007/s10458-019-09420-2},
  ISBN                     = {9781510868083},
  ISSN                     = {15582914},
  Keywords                 = {Game Theory for practical applications, Methodologies for agent-based systems, Noncoopera tive games: Theory {\&} analysis, Noncooperative games computation},
  Url                      = {www.ifaamas.org}
}

@InProceedings{Gunn2013,
  Title                    = {{Effective task allocation for evolving multi-robot teams in dangerous environments}},
  Author                   = {Gunn, Tyler and Anderson, John},
  Booktitle                = {Proceedings - 2013 IEEE/WIC/ACM International Conference on Intelligent Agent Technology, IAT 2013},
  Year                     = {2013},
  Pages                    = {231--238},
  Publisher                = {IEEE Computer Society},
  Volume                   = {2},

  Doi                      = {10.1109/WI-IAT.2013.114},
  ISBN                     = {9781479929023},
  Keywords                 = {Heterogeneity, Multi-robot systems, Roles, Task allocation, Team management, USAR}
}

@Misc{Gym,
  Title                    = {{OpenAI Gym}},

  Author                   = {{Gym}},

  Url                      = {https://gym.openai.com/envs/CartPole-v0/}
}

@Article{H.Sawalmeh2018,
  Title                    = {{An Overview of Collision Avoidance Approaches and Network Architecture of Unmanned Aerial Vehicles (UAVs)}},
  Author                   = {H. Sawalmeh, Ahmad and Shamsiah Othman, Noor},
  Journal                  = {International Journal of Engineering {\&} Technology},
  Year                     = {2018},

  Month                    = {11},
  Number                   = {4.35},
  Pages                    = {924},
  Volume                   = {7},

  Doi                      = {10.14419/ijet.v7i4.35.27395},
  Publisher                = {Science Publishing Corporation}
}

@InProceedings{Honig2018ScalableEnvironments,
  Title                    = {{Scalable task and motion planning for multi-robot systems in obstacle-rich environments}},
  Author                   = {H{\"{o}}nig, Wolfgang},
  Booktitle                = {Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS},
  Year                     = {2018},
  Pages                    = {1746--1748},
  Volume                   = {3},

  ISBN                     = {9781510868083},
  ISSN                     = {15582914},
  Url                      = {www.ifaamas.org}
}

@Book{Hamalainen1991DifferentialFinland,
  Title                    = {{Differential games : developments in modelling and computation : proceedings of the Fourth International Symposium on Differential Games and Applications, August 9-10, 1990, Helsinki University of Technology, Finland}},
  Author                   = {Hamalainen, Raimo P. and Ehtamo, H. K. (Harri Kalevi)},
  Publisher                = {Springer-Verlag},
  Year                     = {1991},

  ISBN                     = {3540537872},
  Pages                    = {292}
}

@InCollection{Hamann2018,
  Title                    = {{Introduction to Swarm Robotics}},
  Author                   = {Hamann, Heiko},
  Booktitle                = {Swarm Robotics: A Formal Approach},
  Publisher                = {Springer International Publishing},
  Year                     = {2018},
  Pages                    = {1--32},

  Abstract                 = {We introduce fundamental concepts of swarm robotics and get a little overview.Swarm robotics is a complex approach that requires an understanding of how to define swarm behavior, whether there is a minimum size of swarms, what are the requirements and properties of swarm systems. We define self-organization and develop an understanding of feedback systems. Swarms do not necessarily need to be homogeneous but can consist of different types of robots making them heterogeneous. We also discus the interaction of robot swarms with human beings as a factor.},
  Doi                      = {10.1007/978-3-319-74528-2_1},
  Mendeley-groups          = {STAI/Literature Review}
}

@PhdThesis{Hamann2008,
  Title                    = {{Space-Time Continuous Models of Swarm Robotics Systems: Supporting Global-to-Local Programming}},
  Author                   = {Hamann, Heiko},
  Year                     = {2008},

  Abstract                 = {In this book, a genericmodel in as far as possiblemathematical closed-formis developed that predicts the behavior of large self-organizing robot groups (robot swarms) based on their control algorithm. In addition, an extensive subsumption of the relatively young and distinctive interdisciplinary research field of swarm robotics is emphasized. The connection to many related fields is highlighted and the concepts and methods borrowed from these fields are described shortly.},
  File                     = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Hamann - 2008 - Space-Time Continuous Models of Swarm Robotic Systems Supporting Global-to-Local Programming.pdf:pdf},
  Url                      = {http://heikohamann.de/pub/hamannPhDThesis.pdf}
}

@InProceedings{Harutyunyan2018LearningOff-policy,
  Title                    = {{Learning with options that terminate off-policy}},
  Author                   = {Harutyunyan, Anna and Vrancx, Peter and Bacon, Pierre Luc and Precup, Doina and Now{\'{e}}, Ann},
  Booktitle                = {32nd AAAI Conference on Artificial Intelligence, AAAI 2018},
  Year                     = {2018},
  Pages                    = {3173--3182},

  Arxivid                  = {1711.03817},
  ISBN                     = {9781577358008},
  Keywords                 = {Hierarchical Reinforcement Learning, Multi-agent Learning},
  Url                      = {www.ifaamas.org}
}

@InProceedings{He2008,
  Title                    = {{A fuzzy neural network based on T-S model for mobile robots to avoid obstacles}},
  Author                   = {He, Kunpeng and Gao, Yanbin and Sun, Hua},
  Booktitle                = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2008},
  Number                   = {PART 1},
  Pages                    = {1127--1134},
  Volume                   = {5314 LNAI},

  Doi                      = {10.1007/978-3-540-88513-9-120},
  ISBN                     = {3540885129},
  ISSN                     = {03029743},
  Keywords                 = {Avoiding obstacles, Fuzzy neural network, Mobile robot, Multi-sensor}
}

@Article{Heirung2019,
  Title                    = {{Model predictive control with active learning for stochastic systems with structural model uncertainty: Online model discrimination}},
  Author                   = {Heirung, Tor Aksel N. and Santos, Tito L.M. and Mesbah, Ali},
  Journal                  = {Computers and Chemical Engineering},
  Year                     = {2019},

  Month                    = {sep},
  Pages                    = {128--140},
  Volume                   = {128},

  Abstract                 = {Structural model uncertainty is prevalent in control design and arises from incomplete knowledge of the system or the existence of different modes of dynamic behavior, such as those arising from system faults and malfunctions. This paper addresses control of stochastic nonlinear systems using model predictive control, or MPC, under structural model uncertainty. Inspired by dual control, the MPC strategy with active learning presented here can probe the uncertain system to select, among a set of candidates, the model that best describes the observed closed-loop system data. The proposed controller involves online model selection based on estimation of the model-hypothesis probabilities and minimization of a computationally tractable measure of the predicted Bayes risk of selection error. The performance of the proposed approach is compared to that of nominal MPC with no learning, MPC with passive learning, and a robust MPC approach that systematically accounts for structural model uncertainty but has no learning mechanism. Simulation results on a nonlinear bioreactor demonstrate that active learning can have significant advantages in maintaining adequate control performance in the presence of structural uncertainty. Active learning can be particularly beneficial for improving online model discrimination and active fault diagnosis under closed-loop control.},
  Doi                      = {10.1016/j.compchemeng.2019.05.012},
  File                     = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Heirung, Santos, Mesbah - 2019 - Model predictive control with active learning for stochastic systems with structural model uncertain(2).pdf:pdf},
  ISSN                     = {00981354},
  Keywords                 = {Bayesian decision theory,Closed-loop fault diagnosis,Dual control,Online model discrimination,Predictive control,Stochastic systems,Structural model uncertainty},
  Publisher                = {Elsevier Ltd}
}

@TechReport{HenriquesMapNet:Environments,
  Title                    = {{MapNet: An Allocentric Spatial Memory for Mapping Environments}},
  Author                   = {Henriques, João F and Vedaldi, Andrea}
}

@TechReport{Hernandez-LealA,
  Title                    = {{A Survey and Critique of Multiagent Deep Reinforcement Learning {\$}}},
  Author                   = {Hernandez-Leal, Pablo and Kartal, Bilal and Taylor, Matthew E},

  Arxivid                  = {1810.05587v3},
  ISBN                     = {1810.05587v3}
}

@InCollection{HilmiIsmail2019,
  Title                    = {{A Survey and Analysis of Cooperative Multi-Agent Robot Systems: Challenges and Directions}},
  Author                   = {Hilmi Ismail, Zool and Sariff, Nohaidda},
  Booktitle                = {Applications of Mobile Robots [Working Title]},
  Publisher                = {IntechOpen},
  Year                     = {2019},
  Month                    = {2},

  Doi                      = {10.5772/intechopen.79337}
}

@Article{Hofbauer1996,
  Title                    = {{Evolutionary dynamics for bimatrix games: A Hamiltonian system?}},
  Author                   = {Hofbauer, Josef},
  Journal                  = {Journal of Mathematical Biology},
  Year                     = {1996},
  Number                   = {5-6},
  Pages                    = {675--688},
  Volume                   = {34},

  Abstract                 = {We review some properties of the evolutionary dynamics for asymmetric conflicts, give a simplified approach to them, and present some new results on the stability and bifurcations occurring in these conservative systems. In particular, we compare their dynamics to those of Hamiltonian systems. {\textcopyright} Springer-Verlag 1996.},
  Doi                      = {10.1007/BF02409754},
  File                     = {::},
  ISSN                     = {14321416},
  Keywords                 = {Bimatrix games,Bipartite systems,Evolutionary game theory,Hamiltonian systems,Replicator dynamics,Stability,Volume-preserving flows},
  Mendeley-groups          = {STAI/Literature Review/MARL},
  Publisher                = {Springer Verlag}
}

@TechReport{Hong2018ASystems,
  Title                    = {{A Deep Policy Inference Q-Network for Multi-Agent Systems}},
  Author                   = {Hong, Zhang-Wei and Su, Shih-Yang and Shann, Tzu-Yun and Chang, Yi-Hsiang and Lee, Chun-Yi},
  Year                     = {2018},

  Keywords                 = {Deep Reinforcement Learning, Multi-agent Learning, Opponent Modeling},
  Url                      = {www.ifaamas.org}
}

@TechReport{Hu2019,
  Title                    = {{Modelling the Dynamics of Multiagent Q-Learning in Repeated Symmetric Games: a Mean Field Theoretic Approach}},
  Author                   = {Hu, Shuyue and Leung, Chin-Wing and Leung, Ho-Fung},

  Abstract                 = {Modelling the dynamics of multi-agent learning has long been an important research topic, but all of the previous works focus on 2-agent settings and mostly use evolutionary game theoretic approaches. In this paper, we study an n-agent setting with n tends to infinity, such that agents learn their policies concurrently over repeated symmetric bimatrix games with some other agents. Using the mean field theory, we approximate the effects of other agents on a single agent by an averaged effect. A Fokker-Planck equation that describes the evolution of the probability distribution of Q-values in the agent population is derived. To the best of our knowledge, this is the first time to show the Q-learning dynamics under an n-agent setting can be described by a system of only three equations. We validate our model through comparisons with agent-based simulations on typical symmetric bimatrix games and different initial settings of Q-values.},
  File                     = {:home/aamalh/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hu, Leung, Leung - Unknown - Modelling the Dynamics of Multiagent Q-Learning in Repeated Symmetric Games a Mean Field Theoretic Approach.pdf:pdf},
  Mendeley-groups          = {STAI/Literature Review/MARL}
}

@Article{Hu2019QNetworks,
  Title                    = {{Q Learning with Quantum Neural Networks}},
  Author                   = {Hu, Wei and Hu, James},
  Journal                  = {Natural Science},
  Year                     = {2019},
  Number                   = {01},
  Pages                    = {31--39},
  Volume                   = {11},

  Doi                      = {10.4236/ns.2019.111005},
  ISSN                     = {2150-4091},
  Publisher                = {Scientific Research Publishing, Inc,}
}

@InProceedings{Huang2005,
  Title                    = {{Reinforcement learning neural network to the problem of autonomous mobile robot obstacle avoidance}},
  Author                   = {Huang, Bing Qiang and Cao, Guang Yi and Guo, Min},
  Booktitle                = {2005 International Conference on Machine Learning and Cybernetics, ICMLC 2005},
  Year                     = {2005},
  Pages                    = {85--89},

  ISBN                     = {078039092X},
  Keywords                 = {Obstacle avoidance, Reinforcement learning, Reinforcement learning neural network}
}

@Book{IanGoodfellowandYoshuaBengioandAaronCourville2016,
  Title                    = {{Deep Learning}},
  Author                   = {{Ian Goodfellow and Yoshua Bengio and Aaron Courville}},
  Publisher                = {MIT Press},
  Year                     = {2016},

  Url                      = {http://www.deeplearningbook.org}
}

@Article{Imhof2005,
  Title                    = {{Evolutionary cycles of cooperation and defection}},
  Author                   = {Imhof, Lorens A. and Fudenberg, Drew and Nowak, Martin A.},
  Journal                  = {Proceedings of the National Academy of Sciences of the United States of America},
  Year                     = {2005},

  Month                    = {aug},
  Number                   = {31},
  Pages                    = {10797--10800},
  Volume                   = {102},

  Abstract                 = {The main obstacle for the evolution of cooperation is that natural selection favors defection in most settings. In the repeated prisoner's dilemma, two individuals interact several times, and, in each round, they have a choice between cooperation and defection. We analyze the evolutionary dynamics of three simple strategies for the repeated prisoner's dilemma: always defect (ALLD), always cooperate (ALLC), and tit-for-tat (TFT). We study mutation-selection dynamics in finite populations. Despite ALLD being the only strict Nash equilibrium, we observe evolutionary oscillations among all three strategies. The population cycles from ALLD to TFT to ALLC and back to ALLD. Most surprisingly, the time average of these oscillations can be entirely concentrated on TFT. In contrast to the classical expectation, which is informed by deterministic evolutionary game theory of infinitely large populations, stochastic evolution of finite populations need not choose the strict Nash equilibrium and can therefore favor cooperation over defection. {\textcopyright} 2005 by The National Academy of Sciences of the USA.},
  Doi                      = {10.1073/pnas.0502589102},
  File                     = {:home/aamalh/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Imhof, Fudenberg, Nowak - 2005 - Evolutionary cycles of cooperation and defection.pdf:pdf},
  ISSN                     = {00278424},
  Keywords                 = {Evolutionary dynamics,Finite population,Prisoner's dilemma,Reciprocity stochastic process},
  Mendeley-groups          = {STAI/Literature Review/MARL}
}

@TechReport{Inc,
  Title                    = {{Parallax Continuous Rotation Servo ({\#}900-00008)}},
  Author                   = {Inc, Parallax},

  Keywords                 = {BASIC Stamp, Propeller P8X32A, animatronics, bidirectional rotation, full rotation, motor, robot drive, robot motor, servomotor, wheeled robot},
  Url                      = {https://www.parallax.com/sites/default/files/downloads/900-00008-Continuous-Rotation-Servo-Documentation-v2.2.pdf}
}

@InProceedings{Inoue2019,
  Title                    = {{Stochastic self-organizing control for swarm robot systems}},
  Author                   = {Inoue, Daisuke and Murai, Daisuke and Yoshida, Hiroaki},
  Booktitle                = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2019},
  Pages                    = {405--416},
  Publisher                = {Springer Verlag},
  Volume                   = {11655 LNCS},

  Abstract                 = {In swarm robot systems, forming a target shape with autonomously moving robots is an important task. Considering cost and scalability, it is desirable that the observation information required by the robots to form patterns be minimal, whereas the patterns themselves can be as complicated as needed. In this paper, we propose a method of achieving this task under the situation that a scalar value representing a clue to its position is the only information that each robot can observe. We adopted the optimization method proposed by Mesquita et al. [International workshop on hybrid systems: Computation and control, pp. 358 (2008)] as a control method for the swarm robot systems. This method requires neither centralized controllers nor position identification of each robot, and we thus refer to it as “self-organizing control.” Compared with existing control methods, the proposed method reduces memory usage and computational complexity. By means of both numerical simulations and experiments with actual robots, we quantitatively confirmed that self-organization was achieved.},
  Doi                      = {10.1007/978-3-030-26369-0_38},
  ISBN                     = {9783030263683},
  ISSN                     = {16113349},
  Keywords                 = {Multi-agent systems,Self-organization,Swarm robotics}
}

@InProceedings{Jakubuv2015UsingPlanning,
  Title                    = {{Using process calculi for plan verification in multiagent planning}},
  Author                   = {Jakubův, Jan and To{\v{z}}i{\v{c}}ka, Jan and Komenda, Antonín},
  Booktitle                = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2015},
  Volume                   = {9494},

  Doi                      = {10.1007/978-3-319-27947-3{\_}13},
  ISBN                     = {9783319279466},
  ISSN                     = {16113349}
}

@TechReport{Jeurgens2017,
  Title                    = {{Identification and Control Implementation of an AR.Drone 2.0}},
  Author                   = {Jeurgens, N L M},
  Year                     = {2017}
}

@Article{Jiang2019Multi-robotSynergies,
  Title                    = {{Multi-robot planning with conflicts and synergies}},
  Author                   = {Jiang, Yuqian and Yedidsion, Harel and Zhang, Shiqi and Sharon, Guni and Stone, Peter},
  Journal                  = {Autonomous Robots},
  Year                     = {2019},
  Pages                    = {2011--2032},
  Volume                   = {43},

  Doi                      = {10.1007/s10514-019-09848-1},
  ISBN                     = {43:20112032},
  Keywords                 = {Intelligent mobile robotics, Multi-robot planning, Planning under temporal uncertainty},
  Url                      = {https://doi.org/10.1007/s10514-019-09848-1}
}

@InProceedings{Jin2019Control-TheoreticLearning,
  Title                    = {{Control-Theoretic Analysis of Smoothness for Stability-Certified Reinforcement Learning}},
  Author                   = {Jin, Ming and Lavaei, Javad},
  Booktitle                = {Proceedings of the IEEE Conference on Decision and Control},
  Year                     = {2019},
  Month                    = {1},
  Pages                    = {6840--6847},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.},
  Volume                   = {2018-December},

  Doi                      = {10.1109/CDC.2018.8618996},
  ISBN                     = {9781538613955},
  ISSN                     = {07431546}
}

@Article{Jin2018Stability-certifiedPerspective,
  Title                    = {{Stability-certified reinforcement learning: A control-theoretic perspective}},
  Author                   = {Jin, Ming and Lavaei, Javad},
  Year                     = {2018},

  Arxivid                  = {1810.11505},
  ISBN                     = {1810.11505v1},
  Keywords                 = {93D09, 93E35, Reinforcement learning, decentralized control synthesis, policy gradient optimization, robust control, safe reinforcement learning AMS subject classifica},
  Url                      = {http://arxiv.org/abs/1810.11505}
}

@InProceedings{Jung2001DistributedArgumentation,
  Title                    = {{Distributed constraint satisfaction as a computational model of negotiation via argumentation}},
  Author                   = {Jung, Hyuckchul},
  Booktitle                = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2001},
  Pages                    = {767},
  Publisher                = {Springer Verlag},
  Volume                   = {2239},

  Doi                      = {10.1007/3-540-45578-7{\_}68},
  ISBN                     = {3540428631},
  ISSN                     = {16113349}
}

@Article{Katt2018BayesianPOMDPs,
  Title                    = {{Bayesian Reinforcement Learning in Factored POMDPs}},
  Author                   = {Katt, Sammie and Oliehoek, Frans and Amato, Christopher},
  Journal                  = {IFAAMAS},
  Year                     = {2018},
  Volume                   = {9},

  Arxivid                  = {1811.05612},
  Keywords                 = {Bayes Networks, Bayesian reinforcement learning, Monte-Carlo Tree Search, Monte-Chain Monte-Carlo, POMDPs},
  Url                      = {www.ifaamas.org http://arxiv.org/abs/1811.05612}
}

@TechReport{Khatib,
  Title                    = {{Real-Time Obstacle Avoidance for Manipulators and Mobile Robots}},
  Author                   = {Khatib, Oussama},

  Url                      = {https://journals.sagepub.com/doi/pdf/10.1177/027836498600500106}
}

@Article{Kim2015,
  Title                    = {{Deep Neural Network for Real-Time Autonomous Indoor Navigation}},
  Author                   = {Kim, Dong Ki and Chen, Tsuhan},
  Year                     = {2015},

  Month                    = {11},

  Arxivid                  = {1511.04668},
  Url                      = {http://arxiv.org/abs/1511.04668}
}

@InProceedings{Kim2016,
  Title                    = {{Smooth Path Planning by Fusion of Artificial Potential Field Method and Collision Cone Approach}},
  Author                   = {Kim, Yong Hwi and Son, Wan Sic and Park, Jin Bae and Yoon, Tae Sung},
  Booktitle                = {MATEC Web of Conferences},
  Year                     = {2016},
  Month                    = {9},
  Publisher                = {EDP Sciences},
  Volume                   = {75},

  Doi                      = {10.1051/matecconf/20167505004},
  ISSN                     = {2261236X}
}

@TechReport{Klima2019RobustDomains,
  Title                    = {{Robust Temporal Difference Learning for Critical Domains}},
  Author                   = {Klima, Richard and Bloembergen, Daan and Kaisers, Michael and Tuyls, Karl},
  Year                     = {2019},

  Booktitle                = {IFAAMAS},
  Keywords                 = {multi-agent learning, reinforcement learning, robust learning},
  Url                      = {www.ifaamas.org},
  Volume                   = {9}
}

@TechReport{Ko2019,
  Title                    = {{ASYMPTOTIC BEHAVIOR AND CONTROL OF A "GUIDANCE BY REPULSION" MODEL}},
  Author                   = {Ko, Dongnam and Zuazua, Enrique},
  Year                     = {2019},

  Abstract                 = {We model and analyze a herding problem, where the drivers try to steer the evaders' trajectories while the evaders always move away from the drivers. This problem is motivated by the guidance-by-repulsion model [10], where the authors answer how to control the evaders' positions and what is the optimal maneuver of the drivers. First, we obtain the well-posedness and the long-time behavior of the one-driver and one-evader model, assuming of the same friction coefficients. In this case, the exact controllability is proved in a long enough time horizon. We extend the model to the multi-driver and multi-evader case, and develop numerical simulations to systematically explore the nature of controlled dynamics in various scenarios. The optimal strategies turn out to share a common pattern to the one-driver and one-evader case: the drivers rapidly occupy the position behind the target, and want to pursuit evaders in a straight line for most of the time. Inspired by this, we build a feedback strategy which stabilizes the direction of evaders.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1911.01133v1},
  Eprint                   = {1911.01133v1},
  File                     = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Ko, Zuazua - 2019 - ASYMPTOTIC BEHAVIOR AND CONTROL OF A GUIDANCE BY REPULSION MODEL.pdf:pdf},
  Mendeley-groups          = {STAI/Literature Review/Swarm Control}
}

@TechReport{Konak,
  Title                    = {{Multi-Objective Optimization Using Genetic Algorithms: A Tutorial}},
  Author                   = {Konak, Abdullah and Coit, David W and Smith, Alice E},

  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.83.9986&rep=rep1&type=pdf}
}

@TechReport{Korein2018Multi-ArmedRobot,
  Title                    = {{Multi-Armed Bandit Algorithms for Spare Time Planning of a Mobile Service Robot}},
  Author                   = {Korein, Max and Veloso, Manuela},
  Year                     = {2018},

  Keywords                 = {Machine learning for robotics, Robot autonomy, Robot planning and plan execution},
  Url                      = {www.ifaamas.org}
}

@TechReport{Koren1991,
  Title                    = {{Potential Field Methods and Their Inherent Limitations for Mobile Robot Navigation}},
  Author                   = {Koren, Yoram and Borenstein, Johann},
  Year                     = {1991},

  Url                      = {https://pdfs.semanticscholar.org/0a52/3bebee3652d2d293c215be24ad643274a319.pdf}
}

@InProceedings{Kouris2018,
  Title                    = {{Learning to Fly by MySelf: A Self-Supervised CNN-Based Approach for Autonomous Navigation}},
  Author                   = {Kouris, Alexandros and Bouganis, Christos-Savvas},
  Booktitle                = {2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  Year                     = {2018},
  Month                    = {10},
  Pages                    = {1--9},
  Publisher                = {IEEE},

  Doi                      = {10.1109/IROS.2018.8594204},
  ISBN                     = {978-1-5386-8094-0},
  Url                      = {https://ieeexplore.ieee.org/document/8594204/}
}

@TechReport{Kouvaros2019FormalSystems,
  Title                    = {{Formal Verification of Open Multi-Agent Systems}},
  Author                   = {Kouvaros, Panagiotis and Lomuscio, Alessio and Pirovano, Edoardo and Punchihewa, Hashan},
  Year                     = {2019},

  Booktitle                = {IFAAMAS},
  Url                      = {www.ifaamas.org},
  Volume                   = {9}
}

@InProceedings{Kraemer2013ConcurrentUncertainty,
  Title                    = {{Concurrent reinforcement learning as a rehearsal for decentralized planning under uncertainty}},
  Author                   = {Kraemer, Landon and Banerjee, Bikramjit},
  Booktitle                = {12th International Conference on Autonomous Agents and Multiagent Systems 2013, AAMAS 2013},
  Year                     = {2013},
  Pages                    = {1291--1292},
  Publisher                = {International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS)},
  Volume                   = {2},

  Keywords                 = {Decentralized partially observable Markov decision processes, Multi-agent reinforcement learning}
}

@Article{Kuantama2017,
  Title                    = {{PID and Fuzzy-PID Control Model for Quadcopter Attitude with Disturbance Parameter}},
  Author                   = {Kuantama, Endrowednes and Vesselenyi, Tiberiu and Dzitac, Simona and Tarca, Radu},
  Journal                  = {International Journal of Computers Communications {\&} Control},
  Year                     = {2017},

  Month                    = {6},
  Number                   = {4},
  Pages                    = {519},
  Volume                   = {12},

  Doi                      = {10.15837/ijccc.2017.4.2962},
  ISSN                     = {1841-9836},
  Url                      = {http://www.univagora.ro/jour/index.php/ijccc/article/view/2962}
}

@TechReport{KumarMohanty2012,
  Title                    = {{Path Generation and Obstacle Avoidance of an Autonomous Mobile Robot Using Intelligent Hybrid Controller}},
  Author                   = {Kumar Mohanty, Prases and Parhi, Dayal R},
  Year                     = {2012},

  Booktitle                = {LNCS},
  Keywords                 = {ANFIS, Mobile robot, navigation},
  Pages                    = {240--247},
  Volume                   = {7677}
}

@Article{Lansdell2019,
  Title                    = {{Learning to solve the credit assignment problem}},
  Author                   = {Lansdell, Benjamin James and Prakash, Prashanth Ravi and Kording, Konrad Paul},
  Year                     = {2019},

  Month                    = {6},

  Arxivid                  = {1906.00889},
  Url                      = {http://arxiv.org/abs/1906.00889}
}

@Article{LAOUICI2014,
  Title                    = {{Hybrid Method for the Navigation of Mobile Robot Using Fuzzy Logic and Spiking Neural Networks}},
  Author                   = {LAOUICI, Zineb and MAMI, Mohammed Amine and KHELFI, Mohamed Fayçal},
  Journal                  = {International Journal of Intelligent Systems and Applications},
  Year                     = {2014},

  Month                    = {11},
  Number                   = {12},
  Pages                    = {1--9},
  Volume                   = {6},

  Doi                      = {10.5815/ijisa.2014.12.01},
  ISSN                     = {2074904X},
  Publisher                = {MECS Publisher}
}

@TechReport{Le2011,
  Title                    = {{On Optimization Methods for Deep Learning}},
  Author                   = {Le, Quoc V. and Ngiam, Jiquan and Coates, Adam and Lahiri, Abhik and Prochnow, Bobby and Ng, Andrew Y.},
  Institution              = {Stanford University},
  Year                     = {2011}
}

@Misc{Lecun2015,
  Title                    = {{Deep learning}},

  Author                   = {Lecun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  Month                    = {5},
  Year                     = {2015},

  Booktitle                = {Nature},
  Doi                      = {10.1038/nature14539},
  ISSN                     = {14764687},
  Number                   = {7553},
  Pages                    = {436--444},
  Publisher                = {Nature Publishing Group},
  Volume                   = {521}
}

@Misc{LeCunn,
  Title                    = {{MNIST handwritten digit database, Yann LeCun, Corinna Cortes and Chris Burges}},

  Author                   = {{LeCunn}},

  Url                      = {http://yann.lecun.com/exdb/mnist/}
}

@Article{Lee2019A2017,
  Title                    = {{A mission management system for complex aerial logistics by multiple unmanned aerial vehicles in MBZIRC 2017}},
  Author                   = {Lee, Jaehyun and Shim, David Hyunchul and Cho, Sungwook and Shin, Heemin and Jung, Sunggoo and Lee, Dasol and Kang, Jaemin},
  Journal                  = {Journal of Field Robotics},
  Year                     = {2019},

  Month                    = {8},
  Number                   = {5},
  Pages                    = {919--939},
  Volume                   = {36},

  Doi                      = {10.1002/rob.21860},
  ISSN                     = {15564967},
  Keywords                 = {MBZIRC, aerial robotics, cooperative robots, multiple UAVs},
  Publisher                = {John Wiley and Sons Inc.}
}

@Article{Lei2018,
  Title                    = {{Dynamic Path Planning of Unknown Environment Based on Deep Reinforcement Learning}},
  Author                   = {Lei, Xiaoyun and Zhang, Zhian and Dong, Peifang},
  Journal                  = {Journal of Robotics},
  Year                     = {2018},

  Month                    = {9},
  Pages                    = {1--10},
  Volume                   = {2018},

  Doi                      = {10.1155/2018/5781591},
  ISSN                     = {1687-9600},
  Url                      = {https://www.hindawi.com/journals/jr/2018/5781591/}
}

@Article{Leibo2018MalthusianLearning,
  Title                    = {{Malthusian Reinforcement Learning}},
  Author                   = {Leibo, Joel Z and Perolat, Julien and Hughes, Edward and Wheelwright, Steven and Marblestone, Adam H and Du{\'{e}}{\~{n}}ez-Guzm{\'{a}}n, Edgar and Sunehag, Peter and Dunning, Iain and Graepel, Thore},
  Journal                  = {IFAAMAS},
  Year                     = {2018},
  Volume                   = {9},

  Arxivid                  = {1812.07019},
  Keywords                 = {Adaptive radiation, Artificial general intelligence, Demography, Evolution, Intrinsic motivation},
  Url                      = {www.ifaamas.org http://arxiv.org/abs/1812.07019}
}

@TechReport{Leibo2017Multi-agentDilemmas,
  Title                    = {{Multi-agent Reinforcement Learning in Sequential Social Dilemmas}},
  Author                   = {Leibo, Joel Z and Zambaldi, Vinicius and Lanctot, Marc and Marecki, Janusz and Graepel, Thore},
  Year                     = {2017},

  Keywords                 = {Agent / discrete models, CCS Concepts •Computing methodologies → Multi-agent reinforce-ment learning, Keywords Social dilemmas, cooperation, Markov games, agent-based social simulation, non-cooperative games, Stochastic games},
  Url                      = {www.ifaamas.org}
}

@TechReport{Letcher2019DifferentiableMechanics,
  Title                    = {{Differentiable Game Mechanics}},
  Author                   = {Letcher, Alistair and Balduzzi, David and Racan{\`{i}}, Sébastien and Martens, James and Foerster, Jakob and Tuyls, Karl and Graepel, Thore},
  Year                     = {2019},

  Booktitle                = {Journal of Machine Learning Research},
  Keywords                 = {classical mechan-ics, deep learning, dynamical systems, game theory, generative adversarial networks, gradient descent, hamiltonian mechanics},
  Pages                    = {1--40},
  Url                      = {https://github.com/deepmind/symplectic-gradient-adjustment.},
  Volume                   = {20}
}

@TechReport{LetcherSTABLEGAMES,
  Title                    = {{STABLE OPPONENT SHAPING IN DIFFERENTIABLE GAMES}},
  Author                   = {Letcher, Alistair and Foerster, Jakob and Balduzzi, David and Rockt{\"{a}}schel, Tim and Whiteson, Shimon}
}

@InProceedings{Li2012,
  Title                    = {{A potential function and artificial neural network for path planning in dynamic environments based on self-reconfigurable mobile robot system}},
  Author                   = {Li, Bin and Chang, Jian and Wu, Chengdong},
  Booktitle                = {2012 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR)},
  Year                     = {2012},
  Month                    = {11},
  Pages                    = {1--6},
  Publisher                = {IEEE},

  Doi                      = {10.1109/SSRR.2012.6523900},
  ISBN                     = {978-1-4799-0165-4},
  Url                      = {http://ieeexplore.ieee.org/document/6523900/}
}

@Article{Li2018,
  Title                    = {{OIL: Observational Imitation Learning}},
  Author                   = {Li, Guohao and M{\"{u}}ller, Matthias and Casser, Vincent and Smith, Neil and Michels, Dominik L. and Ghanem, Bernard},
  Year                     = {2018},

  Month                    = {3},

  Arxivid                  = {1803.01129},
  Url                      = {http://arxiv.org/abs/1803.01129}
}

@InProceedings{Li2017,
  Title                    = {{Decentralized stochastic control of robotic swarm density: Theory, simulation, and experiment}},
  Author                   = {Li, Hanjun and Feng, Chunhan and Ehrhard, Henry and Shen, Yijun and Cobos, Bernardo and Zhang, Fangbo and Elamvazhuthi, Karthik and Berman, Spring and Haberland, Matt and Bertozzi, Andrea L.},
  Booktitle                = {IEEE International Conference on Intelligent Robots and Systems},
  Year                     = {2017},
  Month                    = {dec},
  Pages                    = {4341--4347},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.},
  Volume                   = {2017-Septe},

  Abstract                 = {This paper explores a stochastic approach for controlling swarms of independent robots toward a target distribution in a bounded domain. The robot swarm has no central controller, and individual robots lack both communication and localization capabilities. Robots can only measure a scalar field (e.g. concentration of a chemical) from the environment and from this deduce the desired local swarm density. Based on this value, each robot follows a simple control law that causes the swarm as a whole to diffuse toward the target distribution. Using a new holonomic drive robot, we present the first confirmation of this control law with physical experiment. Despite deviations from assumptions underpinning the theory, the swarm achieves the theorized convergence to the target distribution in both simulation and experiment. In fact, simulated and experimental performance agree with one another and with our hypothesis that the error from the target distribution is inversely proportional to the square root of the number of robots. This is evidence that the algorithm is both practical and easily scalable to large swarms.},
  Doi                      = {10.1109/IROS.2017.8206299},
  ISBN                     = {9781538626825},
  ISSN                     = {21530866}
}

@Article{Lin2019,
  Title                    = {{Fast 3D Collision Avoidance Algorithm for Fixed Wing UAS}},
  Author                   = {Lin, Zijie and Castano, Lina and Mortimer, Edward and Xu, Huan},
  Journal                  = {Journal of Intelligent and Robotic Systems: Theory and Applications},
  Year                     = {2019},

  Doi                      = {10.1007/s10846-019-01037-7},
  ISSN                     = {15730409},
  Keywords                 = {Air vehicle obstacle avoidance, Avoidance efficiency, Fast obstacle avoidance, Optimal avoidance starting time},
  Publisher                = {Springer Netherlands}
}

@InProceedings{Liu2017LearningMacro-actions,
  Title                    = {{Learning for multi-robot cooperation in partially observable stochastic environments with macro-actions}},
  Author                   = {Liu, Miao and Sivakumar, Kavinayan and Omidshafiei, Shayegan and Amato, Christopher and How, Jonathan P.},
  Booktitle                = {IEEE International Conference on Intelligent Robots and Systems},
  Year                     = {2017},
  Pages                    = {1853--1860},
  Volume                   = {2017-Septe},

  Arxivid                  = {1707.07399},
  Doi                      = {10.1109/IROS.2017.8206001},
  ISBN                     = {9781538626825},
  ISSN                     = {21530866},
  Url                      = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8206001}
}

@Article{Liu2019,
  Title                    = {{Distributed Model Predictive Control for Cooperative and Flexible Vehicle Platooning}},
  Author                   = {Liu, Peng and Kurt, Arda and Ozguner, Umit},
  Journal                  = {IEEE Transactions on Control Systems Technology},
  Year                     = {2019},

  Month                    = {may},
  Number                   = {3},
  Pages                    = {1115--1128},
  Volume                   = {27},

  Abstract                 = {This paper investigates the cooperative and flexible vehicle platooning problem in automated highway systems. We formulate the platoon into a dynamically decoupled system and address the flexible platooning problem using distributed model predictive control (DMPC) techniques. A two-step noniterative DMPC strategy is proposed that sequentially solves local components of a constrained optimal control problem over two batches of vehicle clusters based on intervehicle communication. By introducing the clustering procedure, the proposed DMPC scheme only requires compatibility constraints of common neighbors of two adjacent vehicle clusters. With the two-step DMPC scheme, stability of the overall closed-loop system is guaranteed by a series of linear matrix inequalities that can be efficiently solved in practical applications. Collision-free properties are addressed using coupled state constraints together with terminal sets during a cooperation procedure. Simulations of flexible platooning are conducted for both joining and leaving events to show the effectiveness of the two-step DMPC scheme.},
  Doi                      = {10.1109/TCST.2018.2808911},
  ISSN                     = {1558-0865},
  Keywords                 = {Automated highway systems,controller synthesis,cooperative driving,distributed model predictive control (DMPC),platoon formation},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.}
}

@TechReport{LiuTrust-Aware,
  Title                    = {{Trust-Aware Behavior Reflection for Robot Swarm Self-Healing *}},
  Author                   = {Liu, Rui and Jia, Fan and Luo, Wenhao and Chandarana, Meghan and Nam, Changjoo and Lewis, Michael and Sycara, Katia},

  Keywords                 = {Behavior Reflection, Swarm Self-Healing, Trust, Trust-R, WMSR},
  Url                      = {www.ifaamas.org}
}

@Article{Liu2019a,
  Title                    = {{Aircraft Trajectory Optimization for Collision Avoidance Using Stochastic Optimal Control}},
  Author                   = {Liu, Wensheng and Liang, Xuelin and Ma, Yunzhu and Liu, Weiyi},
  Journal                  = {Asian Journal of Control},
  Year                     = {2019},

  Month                    = {sep},
  Number                   = {5},
  Pages                    = {2308--2320},
  Volume                   = {21},

  Doi                      = {10.1002/asjc.1855},
  ISSN                     = {1561-8625},
  Url                      = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asjc.1855}
}

@TechReport{Lomuscio2019ASystems,
  Title                    = {{A Counter Abstraction Tech-nique for the Verification of Probabilistic Swarm Systems}},
  Author                   = {Lomuscio, Alessio and Pirovano, Edoardo},
  Year                     = {2019},

  Booktitle                = {IFAAMAS},
  Url                      = {www.ifaamas.org},
  Volume                   = {9}
}

@Book{Lygeros2004,
  Title                    = {{Lecture Notes on Hybrid Systems}},
  Author                   = {Lygeros, John},
  Year                     = {2004},

  Abstract                 = {The aim of this course is to introduce some fundamental concepts from the area of hybrid systems, that is dynamical systems that involve the interaction of continuous (real valued) states and discrete (finite valued) states. Applications where these types of dynamics play a prominent role will be highlighted. We will introduce general methods for investigating properties such as existence of solutions, reachability and decidability of hybrid systems. The methods will be demonstrated on the motivating applications. Students who successfully complete the course should be able to appreciate the diversity of phenomena that arise in hybrid systems and how discrete “discrete” entities and concepts such as automata, decidability and bisimulation can coexist with continuous entities and concepts, such as differential equations.},
  Booktitle                = {Reading},
  File                     = {:Users/aamalh/STAI/Literature Review/Papers/lygeros.pdf:pdf},
  Pages                    = {82}
}

@Article{Lyu2016,
  Title                    = {{Feature article: Vision-based UAV collision avoidance with 2D dynamic safety envelope}},
  Author                   = {Lyu, Yang and Pan, Quan and Zhao, Chunhui and Zhang, Yizhai and Hu, Jinwen},
  Journal                  = {IEEE Aerospace and Electronic Systems Magazine},
  Year                     = {2016},

  Month                    = {7},
  Number                   = {7},
  Pages                    = {16--26},
  Volume                   = {31},

  Doi                      = {10.1109/MAES.2016.150155},
  ISSN                     = {08858985},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.}
}

@Article{Ma2017Overview:Systems,
  Title                    = {{Overview: A Hierarchical Framework for Plan Generation and Execution in Multirobot Systems}},
  Author                   = {Ma, Hang and H{\"{o}}nig, Wolfgang and Cohen, Liron and Uras, Tansel and Xu, Hong and Kumar, T. K.Satish and Ayanian, Nora and Koenig, Sven},
  Journal                  = {IEEE Intelligent Systems},
  Year                     = {2017},

  Month                    = {11},
  Number                   = {6},
  Pages                    = {6--12},
  Volume                   = {32},

  Doi                      = {10.1109/MIS.2017.4531217},
  ISSN                     = {15411672},
  Keywords                 = {intelligent systems, multirobot planning, multirobot systems, path planning, plan execution},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.}
}

@Misc{Ma2017,
  Title                    = {{Consensus control of stochastic multi-agent systems: a survey}},

  Author                   = {Ma, Lifeng and Wang, Zidong and Han, Qing Long and Liu, Yurong},
  Month                    = {dec},
  Year                     = {2017},

  Abstract                 = {In this article, we provide a review of the consensus control problem for stochastic multi-agent systems (MASs). Recent advances are surveyed according to the method of occurrence of the stochasticity of the MASs. First, the consensus problem is discussed for MASs, wherein individual agents are corrupted by random noises, i.e., the dynamics of agents involve stochasticity in process and/or measurement equations. Both additive noises and multiplicative noises are surveyed in detail and special attention is paid to the MASs whose dynamics are governed by It{\^{o}} differential equations. Moreover, particular effort is devoted to presenting the latest progress on the consensus problem for a special type of stochastic MAS with Markovian jump parameters. Subsequently, the relevant research is summarized for MASs with noisy communication environments and stochastic sampling. Further, we provide a systematic review of the consensus problems for MASs whose communication topology varies randomly in the process of data propagation among agents. Finally, conclusions are drawn and several potential future research directions are outlined.},
  Booktitle                = {Science China Information Sciences},
  Doi                      = {10.1007/s11432-017-9169-4},
  File                     = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Ma et al. - 2017 - Consensus control of stochastic multi-agent systems a survey.pdf:pdf},
  ISSN                     = {18691919},
  Keywords                 = {Markovian jump systems,consensus control,random topology,stochastic multi-agent systems,stochastic noises},
  Number                   = {12},
  Publisher                = {Science in China Press},
  Volume                   = {60}
}

@InProceedings{Mac2016,
  Title                    = {{AR.Drone UAV control parameters tuning based on particle swarm optimization algorithm}},
  Author                   = {Mac, Thi Thoa and Copot, Cosmin and Duc, Trung Tran and De Keyser, Robin},
  Booktitle                = {2016 20th IEEE International Conference on Automation, Quality and Testing, Robotics, AQTR 2016 - Proceedings},
  Year                     = {2016},
  Month                    = {6},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.},

  Doi                      = {10.1109/AQTR.2016.7501380},
  ISBN                     = {9781467386906}
}

@InProceedings{Mac2016a,
  Title                    = {{AR.Drone UAV control parameters tuning based on particle swarm optimization algorithm}},
  Author                   = {Mac, Thi Thoa and Copot, Cosmin and Duc, Trung Tran and De Keyser, Robin},
  Booktitle                = {2016 IEEE International Conference on Automation, Quality and Testing, Robotics (AQTR)},
  Year                     = {2016},
  Month                    = {5},
  Pages                    = {1--6},
  Publisher                = {IEEE},

  Doi                      = {10.1109/AQTR.2016.7501380},
  ISBN                     = {978-1-4673-8692-0},
  Url                      = {http://ieeexplore.ieee.org/document/7501380/}
}

@TechReport{Magalhaes-Mendes,
  Title                    = {{A Comparative Study of Crossover Operators for Genetic Algorithms to Solve the Job Shop Scheduling Problem}},
  Author                   = {Magalh{\~{a}}es-Mendes, Jorge},

  Keywords                 = {Crossover Operators, Genetic Algorithms, JSSP, Key-Words:-Scheduling, Operations Research, Optimization},
  Url                      = {https://pdfs.semanticscholar.org/3bda/cac99759ca1c71e241b815ea50226b05af70.pdf}
}

@TechReport{Makar2001HierarchicalLearning,
  Title                    = {{Hierarchical Multi-Agent Reinforcement Learning}},
  Author                   = {Makar, Rajbala and Mahadevan, Sridhar and Ghavamzadeh, Mohammad},
  Year                     = {2001},

  ISBN                     = {158113326X}
}

@TechReport{MaoModellingDDPG,
  Title                    = {{Modelling the Dynamic Joint Policy of Teammates with Attention Multi-agent DDPG}},
  Author                   = {Mao, Hangyu and Zhang, Zhengchao and Xiao, Zhen and Gong, Zhibo and Gong, Zhibo 2019},

  Keywords                 = {Agent Modelling, Deep Reinforcement Learning, Multi-agent Reinforcement Learning, Teammates Modelling},
  Url                      = {www.ifaamas.org}
}

@techreport{Gleave,
abstract = {Deep reinforcement learning (RL) policies are known to be vulnerable to adversar-ial perturbations to their observations, similar to adversarial examples for classifiers. However, an attacker is not usually able to directly modify another agent's observations. This might lead one to wonder: is it possible to attack an RL agent simply by choosing an adversarial policy acting in a multi-agent environment so as to create natural observations that are adversarial? We demonstrate the existence of adversarial policies in zero-sum games between simulated humanoid robots with proprioceptive observations, against state-of-the-art victims trained via self-play to be robust to opponents. The adversarial policies reliably win against the victims but generate seemingly random and uncoordinated behavior. We find that these policies are more successful in high-dimensional environments, and induce substantially different activations in the victim policy network than when the victim plays against a normal opponent. Fine-tuning protects a victim against a specific adversary, but the attack method can be successfully reapplied to find a new adversarial policy. Videos are available at https://adversarialpolicies.github.io/.},
archivePrefix = {arXiv},
arxivId = {1905.10615v2},
author = {Gleave, Adam and Dennis, Michael and Wild, Cody and Kant, Neel and Levine, Sergey and Russell, Stuart},
eprint = {1905.10615v2},
file = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Gleave et al. - Unknown - ADVERSARIAL POLICIES ATTACKING DEEP REINFORCEMENT LEARNING.pdf:pdf},
mendeley-groups = {STAI/Literature Review},
title = {{ADVERSARIAL POLICIES: ATTACKING DEEP REINFORCEMENT LEARNING}},
url = {https://adversarialpolicies.github.io/.}
}
@techreport{Littman,
abstract = {In the Markov decision process (MDP) formaliza-tion of reinforcement learning, a single adaptive agent interacts with an environment defined by a probabilistic transition function. In this solipsis-tic view, secondary agents can only be part of the environment and are therefore fixed in their behavior. The framework of Markov games allows us to widen this view to include multiple adap-tive agents with interacting or competing goals. This paper considers a step in this direction in which exactly two agents with diametrically opposed goals share an environment. It describes a Q-learning-like algorithm for finding optimal policies and demonstrates its application to a simple two-player game in which the optimal policy is probabilistic.},
author = {Littman, Michael L},
file = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Littman - Unknown - Markov games as a framework for multi-agent reinforcement learning.pdf:pdf},
mendeley-groups = {STAI/Literature Review},
title = {{Markov games as a framework for multi-agent reinforcement learning}}
}

@article{Zhang2019,
abstract = {Recent years have witnessed significant advances in reinforcement learning (RL), which has registered great success in solving various sequential decision-making problems in machine learning. Most of the successful RL applications, e.g., the games of Go and Poker, robotics, and autonomous driving, involve the participation of more than one single agent, which naturally fall into the realm of multi-agent RL (MARL), a domain with a relatively long history, and has recently re-emerged due to advances in single-agent RL techniques. Though empirically successful, theoretical foundations for MARL are relatively lacking in the literature. In this chapter, we provide a selective overview of MARL, with focus on algorithms backed by theoretical analysis. More specifically, we review the theoretical results of MARL algorithms mainly within two representative frameworks, Markov/stochastic games and extensive-form games, in accordance with the types of tasks they address, i.e., fully cooperative, fully competitive, and a mix of the two. We also introduce several significant but challenging applications of these algorithms. Orthogonal to the existing reviews on MARL, we highlight several new angles and taxonomies of MARL theory, including learning in extensive-form games, decentralized MARL with networked agents, MARL in the mean-field regime, (non-)convergence of policy-based methods for learning in games, etc. Some of the new angles extrapolate from our own research endeavors and interests. Our overall goal with this chapter is, beyond providing an assessment of the current state of the field on the mark, to identify fruitful future research directions on theoretical studies of MARL. We expect this chapter to serve as continuing stimulus for researchers interested in working on this exciting while challenging topic.},
archivePrefix = {arXiv},
arxivId = {1911.10635},
author = {Zhang, Kaiqing and Yang, Zhuoran and Başar, Tamer},
eprint = {1911.10635},
file = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Zhang Zhuoran Yang, Bas - Unknown - Multi-Agent Reinforcement Learning A Selective Overview of Theories and Algorithms.pdf:pdf},
mendeley-groups = {STAI/Literature Review},
title = {{Multi-Agent Reinforcement Learning: A Selective Overview of Theories and Algorithms}},
url = {http://arxiv.org/abs/1911.10635},
year = {2019}
}



@inproceedings{Sahin2005,
abstract = {Swarm robotics is a novel approach to the coordination of large numbers of relatively simple robots which takes its inspiration from social insects. This paper proposes a definition to this newly emerging approach by 1) describing the desirable properties of swarm robotic systems, as observed in the system-level functioning of social insects, 2) proposing a definition for the term swarm robotics, and putting forward a set of criteria that can be used to distinguish swarm robotics research from other multi-robot studies, 3) providing a review of some studies which can act as sources of inspiration, and a list of promising domains for the utilization of swarm robotic systems. {\textcopyright} Springer-Verlag Berlin Heidelberg 2005.},
author = {Şahin, Erol},
booktitle = {Lecture Notes in Computer Science},
doi = {10.1007/978-3-540-30552-1_2},
file = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Sahin - 2004 - Swarm Robotics From Sources of Inspiration to Domains of Application. Swarm robotics View project.pdf:pdf},
issn = {03029743},
pages = {10--20},
title = {{Swarm robotics: From sources of inspiration to domains of application}},
url = {https://www.researchgate.net/publication/221116606},
volume = {3342},
year = {2005}
}


@techreport{Hu,
abstract = {In this paper, we adopt general-sum stochas-tic games as a framework for multiagent reinforcement learning. Our work extends previous work by Littman on zero-sum stochas-tic games to a broader framework. We design a multiagent Q-learning method under this framework, and prove that it converges to a Nash equilibrium under speciied conditions. This algorithm is useful for rnding the optimal strategy when there exists a unique Nash equilibrium in the game. When there exist multiple Nash equilibria in the game, this algorithm should be combined with other learning techniques to ond optimal strategies.},
author = {Hu, Junling and Ellman, Michael P W},
file = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Hu, Ellman - Unknown - Multiagent Reinforcement Learning Theoretical Framework and an Algorithm.pdf:pdf},
mendeley-groups = {STAI/Literature Review},
title = {{Multiagent Reinforcement Learning: Theoretical Framework and an Algorithm}}
}


@Article{Marden2018AnnualControl,
  Title                    = {{Annual Review of Control, Robotics, and Autonomous Systems Game Theory and Control}},
  Author                   = {Marden, Jason R and Shamma, Jeff S},
  Year                     = {2018},

  Doi                      = {10.1146/annurev-control-060117},
  Keywords                 = {distributed control, game theory, learning in games, mechanism design, team games, zero-sum games},
  Url                      = {https://doi.org/10.1146/annurev-control-060117-}
}

@Article{Marinescu2014,
  Title                    = {{Decentralised Multi-Agent Reinforcement Learning for Dynamic and Uncertain Environments}},
  Author                   = {Marinescu, Andrei and Dusparic, Ivana and Taylor, Adam and Cahill, Vinny and Clarke, Siobh{\'{a}}n},
  Year                     = {2014},

  Abstract                 = {Multi-Agent Reinforcement Learning (MARL) is a widely used technique for optimization in decentralised control problems. However, most applications of MARL are in static environments, and are not suitable when agent behaviour and environment conditions are dynamic and uncertain. Addressing uncertainty in such environments remains a challenging problem for MARL-based systems. The dynamic nature of the environment causes previous knowledge of how agents interact to become outdated. Advanced knowledge of potential changes through prediction significantly supports agents converging to near-optimal control solutions. In this paper we propose P-MARL, a decentralised MARL algorithm enhanced by a prediction mechanism that provides accurate information regarding up-coming changes in the environment. This prediction is achieved by employing an Artificial Neural Network combined with a Self-Organising Map that detects and matches changes in the environment. The proposed algorithm is validated in a realistic smart-grid scenario, and provides a 92{\%} Pareto efficient solution to an electric vehicle charging problem.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1409.4561},
  Eprint                   = {1409.4561},
  File                     = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Marinescu et al. - Unknown - Decentralised Multi-Agent Reinforcement Learning for Dynamic and Uncertain Environments.pdf:pdf},
  Url                      = {www.aaai.org http://arxiv.org/abs/1409.4561}
}

@InCollection{Mataric2008,
  Title                    = {{Behavior-Based Systems}},
  Author                   = {Matari{\'{c}}, Maja J. and Michaud, François},
  Booktitle                = {Springer Handbook of Robotics},
  Publisher                = {Springer Berlin Heidelberg},
  Year                     = {2008},

  Address                  = {Berlin, Heidelberg},
  Pages                    = {891--909},

  Doi                      = {10.1007/978-3-540-30301-5{\_}39},
  Url                      = {http://link.springer.com/10.1007/978-3-540-30301-5_39}
}

@InProceedings{Matignon2018Multi-robotTrack,
  Title                    = {{Multi-robot simultaneous coverage and mapping of complex scene - Comparison of different strategies: Robotics track}},
  Author                   = {Matignon, Laetitia and Simonint, Olivier},
  Booktitle                = {Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS},
  Year                     = {2018},
  Pages                    = {559--567},
  Volume                   = {1},

  ISBN                     = {9781510868083},
  ISSN                     = {15582914},
  Keywords                 = {Mapping and exploration, Multi-robot systems, Networked robot, Sensor systems},
  Url                      = {www.ifaamas.org}
}

@Article{Matsuda2019,
  Title                    = {{Accurate and Efficient Seafloor Observations With Multiple Autonomous Underwater Vehicles: Theory and Experiments in a Hydrothermal Vent Field}},
  Author                   = {Matsuda, Takumi and Maki, Toshihiro and Sakamaki, Takashi},
  Journal                  = {IEEE Robotics and Automation Letters},
  Year                     = {2019},

  Month                    = {7},
  Number                   = {3},
  Pages                    = {2333--2339},
  Volume                   = {4},

  Doi                      = {10.1109/LRA.2019.2902744},
  ISSN                     = {2377-3766},
  Url                      = {https://ieeexplore.ieee.org/document/8657727/}
}

@InProceedings{Mazurowski2007SolvingOptimization,
  Title                    = {{Solving multi-agent control problems using particle swarm optimization}},
  Author                   = {Mazurowski, Maciej A. and Zurada, Jacek M.},
  Booktitle                = {Proceedings of the 2007 IEEE Swarm Intelligence Symposium, SIS 2007},
  Year                     = {2007},
  Pages                    = {105--111},

  Doi                      = {10.1109/SIS.2007.368033},
  ISBN                     = {1424407087}
}

@InProceedings{McFadyen2013,
  Title                    = {{Aircraft collision avoidance using spherical visual predictive control and single point features}},
  Author                   = {McFadyen, Aaron and Mejias, Luis and Corke, Peter and Pradalier, Cedric},
  Booktitle                = {IEEE International Conference on Intelligent Robots and Systems},
  Year                     = {2013},
  Pages                    = {50--56},

  Doi                      = {10.1109/IROS.2013.6696331},
  ISBN                     = {9781467363587},
  ISSN                     = {21530858}
}

@Article{Mendes2017,
  Title                    = {{A practical approach for hybrid distributed MPC}},
  Author                   = {Mendes, Paulo R.C. and Maestre, Jose M. and Bordons, Carlos and Normey-Rico, Julio E.},
  Journal                  = {Journal of Process Control},
  Year                     = {2017},
  Pages                    = {30--41},
  Volume                   = {55},

  Abstract                 = {This paper presents a framework to deal with distributed optimization problems composed by binary and continuous variables. Instead of using a mixed integer quadratic programming (MIQP), the approach proposed here transforms the MIQP into a set of quadratic programming's (QP) that are easier to solve. In this way an instance of the controller related to each feasible combination of binary variables is created. The distributed controller performs an iterative process where the set of agents must agree on the value of continuous interconnection variables, while each agent must decide the values of local binary variables. During the iteration procedure the instances are rated according to a performance index and the instances with best performance are selected until the best one is obtained. The proposed methodology is applied to economic optimization of networked microgrids.},
  Doi                      = {10.1016/j.jprocont.2017.01.001},
  ISSN                     = {09591524},
  Keywords                 = {Distributed model predictive control,Hybrid systems,Networked microgrids},
  Publisher                = {Elsevier Ltd}
}

@TechReport{Meng,
  Title                    = {{Game-Theory based Multi-Robot Searching Approach}},
  Author                   = {Meng, Yan and Cao, Ke},

  Url                      = {https://www.researchgate.net/publication/237226958}
}

@TechReport{MertikopoulosCYCLESLEARNING,
  Title                    = {{CYCLES IN ADVERSARIAL REGULARIZED LEARNING}},
  Author                   = {Mertikopoulos, Panayotis and Papadimitriou, Christos and Piliouras, Georgios},

  Arxivid                  = {1709.02738v1}
}

@Misc{Mesbah2016,
  Title                    = {{Stochastic model predictive control: An overview and perspectives for future research}},

  Author                   = {Mesbah, Ali},
  Month                    = {dec},
  Year                     = {2016},

  Abstract                 = {Model predictive control (MPC) has demonstrated exceptional success for the high-performance control of complex systems [1], [2]. The conceptual simplicity of MPC as well as its ability to effectively cope with the complex dynamics of systems with multiple inputs and outputs, input and state/output constraints, and conflicting control objectives have made it an attractive multivariable constrained control approach [1]. MPC (a.k.a. receding-horizon control) solves an open-loop constrained optimal control problem (OCP) repeatedly in a receding-horizon manner [3]. The OCP is solved over a finite sequence of control actions {\{}u 0 ,u 1 ,⋯,u N-1 {\}} at every sampling time instant that the current state of the system is measured. The first element of the sequence of optimal control actions is applied to the system, and the computations are then repeated at the next sampling time. Thus, MPC replaces a feedback control law $\pi$({\textperiodcentered}), which can have formidable offline computation, with the repeated solution of an open-loop OCP [2]. In fact, repeated solution of the OCP confers an "implicit" feedback action to MPC to cope with system uncertainties and disturbances. Alternatively, explicit MPC approaches circumvent the need to solve an OCP online by deriving relationships for the optimal control actions in terms of an "explicit" function of the state and reference vectors. However, explicit MPC is not typically intended to replace standard MPC but, rather, to extend its area of application [4]-[6].},
  Booktitle                = {IEEE Control Systems},
  Doi                      = {10.1109/MCS.2016.2602087},
  File                     = {::},
  ISSN                     = {1066033X},
  Mendeley-groups          = {STAI/PhD/Games},
  Number                   = {6},
  Pages                    = {30--44},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.},
  Volume                   = {36}
}

@TechReport{MeursAdvancesIntelligence,
  Title                    = {{Advances in Artificial Intelligence}},
  Author                   = {Meurs, Marie-Jean and Rudzicz, Frank and Goebel, Randy and Tanaka, Yuzuru and Wahlster, Wolfgang and Siekmann, Jörg},

  Doi                      = {10.1007/978-3-030-18305-9},
  Url                      = {http://www.springer.com/series/1244}
}

@PhdThesis{FUHRMANFrancescoRUSSO,
  Title                    = {{Probabilistic Representation of HJB Equations for Optimal Control of Jump Processes , BSDEs and Related Stochastic Calculus}},
  Author                   = {Milano, Politecnico},
  Year                     = {2016},

  File                     = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/FUHRMAN Francesco RUSSO, LUCCHETTI Fr{\'{e}}d{\'{e}}ric PAULIN - Unknown - Politecnico di Milano Probabilistic Representation of HJB Equations for.pdf:pdf}
}

@TechReport{Milchtaich2007StaticGames,
  Title                    = {{Static Stability in Games}},
  Author                   = {Milchtaich, Igal},
  Year                     = {2007},

  Keywords                 = {Stability of equilibrium, static stability}
}

@InProceedings{Min-HoKim2011,
  Title                    = {{A path planning algorithm using artificial potential field based on probability map}},
  Author                   = {{Min-Ho Kim} and {Jung-Hun Heo} and {Yuanlong Wei} and {Min-Cheol Lee}},
  Booktitle                = {2011 8th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)},
  Year                     = {2011},
  Month                    = {11},
  Pages                    = {41--43},
  Publisher                = {IEEE},

  Doi                      = {10.1109/URAI.2011.6145929},
  ISBN                     = {978-1-4577-0723-0},
  Url                      = {http://ieeexplore.ieee.org/document/6145929/}
}

@Article{Minsky2014,
  Title                    = {{Evolutionary artificial neural networks}},
  Author                   = {Minsky, Marvin},
  Journal                  = {Adaptation, Learning, and Optimization},
  Year                     = {2014},
  Pages                    = {187--230},
  Volume                   = {15},

  Doi                      = {10.1007/978-3-642-37846-1{\_}7},
  ISSN                     = {18674542},
  Publisher                = {Springer Verlag}
}

@InCollection{Mitraa,
  Title                    = {{Mesh Smoothing}},
  Author                   = {Mitra, Niloy},

  Url                      = {https://moodle-1819.ucl.ac.uk/pluginfile.php/370192/mod_resource/content/6/05_Smoothing.pdf}
}

@TechReport{Mitra,
  Title                    = {{Mesh Smoothing}},
  Author                   = {Mitra, Niloy J}
}

@TechReport{Mnih,
  Title                    = {{Playing Atari with Deep Reinforcement Learning}},
  Author                   = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},

  Url                      = {https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf}
}

@InProceedings{Molinos2014,
  Title                    = {{Dynamic obstacle avoidance based on curvature arcs}},
  Author                   = {Molinos, Eduardo and Llamazares, Angel and Ocana, Manuel and Herranz, Fernando},
  Booktitle                = {2014 IEEE/SICE International Symposium on System Integration, SII 2014},
  Year                     = {2014},
  Month                    = {1},
  Pages                    = {186--191},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.},

  Doi                      = {10.1109/SII.2014.7028035},
  ISBN                     = {9781479969449}
}

@Article{Montiel2015,
  Title                    = {{Path planning for mobile robots using Bacterial Potential Field for avoiding static and dynamic obstacles}},
  Author                   = {Montiel, Oscar and Orozco-Rosas, Ulises and Sep{\'{u}}lveda, Roberto},
  Journal                  = {Expert Systems with Applications},
  Year                     = {2015},

  Month                    = {7},
  Number                   = {12},
  Pages                    = {5177--5191},
  Volume                   = {42},

  Doi                      = {10.1016/J.ESWA.2015.02.033},
  ISSN                     = {0957-4174},
  Publisher                = {Pergamon},
  Url                      = {https://www.sciencedirect.com/science/article/pii/S0957417415001402}
}

@InProceedings{Mordatch2018EmergencePopulations,
  Title                    = {{Emergence of grounded compositional language in multi-agent populations}},
  Author                   = {Mordatch, Igor and Abbeel, Pieter},
  Booktitle                = {32nd AAAI Conference on Artificial Intelligence, AAAI 2018},
  Year                     = {2018},
  Pages                    = {1495--1502},

  Arxivid                  = {1703.04908},
  ISBN                     = {9781577358008},
  Keywords                 = {Multi-Agent Reinforcement Learning, Multi-Robot Systems, Robot Team Formation},
  Url                      = {https://blog.openai.com/openai-five/.}
}

@TechReport{MouraPires,
  Title                    = {{Lecture Notes in Artificial Intelligence 2902 Subseries of Lecture Notes in Computer Science}},
  Author                   = {Moura Pires, Fernando and Abreu, Salvador},

  Pages                    = {24--28}
}

@TechReport{Mueller-Wodarg2018,
  Title                    = {{Fluid Dynamics Third year Physics core course}},
  Author                   = {Mueller-Wodarg, Ingo},
  Year                     = {2018}
}

@TechReport{MylvaganamASystems,
  Title                    = {{A Game Theoretic Approach to Distributed Control of Homogeneous Multi-Agent Systems}},
  Author                   = {Mylvaganam, T}
}

@TechReport{Mylvaganam2014,
  Title                    = {{APPROXIMATE FEEDBACK SOLUTIONS FOR DIFFERENTIAL GAMES THEORY AND APPLICATIONS}},
  Author                   = {Mylvaganam, Thulasi},
  Year                     = {2014}
}

@Article{Mylvaganam2017AutonomousApproach,
  Title                    = {{Autonomous collision avoidance for wheeled mobile robots using a differential game approach}},
  Author                   = {Mylvaganam, Thulasi and Sassano, Mario},
  Journal                  = {European Journal of Control},
  Year                     = {2017},
  Pages                    = {53--61},
  Volume                   = {40},

  Doi                      = {10.1016/j.ejcon.2017.11.005},
  Keywords                 = {Collision avoidance, Differential games, Multi-agent systems, Nonlinear control systems},
  Url                      = {https://doi.org/10.1016/j.ejcon.2017.11.005}
}

@InProceedings{Nagarajan2018,
  Title                    = {{Three body problems in evolutionary game dynamics: Convergence, periodicity and limit cycles}},
  Author                   = {Nagarajan, Sai Ganesh and Mohamed, Sameh and Piliouras, Georgios},
  Booktitle                = {Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS},
  Year                     = {2018},
  Pages                    = {685--693},
  Volume                   = {1},

  Abstract                 = {We study the asymptotic behavior of replicator dynamics in sett ings of network interaction. We focus on three agent graphical games where each edge/game is either a 2x2 zero-sum or a 2x2 coordination game. Using tools from dynamical systems such as Lyapunov functions and invariant functions we establish that this simple family of games can exhibit an interesting range of behavi ors such as global convergence, periodicity for all initial conditions as well as limit cycles. In contrast, we do not observe more complex behavior such as toroids or chaos while it is possible to reproduce them in slightly more complicated settings.},
  File                     = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Nagarajan, Mohamed, Piliouras - 2018 - Three Body Problems in Evolutionary Game Dynamics Convergence, Periodicity and Limit Cycles(2).pdf:pdf},
  ISBN                     = {9781510868083},
  ISSN                     = {15582914},
  Keywords                 = {Cooperative games,Evolutionary games,Multi-agent learning,Noncooperative games,Theory and analysis},
  Mendeley-groups          = {STAI/Literature Review},
  Url                      = {www.ifaamas.org}
}

@Book{Nagy2013,
  Title                    = {{Active Team Management Strategies for Multi-robot Teams in Dangerous Environments}},
  Author                   = {Nagy, Geoff and Anderson, John},
  Publisher                = {WORLD SCIENTIFIC},
  Year                     = {2013},
  Month                    = {6},

  Booktitle                = {Advances in Artificial Intelligence},
  Doi                      = {10.1142/1305}
}

@InCollection{Neal2011MCMCDynamics,
  Title                    = {{MCMC using hamiltonian dynamics}},
  Author                   = {Neal, Radford M.},
  Booktitle                = {Handbook of Markov Chain Monte Carlo},
  Publisher                = {CRC Press},
  Year                     = {2011},
  Month                    = {5},
  Pages                    = {113--162},

  Arxivid                  = {1206.1901},
  Doi                      = {10.1201/b10905-6},
  ISBN                     = {9781420079425}
}

@InProceedings{Negenborn2014,
  Title                    = {{Distributed Model Predictive Control: An overview of features and research opportunities}},
  Author                   = {Negenborn, R. R. and Maestre, J. M.},
  Booktitle                = {Proceedings of the 11th IEEE International Conference on Networking, Sensing and Control, ICNSC 2014},
  Year                     = {2014},
  Pages                    = {530--535},
  Publisher                = {IEEE Computer Society},

  Abstract                 = {This is a position paper on the current state of the art in distributed Model Predictive Control (MPC) and our view on its future potential. We present results from a recent survey of 35 distributed MPC approaches. For this, we propose a way in which distributed MPC approaches can be categorized for comparison. We also link the potential that these approaches have to the domain of other fields such as integrated environmental optimal decision making and cyber-physical systems. Many challenges for realizing these links have to be faced. We present our views on how the advances in several highly active research domains could be used to overcome these challenges. As such, this paper is intended as a starting point for the exploration of various novel research cooperations. {\textcopyright} 2014 IEEE.},
  Doi                      = {10.1109/ICNSC.2014.6819682},
  ISBN                     = {9781479931064},
  Keywords                 = {Distributed model predictive control,algorithm categorization,emerging research areas}
}

@InCollection{Nowe2012GameLearning,
  Title                    = {{Game theory and multi-agent reinforcement learning}},
  Author                   = {Now{\'{e}}, Ann and Vrancx, Peter and De Hauwere, Yann Michaël},
  Booktitle                = {Adaptation, Learning, and Optimization},
  Publisher                = {Springer Verlag},
  Year                     = {2012},
  Pages                    = {441--470},
  Volume                   = {12},

  Doi                      = {10.1007/978-3-642-27645-3{\_}14},
  ISSN                     = {18674542},
  Keywords                 = {Assure, Eter, Librium, Lution, Nash}
}

@InProceedings{OBeirne2006AExploration,
  Title                    = {{A market framework for collaborative robot exploration}},
  Author                   = {O'Beirne, Declan and Schukat, Michael},
  Booktitle                = {VDI Berichte},
  Year                     = {2006},
  Number                   = {1956},
  Pages                    = {305},

  ISSN                     = {00835560},
  Keywords                 = {Collaborative, Exploration, Market}
}

@TechReport{OliehoekDecentralizedPOMDPs,
  Title                    = {{Decentralized POMDPs}},
  Author                   = {Oliehoek, Frans A}
}

@Article{Omidshafiei2017DecentralizedMacro-actions,
  Title                    = {{Decentralized control of multi-robot partially observable Markov decision processes using belief space macro-actions}},
  Author                   = {Omidshafiei, Shayegan and Agha-Mohammadi, Ali-Akbar and Amato, Christopher and Liu, Shih-Yuan and How, Jonathan P and Vian, John},
  Journal                  = {The International Journal of Robotics Research},
  Year                     = {2017},
  Number                   = {2},
  Pages                    = {231--258},
  Volume                   = {36},

  Doi                      = {10.1177/0278364917692864}
}

@Article{Owen2005,
  Title                    = {{The effects of linear and quadratic drag on falling spheres: An undergraduate laboratory}},
  Author                   = {Owen, Julia P. and Ryu, William S.},
  Journal                  = {European Journal of Physics},
  Year                     = {2005},

  Month                    = {11},
  Number                   = {6},
  Pages                    = {1085--1091},
  Volume                   = {26},

  Doi                      = {10.1088/0143-0807/26/6/016},
  ISSN                     = {01430807}
}

@InProceedings{Pallottino2007ProbabilisticAvoidance,
  Title                    = {{Probabilistic verification of decentralized multi-agent control strategies: A Case Study in Conflict Avoidance}},
  Author                   = {Pallottino, Lucia and Bicchi, Antonio and Frazzoli, Emilio},
  Booktitle                = {Proceedings of the American Control Conference},
  Year                     = {2007},
  Pages                    = {170--175},

  Doi                      = {10.1109/ACC.2007.4283164},
  ISBN                     = {1424409888},
  ISSN                     = {07431619}
}

@Article{Paulson2019,
  Title                    = {{An efficient method for stochastic optimal control with joint chance constraints for nonlinear systems}},
  Author                   = {Paulson, Joel A. and Mesbah, Ali},
  Journal                  = {International Journal of Robust and Nonlinear Control},
  Year                     = {2019},

  Month                    = {oct},
  Number                   = {15},
  Pages                    = {5017--5037},
  Volume                   = {29},

  Doi                      = {10.1002/rnc.3999},
  ISSN                     = {1049-8923},
  Url                      = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rnc.3999}
}

@Article{Pini2011TaskSelection,
  Title                    = {{Task partitioning in swarms of robots: An adaptive method for strategy selection}},
  Author                   = {Pini, Giovanni and Brutschy, Arne and Frison, Marco and Roli, Andrea and Dorigo, Marco and Birattari, Mauro},
  Journal                  = {Swarm Intelligence},
  Year                     = {2011},
  Number                   = {3-4},
  Pages                    = {283--304},
  Volume                   = {5},

  Doi                      = {10.1007/s11721-011-0060-1},
  ISSN                     = {19353812},
  Keywords                 = {Foraging, Self-organization, Swarm robotics, Task partitioning}
}

@Article{Pini2013AutonomousEstimation,
  Title                    = {{Autonomous task partitioning in robot foraging: An approach based on cost estimation}},
  Author                   = {Pini, Giovanni and Brutschy, Arne and Pinciroli, Carlo and Dorigo, Marco and Birattari, Mauro},
  Journal                  = {Adaptive Behavior},
  Year                     = {2013},

  Doi                      = {10.1177/1059712313484771},
  ISSN                     = {10597123},
  Keywords                 = {Task partitioning, foraging, self-organization, swarm intelligence, swarm robotics}
}

@TechReport{Platt1998,
  Title                    = {{Sequential Minimal Optimization: A Fast Algorithm for Training Support Vector Machines}},
  Author                   = {Platt, John C},
  Year                     = {1998},

  Url                      = {https://pdfs.semanticscholar.org/59ee/e096b49d66f39891eb88a6c84cc89acba12d.pdf}
}

@TechReport{Pounds,
  Title                    = {{Modelling and Control of a Quad-Rotor Robot}},
  Author                   = {Pounds, Paul and Mahony, Robert and Corke, Peter},

  Url                      = {https://pdfs.semanticscholar.org/4eb8/ee77b0fe804ad6df17f80ad4d9eca1791733.pdf}
}

@Book{Prince2012,
  Title                    = {{Computer Vision: Models, Learning, and Inference}},
  Author                   = {Prince, S.J.D.},
  Publisher                = {Cambridge University Press},
  Year                     = {2012}
}

@Book{Prince2012a,
  Title                    = {{Computer Vision: Models, Learning, and Inference}},
  Author                   = {Prince, Simon J.D.},
  Publisher                = {Cambridge University Press},
  Year                     = {2012}
}

@InProceedings{Purian2013,
  Title                    = {{Mobile robots path planning using ant colony optimization and Fuzzy Logic algorithms in unknown dynamic environments}},
  Author                   = {Purian, Fatemeh Khosravi and Sadeghian, Ehsan},
  Booktitle                = {CARE 2013 - 2013 IEEE International Conference on Control, Automation, Robotics and Embedded Systems, Proceedings},
  Year                     = {2013},

  Doi                      = {10.1109/CARE.2013.6733718},
  ISBN                     = {9781467361538},
  Keywords                 = {Ants colony algorithm, fuzzy logic, mobile robot, path planning, the dynamic environment}
}

@InProceedings{Qiao2008,
  Title                    = {{Application of reinforcement learning based on neural network to dynamic obstacle avoidance}},
  Author                   = {Qiao, Junfei and Hou, Zhanjun and Ruan, Xiaogang},
  Booktitle                = {Proceedings of the 2008 IEEE International Conference on Information and Automation, ICIA 2008},
  Year                     = {2008},
  Pages                    = {784--788},

  Doi                      = {10.1109/ICINFA.2008.4608104},
  ISBN                     = {9781424421848}
}

@InProceedings{Ramachandran2007BayesianLearning,
  Title                    = {{Bayesian inverse reinforcement learning}},
  Author                   = {Ramachandran, Deepak and Amir, Eyal},
  Booktitle                = {IJCAI International Joint Conference on Artificial Intelligence},
  Year                     = {2007},

  ISSN                     = {10450823}
}

@Book{rawlings2017model,
  Title                    = {{Model Predictive Control: Theory, Computation, and Design}},
  Author                   = {Rawlings, J B and Mayne, D Q and Diehl, M},
  Publisher                = {Nob Hill Publishing},
  Year                     = {2017},

  ISBN                     = {9780975937730},
  Url                      = {https://books.google.co.uk/books?id=MrJctAEACAAJ}
}

@TechReport{Ray2010,
  Title                    = {{An Extension of Bayesian Game Approximation to Partially Observable Stochastic Games with Competition and Cooperation. Theoretical and Computational Models of the Human Mind and Brain View project An Extension of Bayesian Game Approximation to Partially O}},
  Author                   = {Ray, Laura E and Kralik, Jerald D and Shi, Dongqing and Sauter, Michael Z and Sun, Xueqing},
  Year                     = {2010},

  Url                      = {https://www.researchgate.net/publication/220835260}
}

@Article{Reis2019RobustVehicles,
  Title                    = {{Robust Cooperative Moving Path Following Control for Marine Robotic Vehicles}},
  Author                   = {Reis, Matheus F. and Jain, R. Praveen and Aguiar, A. Pedro and de Sousa, Joao Borges},
  Journal                  = {Frontiers in Robotics and AI},
  Year                     = {2019},

  Month                    = {11},
  Volume                   = {6},

  Doi                      = {10.3389/frobt.2019.00121},
  ISSN                     = {2296-9144},
  Url                      = {https://www.frontiersin.org/article/10.3389/frobt.2019.00121/full}
}

@Misc{Rizk2018,
  Title                    = {{Decision Making in Multiagent Systems: A Survey}},

  Author                   = {Rizk, Yara and Awad, Mariette and Tunstel, Edward W.},
  Month                    = {9},
  Year                     = {2018},

  Booktitle                = {IEEE Transactions on Cognitive and Developmental Systems},
  Doi                      = {10.1109/TCDS.2018.2840971},
  ISSN                     = {23798939},
  Keywords                 = {Cooperation, Markov decision process (MDP), decision making models, game theory, multiagent systems (MASs), swarm intelligence},
  Number                   = {3},
  Pages                    = {514--529},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.},
  Volume                   = {10}
}

@Article{RobotAI,
  Title                    = {{Artificial Intelligence and Robotics}},
  Author                   = {{RobotAI}}
}

@Article{Rong2019CompetitiveNetworks,
  Title                    = {{Competitive Bridge Bidding with Deep Neural Networks}},
  Author                   = {Rong, Jiang and Qin, Tao and An, Bo},
  Journal                  = {IFAAMAS},
  Year                     = {2019},
  Volume                   = {9},

  Arxivid                  = {1903.00900},
  Keywords                 = {artificial intelligence, contract bridge, reinforcement learning},
  Url                      = {https://en.wikipedia.org/wiki/Standard_American http://arxiv.org/abs/1903.00900}
}

@TechReport{Rosello2018Multi-AgentTracking,
  Title                    = {{Multi-Agent Reinforcement Learning for Multi-Object Tracking}},
  Author                   = {Rosello, Pol and Kochenderfer, Mykel J},
  Year                     = {2018},

  Booktitle                = {ACM Reference Format: Pol Rosello and Mykel J. Kochenderfer},
  Keywords                 = {Engineering Multiagent Systems—Innovative agents a, Learning and Adaptation—Deep learning, Learning and Adaptation—Multiagent learning},
  Url                      = {www.ifaamas.org}
}

@Article{Rosen2019CommunicatingDisplays,
  Title                    = {{Communicating and controlling robot arm motion intent through mixed-reality head-mounted displays}},
  Author                   = {Rosen, Eric and Whitney, David and Phillips, Elizabeth and Chien, Gary and Tompkin, James and Konidaris, George and Tellex, Stefanie},
  Journal                  = {International Journal of Robotics Research},
  Year                     = {2019},

  Month                    = {10},

  Arxivid                  = {1708.03655},
  Doi                      = {10.1177/0278364919842925},
  ISSN                     = {17413176},
  Keywords                 = {Mixed reality, human–robot interaction, motion planning},
  Publisher                = {SAGE Publications Inc.}
}

@Article{Rosenfeld2019ExplainabilitySystems,
  Title                    = {{Explainability in human–agent systems}},
  Author                   = {Rosenfeld, Avi and Richardson, Ariella},
  Journal                  = {Autonomous Agents and Multi-Agent Systems},
  Year                     = {2019},

  Arxivid                  = {1904.08123},
  Doi                      = {10.1007/s10458-019-09408-y},
  ISSN                     = {15737454},
  Keywords                 = {Human–agent systems, Machine learning interpretability, Machine learning transparency, XAI},
  Publisher                = {Springer New York LLC}
}

@Article{Rosolia2018,
  Title                    = {{Learning model predictive control for iterative tasks. A data-driven control framework}},
  Author                   = {Rosolia, Ugo and Borrelli, Francesco},
  Journal                  = {IEEE Transactions on Automatic Control},
  Year                     = {2018},

  Month                    = {jul},
  Number                   = {7},
  Pages                    = {1883--1896},
  Volume                   = {63},

  Abstract                 = {A learning model predictive controller for iterative tasks is presented. The controller is reference-free and is able to improve its performance by learning from previous iterations. A safe set and a terminal cost function are used in order to guarantee recursive feasibility and nondecreasing performance at each iteration. This paper presents the control design approach, and shows how to recursively construct terminal set and terminal cost from state and input trajectories of previous iterations. Simulation results show the effectiveness of the proposed control logic.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1609.01387},
  Doi                      = {10.1109/TAC.2017.2753460},
  Eprint                   = {1609.01387},
  File                     = {:home/aamalh/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rosolia, Borrelli - 2018 - Learning model predictive control for iterative tasks. A data-driven control framework.pdf:pdf},
  ISSN                     = {00189286},
  Keywords                 = {Data driven,iterative learning control,learning,optimal control,predictive control,safety},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.}
}

@InProceedings{Ross2013,
  Title                    = {{Learning monocular reactive UAV control in cluttered natural environments}},
  Author                   = {Ross, Stephane and Melik-Barkhudarov, Narek and Shankar, Kumar Shaurya and Wendel, Andreas and Dey, Debadeepta and Bagnell, J. Andrew and Hebert, Martial},
  Booktitle                = {Proceedings - IEEE International Conference on Robotics and Automation},
  Year                     = {2013},
  Pages                    = {1765--1772},

  Doi                      = {10.1109/ICRA.2013.6630809},
  ISBN                     = {9781467356411},
  ISSN                     = {10504729}
}

@Article{Roy2017,
  Title                    = {{A Fokker-Planck approach to control collective motion}},
  Author                   = {Roy, Souvik and Borz{\`{i}}, Alfio and Klingenberg, Christian and Annunziato, Mario and Alfio,  and Borz`ı, Borz`},
  Journal                  = {Article in Computational Optimization and Applications},
  Year                     = {2017},

  Abstract                 = {A Fokker-Planck control strategy for collective motion is investigated. This strategy is formulated as the minimisation of an expectation objective with a bilinear optimal control problem governed by the Fokker-Planck equation modelling the evolution of the probability density function of the stochastic motion. Theoretical results on existence and regularity of optimal controls are provided. The resulting optimality system is discretized using an alternate-direction implicit Chang-Cooper scheme that guarantees conservativeness, positiv-ity, L 1 stability, and second-order accuracy of the forward solution. A projected non-linear conjugate gradient scheme is used to solve the optimality system. Results of numerical experiments validate the theoretical accuracy estimates and demonstrate the efficiency of the proposed control framework.},
  Doi                      = {10.1007/s10589-017-9944-3},
  File                     = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Roy et al. - 2017 - A Fokker-Planck approach to control collective motion.pdf:pdf},
  Keywords                 = {35Q91,35Q93,49J20,49K20,65C20,Chang-Cooper scheme,Fokker-Planck equation,alternate direction method,control constrained PDE optimization AMS: 35Q84,pro-jected gradient method},
  Mendeley-groups          = {STAI/Literature Review/Swarm Control},
  Url                      = {https://www.researchgate.net/publication/282152317}
}

@TechReport{Sabatino2015,
  Title                    = {{Quadrotor control: modeling, nonlinear control design, and simulation}},
  Author                   = {Sabatino, Francesco},
  Year                     = {2015},

  Url                      = {https://www.kth.se/polopoly_fs/1.588039!/Thesis KTH - Francesco Sabatino.pdf}
}

@TechReport{Sabatino2015a,
  Title                    = {{Quadrotor control: modeling, nonlinear control design, and simulation}},
  Author                   = {Sabatino, Francesco},
  Year                     = {2015},

  Url                      = {https://www.kth.se/polopoly_fs/1.588039.1550155544!/Thesis KTH - Francesco Sabatino.pdf}
}

@TechReport{Sabatino2015b,
  Title                    = {{Quadrotor control: modeling, nonlinear control design, and simulation}},
  Author                   = {Sabatino, Francesco},
  Year                     = {2015}
}

@Article{Sanders2018,
  Title                    = {{The prevalence of chaotic dynamics in games with many players}},
  Author                   = {Sanders, James B.T. and Farmer, J. Doyne and Galla, Tobias},
  Journal                  = {Scientific Reports},
  Year                     = {2018},

  Month                    = {dec},
  Number                   = {1},
  Volume                   = {8},

  Abstract                 = {We study adaptive learning in a typical p-player game. The payoffs of the games are randomly generated and then held fixed. The strategies of the players evolve through time as the players learn. The trajectories in the strategy space display a range of qualitatively different behaviours, with attractors that include unique fixed points, multiple fixed points, limit cycles and chaos. In the limit where the game is complicated, in the sense that the players can take many possible actions, we use a generating-functional approach to establish the parameter range in which learning dynamics converge to a stable fixed point. The size of this region goes to zero as the number of players goes to infinity, suggesting that complex non-equilibrium behaviour, exemplified by chaos, is the norm for complicated games with many players.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1612.08111},
  Doi                      = {10.1038/s41598-018-22013-5},
  Eprint                   = {1612.08111},
  File                     = {:home/aamalh/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sanders, Farmer, Galla - 2018 - The prevalence of chaotic dynamics in games with many players.pdf:pdf},
  ISSN                     = {20452322},
  Mendeley-groups          = {STAI/Literature Review/MARL},
  Publisher                = {Nature Publishing Group}
}

@article{Camerer1999,
abstract = {In 'experience-weighted attraction' (EWA) learning, strategies have attractions that reflect initial predispositions, are updated based on payoff experience, and determine choice probabilities according to some rule (e.g., logit). A key feature is a parameter 6 that weights the strength of hypothetical reinforcement of strategies that were not chosen according to the payoff they would have yielded, relative to reinforcement of chosen strategies according to received payoffs. The other key features are two discount rates, $\phi$ and $\rho$, which separately discount previous attractions, and an experience weight. EWA includes reinforcement learning and weighted fictitious play (belief learning) as special cases, and hybridizes their key elements. When $\delta$ = 0 and $\rho$ = 0, cumulative choice reinforcement results. When $\delta$ = 1 and $\rho$ = $\phi$, levels of reinforcement of strategies are exactly the same as expected payoffs given weighted fictitious play beliefs. Using three sets of experimental data, parameter estimates of the model were calibrated on part of the data and used to predict a holdout sample. Estimates of $\delta$ are generally around .50, $\phi$ around .8-1, and p varies from 0 to $\phi$. Reinforcement and belief-learning special cases are generally rejected in favor of EWA, though belief models do better in some constant-sum games. EWA is able to combine the best features of previous approaches, allowing attractions to begin and grow flexibly as choice reinforcement docs, but reinforcing unchosen strategies substantially as belief-based models implicitly do.},
author = {Camerer, Colin and Ho, Teck Hua},
doi = {10.1111/1468-0262.00054},
issn = {00129682},
journal = {Econometrica},
keywords = {Behavioral game theory,Fictitious play,Learning,Reinforcement learning},
mendeley-groups = {STAI/Literature Review},
month = {jul},
number = {4},
pages = {827--874},
publisher = {Blackwell Publishing Ltd},
title = {{Experience-weighted attraction learning in normal form games}},
url = {https://onlinelibrary.wiley.com/doi/full/10.1111/1468-0262.00054 https://onlinelibrary.wiley.com/doi/abs/10.1111/1468-0262.00054 https://onlinelibrary.wiley.com/doi/10.1111/1468-0262.00054},
volume = {67},
year = {1999}
}


@book{Camerer2003,
  added-at = {2009-08-21T12:12:59.000+0200},
  address = {Princeton, NJ [u.a.]},
  author = {Camerer, {Colin F.}},
  biburl = {https://www.bibsonomy.org/bibtex/2d45f56603a7d4c62e50c737732aa2df5/fbw_hannover},
  interhash = {2cd22eb68a0aec4a3cd84006e788ff6a},
  intrahash = {d45f56603a7d4c62e50c737732aa2df5},
  isbn = {978-0-691-09039-9},
  keywords = {Decision_making Entscheidungstheorie Game_theory Human_behavior Mathematical_models Methoden_und_Techniken_der_Betriebswirtschaft Methoden_und_Techniken_der_Volkswirtschaft Social_interaction Spieltheorie Statistische_Entscheidungstheorie Theorie Verhaltenswissenschaften Verhaltensökonomik},
  pagetotal = {XV, 550},
  ppn_gvk = {353560901},
  publisher = {Princeton Univ. Press [u.a.]},
  series = {The roundtable series in behavioral economics},
  subtitle = {experiments in strategic interaction},
  timestamp = {2009-08-21T12:13:18.000+0200},
  title = {Behavioral game theory},
  url = {http://gso.gbv.de/DB=2.1/CMD?ACT=SRCHA&SRT=YOP&IKT=1016&TRM=ppn+353560901&sourceid=fbw_bibsonomy},
  year = 2003
}

@Article{Sartoretti2014,
  Title                    = {{Decentralized self-selection of swarm trajectories: from dynamical systems theory to robotic implementation}},
  Author                   = {Sartoretti, Guillaume and Hongler, Max Olivier and de Oliveira, Marcelo Elias and Mondada, Francesco},
  Journal                  = {Swarm Intelligence},
  Year                     = {2014},
  Number                   = {4},
  Pages                    = {329--351},
  Volume                   = {8},

  Abstract                 = {In this paper, we present a distributed control strategy, enabling agents to converge onto and travel along a consensually selected curve among a class of closed planar curves. Individual agents identify the number of neighbors within a finite circular sensing range and obtain information from their neighbors through local communication. The information is then processed to update the control parameters and force the swarm to converge onto and circulate along the aforementioned planar curve. The proposed mathematical framework is based on stochastic differential equations driven by white Gaussian noise (diffusion processes). Using this framework, there is maximum probability that the swarm dynamics will be driven toward the consensual closed planar curve. In the simplest configuration where a circular consensual curve is obtained, we are able to derive an analytical expression that relates the radius of the circular formation to the agent's interaction range. Such an intimate relation is also illustrated numerically for more general curves. The agent-based control strategy is then translated into a distributed Braitenberg-inspired one. The proposed robotic control strategy is then validated by numerical simulations and by implementation on an actual robotic swarm. It can be used in applications that involve large numbers of locally interacting agents, such as traffic control, deployment of communication networks in hostile environments, or environmental monitoring.},
  Doi                      = {10.1007/s11721-014-0101-7},
  File                     = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Sartoretti et al. - 2014 - Decentralized self-selection of swarm trajectories from dynamical systems theory to robotic implementation.pdf:pdf},
  ISSN                     = {19353820},
  Keywords                 = {Braitenberg control mechanism,Brownian agents,Distributed swarm control,Mean-field approach,Mixed canonical-dissipative dynamics,Robotics experimental validation,Spatio-temporal pattern}
}

@Article{Sato2002,
  Title                    = {{Chaos in learning a simple two-person game}},
  Author                   = {Sato, Yuzuru and Akiyama, Eizo and Farmer, J. Doyne},
  Journal                  = {Proceedings of the National Academy of Sciences of the United States of America},
  Year                     = {2002},

  Month                    = {apr},
  Number                   = {7},
  Pages                    = {4748--4751},
  Volume                   = {99},

  Abstract                 = {We investigate the problem of learning to play the game of rock-paper-scissors. Each player attempts to improve her/his average score by adjusting the frequency of the three possible responses, using reinforcement learning. For the zero sum game the learning process displays Hamiltonian chaos. Thus, the learning trajectory can be simple or complex, depending on initial conditions. We also investigate the non-zero sum case and show that it can give rise to chaotic transients. This is, to our knowledge, the first demonstration of Hamiltonian chaos in learning a basic two-person game, extending earlier findings of chaotic attractors in dissipative systems. As we argue here, chaos provides an important self-consistency condition for determining when players will learn to behave as though they were fully rational. That chaos can occur in learning a simple game indicates one should use caution in assuming real people will learn to play a game according to a Nash equilibrium strategy.},
  Doi                      = {10.1073/pnas.032086299},
  File                     = {:home/aamalh/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sato, Akiyama, Farmer - 2002 - Chaos in learning a simple two-person game.pdf:pdf},
  ISSN                     = {00278424},
  Mendeley-groups          = {STAI/Literature Review/MARL}
}

@TechReport{Schaffer,
  Title                    = {{Multiple Objective Optimization with Vector Evaluated Genetic Algorithms. A Novel Approach to Event-driven Simulation of Spiking Neural Network View project 1) a diagnostic test for dementia based upon speech View project}},
  Author                   = {Schaffer, J David},

  Url                      = {https://www.researchgate.net/publication/220885605}
}

@Book{Scholkopf1999,
  Title                    = {{Advances in kernel methods : support vector learning}},
  Author                   = {Schölkopf, Bernhard. and Burges, Christopher J. C. and Smola, Alexander J.},
  Publisher                = {MIT Press},
  Year                     = {1999},

  Booktitle                = {Advances in kernel methods},
  ISBN                     = {0262194163},
  Pages                    = {376},
  Url                      = {https://dl.acm.org/citation.cfm?id=299106}
}

@Book{SchwartzMulti-agentApproach,
  Title                    = {{Multi-agent machine learning : a reinforcement approach}},
  Author                   = {Schwartz, Howard M.},

  ISBN                     = {9781118362082}
}

@Article{Sedaghat-Pisheh2017,
  Title                    = {{Collision avoidance algorithms for unmanned aerial vehicles using computer vision}},
  Author                   = {Sedaghat-Pisheh, Hani and Rivera, Amaury and Biaz, Saad and Chapman, Richard},
  Journal                  = {Journal of Computing Sciences in Colleges},
  Year                     = {2017},
  Number                   = {2},
  Pages                    = {191--197},
  Volume                   = {33},

  ISSN                     = {1937-4771}
}

@Article{SerdarGuzel2019AStrategy,
  Title                    = {{A Novel Framework for Multi-Agent Systems Using a Decentralized Strategy}},
  Author                   = {Serdar G{\"{u}}zel, Mehmet and Ajabshir, Vahid Babaei},
  Journal                  = {Robotica},
  Year                     = {2019},
  Pages                    = {691--707},
  Volume                   = {37},

  Doi                      = {10.1017/S0263574718001261},
  Keywords                 = {Decentralized architecture, Multi-agent systems, Pattern formation, Swarm intelligence, Vision for navigation},
  Publisher                = {C Cambridge University Press},
  Url                      = {https://doi.org/10.1017/S0263574718001261}
}

@InProceedings{Sethi2017,
  Title                    = {{Comparative analysis of a recommender system based on ant colony optimization and artificial bee colony optimization algorithms}},
  Author                   = {Sethi, Deepshikha and Singhal, Abhishek},
  Booktitle                = {8th International Conference on Computing, Communications and Networking Technologies, ICCCNT 2017},
  Year                     = {2017},
  Month                    = {12},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.},

  Doi                      = {10.1109/ICCCNT.2017.8204106},
  ISBN                     = {9781509030385},
  Keywords                 = {Ant Colony Optimization, Artificial Bee Colony Optimization, CPU Time, Collaborative Filtering, Standard Functions}
}

@InProceedings{Shahrokhi2019,
  Title                    = {{Reshaping particle configurations by collisions with rigid objects}},
  Author                   = {Shahrokhi, Shiva and Zhao, Haoran and Becker, Aaron T.},
  Booktitle                = {Proceedings - IEEE International Conference on Robotics and Automation},
  Year                     = {2019},
  Month                    = {may},
  Pages                    = {4436--4443},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.},
  Volume                   = {2019-May},

  Abstract                 = {Consider many particles actuated by a uniform global external field (e.g. gravitational or magnetic fields). This paper presents analytical results using workspace obstacles and global inputs to reshape such a group of particles. Shape control of many particles is necessary for conveying information, construction, and navigation. First we show how the particles' characteristic angle of repose can be used to reshape the particles by controlling angle of attack and the magnitude of the driving force. These can then be used to control the force and torque applied to a rectangular rigid body. Next, we examine the full set of stable, achievable mean and variance configurations for the shape of a particle group in two canonical environments: a square and a circular workspace. Finally, we show how workspaces with linear boundary layers can be used to achieve a more rich set of mean and variance configurations.},
  Doi                      = {10.1109/ICRA.2019.8794405},
  ISBN                     = {9781538660263},
  ISSN                     = {10504729}
}

@Article{Sharma2012,
  Title                    = {{Bayesian-game-based fuzzy reinforcement learning control for decentralized POMDPs}},
  Author                   = {Sharma, Rajneesh and Spaan, Matthijs T.J.},
  Journal                  = {IEEE Transactions on Computational Intelligence and AI in Games},
  Year                     = {2012},
  Number                   = {4},
  Pages                    = {309--328},
  Volume                   = {4},

  Doi                      = {10.1109/TCIAIG.2012.2212279},
  ISSN                     = {1943068X},
  Keywords                 = {Bayesian games (BGs), decentralized partially observable Markov decision, fuzzy systems, reinforcement learning (RL)}
}

@InProceedings{Sharma2011FuzzyProcesses,
  Title                    = {{Fuzzy reinforcement learning control for decentralized partially observable Markov decision processes}},
  Author                   = {Sharma, Rajneesh and Spaan, Matthijs T.J.},
  Booktitle                = {IEEE International Conference on Fuzzy Systems},
  Year                     = {2011},
  Pages                    = {1422--1429},

  Doi                      = {10.1109/FUZZY.2011.6007675},
  ISBN                     = {9781424473175},
  ISSN                     = {10987584},
  Keywords                 = {Cooperative multiagent systems, Decentralized POMDPs, Fuzzy systems, Reinforcement learning}
}

@TechReport{Shawe-Taylor,
  Title                    = {{A review of optimization methodologies in support vector machines}},
  Author                   = {Shawe-Taylor, John and Sun, Shiliang},

  Keywords                 = {Decision support systems, Duality, Optimization methodology, Pattern classification, Support vector machine (SVM)},
  Url                      = {https://shiliangsun.github.io/pubs/ROMSVM.pdf}
}

@TechReport{ShohamMultiagentFoundations,
  Title                    = {{Multiagent Systems: Algorithmic, Game-Theoretic, and Logical Foundations}},
  Author                   = {Shoham, Yoav and Leyton-Brown, Kevin},

  Keywords                 = {algorithms, auctions, communication, competition, cooperation, distributed problem solving, game theory, learning, logic, mechanism design, social choice},
  Url                      = {http://www.masfoundations.org.}
}

@Article{Singla2018,
  Title                    = {{Memory-based Deep Reinforcement Learning for Obstacle Avoidance in UAV with Limited Environment Knowledge}},
  Author                   = {Singla, Abhik and Padakandla, Sindhu and Bhatnagar, Shalabh},
  Year                     = {2018},

  Month                    = {11},

  Arxivid                  = {1811.03307},
  Url                      = {http://arxiv.org/abs/1811.03307}
}

@InProceedings{Sirigineedi2010DecentralisedApproach,
  Title                    = {{Decentralised cooperative aerial surveillance for harbour security: A formal verification approach}},
  Author                   = {Sirigineedi, Gopinadh and Tsourdos, Antonios and White, Brian A. and Silson, Peter},
  Booktitle                = {2010 IEEE Globecom Workshops, GC'10},
  Year                     = {2010},
  Pages                    = {1831--1835},

  Doi                      = {10.1109/GLOCOMW.2010.5700258},
  ISBN                     = {9781424488650}
}

@Article{Solihin2011,
  Title                    = {{Tuning of PID Controller Using Particle Swarm Optimization (PSO)}},
  Author                   = {Solihin, Mahmud Iwan and Tack, Lee Fook and Kean, Moey Leap},
  Journal                  = {International Journal on Advanced Science, Engineering and Information Technology},
  Year                     = {2011},
  Number                   = {4},
  Pages                    = {458},
  Volume                   = {1},

  Doi                      = {10.18517/ijaseit.1.4.93},
  ISSN                     = {2460-6952},
  Url                      = {http://ijaseit.insightsociety.org/index.php?option=com_content&view=article&id=9&Itemid=1&article_id=93}
}

@InProceedings{Spaan2006DecentralizedAgents,
  Title                    = {{Decentralized planning under uncertainty for teams of communicating agents}},
  Author                   = {Spaan, Matthijs T.J. and Gordon, Geoffrey J. and Vlassis, Nikos},
  Booktitle                = {Proceedings of the International Conference on Autonomous Agents},
  Year                     = {2006},
  Pages                    = {249--256},
  Volume                   = {2006},

  Doi                      = {10.1145/1160633.1160678},
  ISBN                     = {1595933034},
  Keywords                 = {Artificial intelligence, Cooperative multiagent systems, Decentralized POMDPs, Planning under uncertainty}
}

@InProceedings{Stancliff2009PlanningAllocation,
  Title                    = {{Planning to fail - Reliability needs to be considered a priori in multirobot task allocation}},
  Author                   = {Stancliff, Stephen B. and Dolan, John and Trebi-Ollennu, Ashitey},
  Booktitle                = {Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics},
  Year                     = {2009},
  Pages                    = {2362--2367},

  Doi                      = {10.1109/ICSMC.2009.5346359},
  ISBN                     = {9781424427949},
  ISSN                     = {1062922X},
  Keywords                 = {Multirobot systems, Reliability, Task allocation}
}

@Book{Strogatz2000,
  Title                    = {Nonlinear Dynamics and Chaos: With Applications to Physics, Biology, Chemistry and Engineering},
  Author                   = {Strogatz, Steven H.},
  Publisher                = {Westview Press},
  Year                     = {2000},

  Added-at                 = {2010-05-11T11:15:46.000+0200},
  Biburl                   = {https://www.bibsonomy.org/bibtex/2e3b3dc5a68df87d71becbe75709a7121/flashbang},
  Citeulike-article-id     = {6778211},
  Interhash                = {097881c5ab43732a75182222236e72c7},
  Intrahash                = {e3b3dc5a68df87d71becbe75709a7121},
  Keywords                 = {chaos dynamical-systems nonlinear},
  Posted-at                = {2010-03-08 21:41:28},
  Priority                 = {2},
  Timestamp                = {2010-05-11T11:16:46.000+0200}
}

@Article{Subramanian2019,
  Title                    = {{Reinforcement learning in stationary mean-field games}},
  Author                   = {Subramanian, Jayakumar},
  Journal                  = {Proceedings of the 18th International Conference of Autonomous Agents and Multi-Agent Systems, AAMAS'19},
  Year                     = {2019},
  Number                   = {Aamas},
  Pages                    = {251--259},
  Volume                   = {9},

  Abstract                 = {Multi-agent reinforcement learning has made significant progress in recent years, but it remains a hard problem. Hence, one often resorts to developing learning algorithms for specific classes of multi-agent systems. In this paper we study reinforcement learning in a specific class of multi-agent systems systems called mean-field games. In particular, we consider learning in stationary mean-field games. We identify two different solution concepts—stationary mean-field equilibrium and stationary mean-field social-welfare optimal policy—for such games based on whether the agents are non-cooperative or cooperative, respectively. We then generalize these solution concepts to their local variants using bounded ra- tionality based arguments. For these two local solution concepts, we present two reinforcement learning algorithms. We show that the algorithms converge to the right solution under mild technical conditions and demonstrate this using two numerical examples.},
  File                     = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Subramanian, Mahajan - 2019 - Reinforcement Learning in Stationary Mean-field Games.pdf:pdf},
  Keywords                 = {bounded rationality,mean-field games,multi-agent reinforcement learning,stationary},
  Url                      = {www.ifaamas.org}
}

@InProceedings{Subramanian2012,
  Title                    = {{Obstacle avoidance using multi-point potential field approach for an underactuated flat-fish type AUV in dynamic environment}},
  Author                   = {Subramanian, Saravanakumar and George, Thomas and Thondiyath, Asokan},
  Booktitle                = {Communications in Computer and Information Science},
  Year                     = {2012},
  Pages                    = {20--27},
  Volume                   = {330 CCIS},

  Doi                      = {10.1007/978-3-642-35197-6{\_}3},
  ISBN                     = {9783642351969},
  ISSN                     = {18650929},
  Keywords                 = {AUV, dynamic model, obstacle avoidance, potential field, trajectory planning}
}

@Book{Sutton2018,
  Title                    = {{Reinforcement Learning: An Introduction}},
  Author                   = {Sutton, R and Barto, A},
  Publisher                = {MIT Press},
  Year                     = {2018},

  Url                      = {http://incompleteideas.net/book/the-book-2nd.html}
}

@InProceedings{Symington2014,
  Title                    = {{Simulating quadrotor UAVs in outdoor scenarios}},
  Author                   = {Symington, Andrew and De Nardi, Renzo and Julier, Simon and Hailes, Stephen},
  Booktitle                = {2014 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  Year                     = {2014},
  Month                    = {9},
  Pages                    = {3382--3388},
  Publisher                = {IEEE},

  Doi                      = {10.1109/IROS.2014.6943033},
  ISBN                     = {978-1-4799-6934-0},
  Url                      = {http://ieeexplore.ieee.org/document/6943033/}
}

@Article{Tai2016,
  Title                    = {{A Survey of Deep Network Solutions for Learning Control in Robotics: From Reinforcement to Imitation}},
  Author                   = {Tai, Lei and Zhang, Jingwei and Liu, Ming and Boedecker, Joschka and Burgard, Wolfram},
  Year                     = {2016},

  Month                    = {12},

  Arxivid                  = {1612.07139},
  Url                      = {http://arxiv.org/abs/1612.07139}
}

@Article{Tarapore2019FaultDetection,
  Title                    = {{Fault Detection in a Swarm of Physical Robots Based on Behavioral Outlier Detection}},
  Author                   = {Tarapore, Danesh and Timmis, Jon and Christensen, Anders Lyhne},
  Journal                  = {IEEE Transactions on Robotics},
  Year                     = {2019},

  Month                    = {8},
  Pages                    = {1--7},

  Doi                      = {10.1109/tro.2019.2929015},
  ISSN                     = {1552-3098},
  Publisher                = {Institute of Electrical and Electronics Engineers (IEEE)}
}

@InProceedings{Thomas2005Multi-robotScenarios,
  Title                    = {{Multi-robot task allocation in lunar mission construction scenarios}},
  Author                   = {Thomas, George and Howard, Ayanna M. and Williams, Andrew B. and Moore-Alston, Aryen},
  Booktitle                = {Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics},
  Year                     = {2005},
  Pages                    = {518--523},
  Volume                   = {1},

  Doi                      = {10.1109/icsmc.2005.1571198},
  ISSN                     = {1062922X},
  Keywords                 = {Multi-agent coordination, Multi-robot systems, Space exploration, Task allocation}
}

@TechReport{Tomlin2000ASystems,
  Title                    = {{A Game Theoretic Approach to Controller Design for Hybrid Systems}},
  Author                   = {Tomlin, Claire J and Lygeros, John and Shankar Sastry, S},
  Year                     = {2000},

  Keywords                 = {Aircraft control, air-traffic control, automated high-ways, game theory, hybrid automata, optimal control}
}

@Article{Torreno2017CooperativeSurvey,
  Title                    = {{Cooperative multi-Agent planning: A survey}},
  Author                   = {Torreno, Alejandro and Onaindia, Eva and Komenda, Antoní N. and S Tolba, Michal},
  Journal                  = {ACM Computing Surveys},
  Year                     = {2017},

  Month                    = {11},
  Number                   = {6},
  Volume                   = {50},

  Doi                      = {10.1145/3128584},
  ISSN                     = {15577341},
  Keywords                 = {Distribution, Multi-Agent heuristic functions, Planning and coordination strategies, Privacy preservation},
  Publisher                = {Association for Computing Machinery}
}

@TechReport{TrackExplainableReview,
  Title                    = {{Explainable Agents and Robots: Results from a Systematic Literature Review}},
  Author                   = {Track, Robotics and Anjomshoae, Sule and Najjar, Amro and Calvaresi, Davide and Fr{\"{a}}mling, Kary},

  Keywords                 = {Explainable AI, autonomous agents, goal-based XAI, human-robot interaction},
  Url                      = {www.ifaamas.org}
}

@TechReport{Track2018ApprenticeshipTask,
  Title                    = {{Apprenticeship Bootstrapping: Inverse Reinforcement Learning in a Multi-Skill UAV-UGV Coordination Task}},
  Author                   = {Track, Robotics and Nguyen, Hung The and Garratt, Matthew and Bui, Lam Thu and Abbass, Hussein and Lam, Thu and Bui, Hussein Abbass},
  Year                     = {2018},

  Keywords                 = {Apprenticeship Learning, Deep Q-learning, Ground-Air Interaction, Inverse Reinforcement Learning, UAVs, UGVs},
  Url                      = {www.ifaamas.org}
}

@Book{Fredi2010,
  Title                    = {Optimal control of partial differential equations. Theory, methods and applications},
  Author                   = {Tröltzsch, Fredi},
  Year                     = {2010},
  Month                    = {01},
  Volume                   = {112},

  Doi                      = {10.1090/gsm/112}
}

@Article{Tuyls2006AnGames,
  Title                    = {{An Evolutionary Dynamical Analysis of Multi-Agent Learning in Iterated Games}},
  Author                   = {Tuyls, Karl and Jan ', Pieter and Hoen, T and Nl, Hoen@cwi and Vanschoenwinkel, Bram},
  Journal                  = {Autonomous Agents and Multi-Agent Systems},
  Year                     = {2006},
  Pages                    = {115--153},
  Volume                   = {12},

  Doi                      = {10.1007/s10458-005-3783-9},
  Keywords                 = {COllective INtelligence, Evolutionary Game Theory, iterated games, multi-agent systems, reinforcement learning}
}

@TechReport{TuylsLectureScience,
  Title                    = {{Lecture Notes in Artificial Intelligence 3898 Subseries of Lecture Notes in Computer Science}},
  Author                   = {Tuyls, Karl and Jan, Pieter and Verbeeck, Katja and Sen, Sandip}
}

@TechReport{VallamDynamicFormat,
  Title                    = {{Dynamic Particle Allocation to Solve Interactive POMDP Models for Social Decision Making AAMAS; ACM proceedings; L A T E X; text tagging ACM Reference Format}},
  Author                   = {Vallam, Rohith Dwarakanath and Ahuja, Sarthak and Shravan, Surya and Sajja, Kumar and Chaudhuri, Ritwik and Pimplikar, Rakesh and Mukherjee, Kushal and Narayanam, Ramasuri and Parija, Gyana and Dwarakanath Vallam, Rohith},

  Keywords                 = {AAMAS, ACM proceedings, LaTeX, text tagging},
  Publisher                = {AAMAS},
  Url                      = {www.ifaamas.org}
}

@Article{VanParys2017,
  Title                    = {{Distributed MPC for multi-vehicle systems moving in formation}},
  Author                   = {{Van Parys}, Ruben and Pipeleers, Goele},
  Journal                  = {Robotics and Autonomous Systems},
  Year                     = {2017},

  Month                    = {nov},
  Pages                    = {144--152},
  Volume                   = {97},

  Abstract                 = {This work presents a novel distributed model predictive control (DMPC) strategy for controlling multi-vehicle systems moving in formation. The vehicles' motion trajectories are parameterized as polynomial splines and by exploiting the properties of the B-spline basis functions, constraints on the trajectories are efficiently enforced. The computations for solving the resulting optimization problem are distributed among the agents by the Alternating Direction Method of Multipliers (ADMM). In order to reduce the computation time and the amount of inter-vehicle interaction, only one ADMM iteration is performed per control update. In this way the method converges over the subsequent control updates. Simulations for various nonholonomic vehicle types and an experimental validation on in-house developed robotic platforms prove the capability of the proposed approach. A supporting software toolbox is provided that implements the proposed approach and that facilitates its use.},
  Doi                      = {10.1016/j.robot.2017.08.009},
  ISSN                     = {09218890},
  Keywords                 = {Alternating Direction Method of Multipliers (ADMM),B-spline,Distributed model predictive control (DMPC),Nonholonomic multi-vehicle system},
  Publisher                = {Elsevier B.V.}
}

@Article{Vaughan2008,
  Title                    = {{Massively multi-robot simulation in stage}},
  Author                   = {Vaughan, Richard},
  Journal                  = {Swarm Intell},
  Year                     = {2008},
  Pages                    = {189--208},
  Volume                   = {2},

  Doi                      = {10.1007/s11721-008-0014-4},
  Keywords                 = {Multi-robot {\textperiodcentered}, Player/stage, Simulation {\textperiodcentered}, Stage {\textperiodcentered}, Swarm {\textperiodcentered}},
  Url                      = {http://dx.doi.org/10.1007/s11721-008-0014-4}
}

@Article{Venkat2006,
  Title                    = {{Distributed model predictive control: Theory and applications}},
  Author                   = {Venkat, Aswin},
  Journal                  = {Philosophy},
  Year                     = {2006},
  Pages                    = {352},

  Abstract                 = {Most standard model predictive control (MPC) implementations partition the plant into sev- eral units and apply MPC individually to these units. It is known that such a completely de- centralized control strategy may result in unacceptable control performance, especially if the units interact strongly. Completely centralized control of large, networked systems is viewed by most practitioners as impractical and unrealistic. In this dissertation, a new framework for distributed, linear MPC with guaranteed closed-loop stability and performance properties is presented. A modeling framework that quantifies the interactions among subsystems is em- ployed. One may think that modeling the interactions between subsystems and exchanging trajectory information among MPCs (communication) is sufficient to improve controller per- formance. We show that this idea is incorrect and may not provide even closed-loop stability. Acooperative distributedMPCframework, in which the objective functions of the local MPCs are modified to achieve systemwide control objectives is proposed. This approach allows prac- titioners to tackle large, interacting systems by building on localMPCsystems already in place. The iterations generated by the proposed distributed MPC algorithm are systemwide feasible, and the controller based on any intermediate termination of the algorithm is closed-loop stable. These two features allow the practitioner to terminate the distributed MPC algorithm at the end of the sampling interval, even if convergence is not achieved. If iterated to conver- gence, the distributed MPC algorithm achieves optimal, centralized MPC control. Building on results obtained under state feedback, we tackle next, distributed MPC under output feedback. Two distributed estimator design strategies are proposed. Each es- timator is stable and uses only local measurements to estimate subsystem states. Feasibility and closed-loop stability for all distributed MPC algorithm iteration numbers are established for the distributed estimator-distributed regulator assembly in the case of decaying estimate error. A subsystem-based disturbance modeling framework to eliminate steady-state offset due to modeling errors and unmeasured disturbances is presented. Conditions to verify suit- ability of chosen local disturbance models are provided. A distributed target calculation al- gorithm to compute steady-state targets locally is proposed. All iterates generated by the distributed target calculation algorithm are feasible steady states. Conditions under which the proposed distributed MPC framework, with distributed estimation, distributed target cal- culation and distributed regulation, achieves offset-free control at steady state are described. Finally, the distributed MPC algorithm is augmented to allow asynchronous optimization and asynchronous feedback. Asynchronous feedback distributed MPC enables the practitioner to achieve performance superior to centralized MPC operated at the slowest sampled rate. Ex- amples from chemical engineering, electrical engineering and civil engineering are examined and benefits of employing the proposed distributed MPC paradigm are demonstrated.},
  File                     = {::},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.101.410{\&}rep=rep1{\&}type=pdf{\%}5Cnhttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.101.410{\%}7B{\&}{\%}7Drep=rep1{\%}7B{\&}{\%}7Dtype=pdf}
}

@Article{Virgili-Llop2019AttitudeShifting,
  Title                    = {{Attitude stabilization of spacecraft in very low earth orbit by center-of-mass shifting}},
  Author                   = {Virgili-Llop, Josep and Polat, Halis C. and Romano, Marcello},
  Journal                  = {Frontiers Robotics AI},
  Year                     = {2019},
  Number                   = {FEB},
  Volume                   = {6},

  Doi                      = {10.3389/frobt.2019.00007},
  ISSN                     = {22969144},
  Keywords                 = {Aerodynamic disturbance, Attitude control, Attitude stabilization, CubeSat, Movable masses, Shifting masses, Spacecraft aerodynamics, Very Low Earth Orbit},
  Publisher                = {Frontiers Media S.A.}
}

@TechReport{Vitelli,
  Title                    = {{CARMA: A Deep Reinforcement Learning Approach to Autonomous Driving}},
  Author                   = {Vitelli, Matt and Nayebi, Aran}
}

@TechReport{Wang2019EvolvingBehavior,
  Title                    = {{Evolving Intrinsic Motivations for Altruistic Behavior}},
  Author                   = {Wang, Jane X and Hughes, Edward and Fernando, Chrisantha and Czarnecki, Wojciech M and Du{\'{e}}{\~{n}}ez-Guzm{\'{a}}n, Edgar A and Leibo, Joel Z and Czar-necki, Wojciech M},
  Year                     = {2019},

  Booktitle                = {IFAAMAS},
  Keywords                 = {altruism, evolution, multi-agent, social dilemmas},
  Url                      = {www.ifaamas.org},
  Volume                   = {10}
}

@Article{Wang2018,
  Title                    = {{Deep Reinforcement Learning for Autonomous Driving}},
  Author                   = {Wang, Sen and Jia, Daoyuan and Weng, Xinshuo},
  Year                     = {2018},

  Month                    = {11},

  Arxivid                  = {1811.11329},
  Url                      = {http://arxiv.org/abs/1811.11329}
}

@Article{Weisstein,
  Title                    = {{Green's Theorem}},
  Author                   = {Weisstein, Eric W.},

  Keywords                 = {15, 15A72, 26B, Mathematics:Algebra:Vector Algebra, Mathematics:Calculus and Analysis:Calculus:Multiva},
  Publisher                = {Wolfram Research, Inc.},
  Url                      = {http://mathworld.wolfram.com/GreensTheorem.html}
}

@TechReport{Weyns2018EngineeringSystems,
  Title                    = {{Engineering Multi-Agent Systems}},
  Author                   = {Weyns, Danny and Mascardi, Viviana and Ricci, Alessandro},
  Year                     = {2018},

  Booktitle                = {EMAS},
  Doi                      = {10.1007/978-3-030-25693-7},
  Url                      = {http://www.springer.com/series/1244}
}

@InCollection{Wingate2012,
  Title                    = {{Predictively defined representations of state}},
  Author                   = {Wingate, David},
  Booktitle                = {Adaptation, Learning, and Optimization},
  Publisher                = {Springer Verlag},
  Year                     = {2012},
  Pages                    = {415--439},
  Volume                   = {12},

  Abstract                 = {The concept of state is central to dynamical systems. In any timeseries problem—such as filtering, planning or forecasting—models and algorithms summarize important information from the past into some sort of state variable. In this chapter, we start with a broad examination of the concept of state, with emphasis on the fact that there are many possible representations of state for a given dynamical system, each with different theoretical and computational properties. We then focus on models with predictively defined representations of state that represent state as a set of statistics about the short-term future, as opposed to the classic approach of treating state as a latent, unobservable quantity. In other words, the past is summarized into predictions about the actions and observations in the short-term future, which can be used to make further predictions about the infinite future.While this representational idea applies to any dynamical system problem, it is particularly useful in a model-based RL context, when an agent must learn a representation of state and a model of system dynamics online: because the representation (and hence all of the model's parameters) are defined using only statistics of observable quantities, their learning algorithms are often straightforward and have attractive theoretical properties. Here, we survey the basic concepts of predictively defined representations of state, important auxiliary constructs (such as the systems dynamics matrix), and theoretical results on their representational power and learnability.},
  Doi                      = {10.1007/978-3-642-27645-3_13},
  ISSN                     = {18674542},
  Keywords                 = {Covariance,Entropy,Posit,Tated,Transportation}
}

@Book{Woolridge2009,
  Title                    = {An Introduction to MultiAgent Systems},
  Author                   = {Wooldridge, Michael},
  Publisher                = {Wiley Publishing},
  Year                     = {2009},
  Edition                  = {2nd},

  ISBN                     = {0470519460}
}

@InProceedings{Yagan2007CoordinatedControl,
  Title                    = {{Coordinated reinforcement learning for decentralized optimal control}},
  Author                   = {Yagan, Daniel and Tham, Chen Khong},
  Booktitle                = {Proceedings of the 2007 IEEE Symposium on Approximate Dynamic Programming and Reinforcement Learning, ADPRL 2007},
  Year                     = {2007},
  Pages                    = {296--302},

  Doi                      = {10.1109/ADPRL.2007.368202},
  ISBN                     = {1424407060}
}

@InProceedings{Yaghmaie2013,
  Title                    = {{A new method for mobile robot navigation in dynamic environment: Escaping algorithm}},
  Author                   = {Yaghmaie, F. Adib and Mobarhani, A. and Taghirad, H. D.},
  Booktitle                = {2013 First RSI/ISM International Conference on Robotics and Mechatronics (ICRoM)},
  Year                     = {2013},
  Month                    = {2},
  Pages                    = {212--217},
  Publisher                = {IEEE},

  Doi                      = {10.1109/ICRoM.2013.6510107},
  ISBN                     = {978-1-4673-5811-8},
  Url                      = {http://ieeexplore.ieee.org/document/6510107/}
}

@TechReport{Yang2004,
  Title                    = {{Multiagent Reinforcement Learning for Multi-Robot Systems: A Survey Cooperative Control and Decision Making of Multiple Agent Systems View project autonomous and adaptive systems View project Multiagent Reinforcement Learning for Multi-Robot Systems: A Survey}},
  Author                   = {Yang, Erfu and Gu, Dongbing},
  Year                     = {2004},

  Abstract                 = {Multiagent reinforcement learning for multi-robot systems is a challenging issue in both robotics and artificial intelligence. With the ever increasing interests in theoretical researches and practical applications, currently there have been a lot of efforts towards providing some solutions to this challenge. However, there are still many difficulties in scaling up the multiagent reinforcement learning to multi-robot systems. The main objective of this paper is to provide a survey, though not completely on the multiagent reinforcement learning in multi-robot systems. After reviewing important advances in this field, some challenging problems and promising research directions are analyzed. A concluding remark is made from the perspectives of the authors.},
  File                     = {::},
  Mendeley-groups          = {STAI/Literature Review},
  Url                      = {https://www.researchgate.net/publication/2948830}
}

@TechReport{YangNoRML:Learning,
  Title                    = {{NoRML: No-Reward Meta Learning}},
  Author                   = {Yang, Yuxiang and Caluwaerts, Ken and Iscen, Atil and Tan, Jie and Finn, Chelsea},

  Booktitle                = {IFAAMAS},
  Keywords                 = {Deep Learning, Meta-Learning, Reinforcement Learning},
  Url                      = {www.ifaamas.org},
  Volume                   = {9}
}

@TechReport{Yang2018,
  Title                    = {{Mean Field Multi-Agent Reinforcement Learning}},
  Author                   = {Yang, Yaodong and Luo, Rui and Li, Minne and Zhou, Ming and Zhang, Weinan and Wang, Jun},
  Year                     = {2018},

  Abstract                 = {Existing multi-agent reinforcement learning methods are limited typically to a small number of agents. When the agent number increases largely, the learning becomes intractable due to the curse of the dimensionality and the exponential growth of agent interactions. In this paper, we present Mean Field Reinforcement Learning where the interactions within the population of agents are approximated by those between a single agent and the average effect from the overall population or neighboring agents; the interplay between the two entities is mutually reinforced: the learning of the individual agent's optimal policy depends on the dynamics of the population, while the dynamics of the population change according to the collective patterns of the individual policies. We develop practical mean field Q-learning and mean field Actor-Critic algorithms and analyze the convergence of the solution to Nash equilibrium. Experiments on Gaussian squeeze, Ising model, and battle games justify the learning effectiveness of our mean field approaches. In addition, we report the first result to solve the Ising model via model-free reinforcement learning methods.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1802.05438v4},
  Eprint                   = {1802.05438v4},
  File                     = {:home/aamalh/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2018 - Mean Field Multi-Agent Reinforcement Learning.pdf:pdf}
}

@Article{Yin2014,
  Title                    = {{A simplified predictive control of constrained Markov jump system with mixed uncertainties}},
  Author                   = {Yin, Yanyan and Liu, Yanqing and Karimi, Hamid R.},
  Journal                  = {Abstract and Applied Analysis},
  Year                     = {2014},
  Volume                   = {2014},

  Abstract                 = {A simplified model predictive control algorithm is designed for discrete-time Markov jump systems with mixed uncertainties. The mixed uncertainties include model polytope uncertainty and partly unknown transition probability. The simplified algorithm involves finite steps. Firstly, in the previous steps, a simplified mode-dependent predictive controller is presented to drive the state to the neighbor area around the origin. Then the trajectory of states is driven as expected to the origin by the final-step mode-independent predictive controller. The computational burden is dramatically cut down and thus it costs less time but has the acceptable dynamic performance. Furthermore, the polyhedron invariant set is utilized to enlarge the initial feasible area. The numerical example is provided to illustrate the efficiency of the developed results. {\textcopyright} 2014 Yanyan Yin et al.},
  Doi                      = {10.1155/2014/475808},
  File                     = {:Users/aamalh/Library/Application Support/Mendeley Desktop/Downloaded/Yin, Liu, Karimi - 2014 - A simplified predictive control of constrained Markov jump system with mixed uncertainties.pdf:pdf},
  ISSN                     = {16870409},
  Publisher                = {Hindawi Publishing Corporation}
}

@Article{Zadeh1965,
  Title                    = {{Fuzzy sets}},
  Author                   = {Zadeh, L.A.},
  Journal                  = {Information and Control},
  Year                     = {1965},

  Month                    = {6},
  Number                   = {3},
  Pages                    = {338--353},
  Volume                   = {8},

  Doi                      = {10.1016/S0019-9958(65)90241-X},
  ISSN                     = {0019-9958},
  Publisher                = {Academic Press},
  Url                      = {https://www.sciencedirect.com/science/article/pii/S001999586590241X}
}

@Article{Zahadat2016DivisionInhibition,
  Title                    = {{Division of labor in a swarm of autonomous underwater robots by improved partitioning social inhibition}},
  Author                   = {Zahadat, Payam and Schmickl, Thomas},
  Journal                  = {Adaptive Behavior},
  Year                     = {2016},
  Number                   = {2},
  Pages                    = {87--101},
  Volume                   = {24},

  Doi                      = {10.1177/1059712316633028},
  ISSN                     = {17412633},
  Keywords                 = {Swarm intelligence, adaptive division of labor, bio-inspired algorithm, distributed partitioning, social inhibition, swarm robotics},
  Publisher                = {SAGE Publications Ltd}
}

@InProceedings{Zhang2012AnTeams,
  Title                    = {{An efficient stochastic clustering auction for heterogeneous robot teams}},
  Author                   = {Zhang, Kai and Collins, Emmanuel G. and Barbu, Adrian},
  Booktitle                = {2012 IEEE International Conference on Robotics and Automation},
  Year                     = {2012},
  Month                    = {5},
  Pages                    = {4806--4813},
  Publisher                = {IEEE},

  Doi                      = {10.1109/ICRA.2012.6224588},
  ISBN                     = {978-1-4673-1405-3},
  Url                      = {http://ieeexplore.ieee.org/document/6224588/}
}

@TechReport{Zhao2015,
  Title                    = {{3D Obstacle Avoidance for Unmanned Autonomous System (UAS)}},
  Author                   = {Zhao, Lin},
  Year                     = {2015},

  Keywords                 = {Autonomous, Obstacle Aviodance, UAS, three-dimensional},
  Url                      = {http://digitalscholarship.unlv.edu/thesesdissertationshttp://digitalscholarship.unlv.edu/thesesdissertations/2507}
}

@Article{Zheng2017,
  Title                    = {{Distributed Model Predictive Control for Heterogeneous Vehicle Platoons under Unidirectional Topologies}},
  Author                   = {Zheng, Yang and Li, Shengbo Eben and Li, Keqiang and Borrelli, Francesco and Hedrick, J. Karl},
  Journal                  = {IEEE Transactions on Control Systems Technology},
  Year                     = {2017},

  Month                    = {may},
  Number                   = {3},
  Pages                    = {899--910},
  Volume                   = {25},

  Abstract                 = {This paper presents a distributed model predictive control (DMPC) algorithm for heterogeneous vehicle platoons with unidirectional topologies and a priori unknown desired set point. The vehicles (or nodes) in a platoon are dynamically decoupled but constrained by spatial geometry. Each node is assigned a local open-loop optimal control problem only relying on the information of neighboring nodes, in which the cost function is designed by penalizing on the errors between the predicted and assumed trajectories. Together with this penalization, an equality-based terminal constraint is proposed to ensure stability, which enforces the terminal states of each node in the predictive horizon equal to the average of its neighboring states. By using the sum of local cost functions as a Lyapunov candidate, it is proved that asymptotic stability of such a DMPC can be achieved through an explicit sufficient condition on the weights of the cost functions. Simulations with passenger cars demonstrate the effectiveness of the proposed DMPC.},
  Doi                      = {10.1109/TCST.2016.2594588},
  ISSN                     = {10636536},
  Keywords                 = {Autonomous vehicle,distributed control,graph theory heterogeneous platoon,model predictive control (MPC)},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc.}
}

@Misc{6.Documentation,
  Title                    = {{6. Camera Hardware — Picamera 1.12 documentation}},

  Url                      = {https://picamera.readthedocs.io/en/release-1.12/fov.html}
}

@Misc{BASE,
  Title                    = {{BASE}},

  Url                      = {https://base.xsens.com/hc/en-us/articles/115000224125-RMS-noise-of-accelerometers-and-gyroscopes}
}

@Misc{BASEb,
  Title                    = {{BASE}},

  Url                      = {https://base.xsens.com/hc/en-us/articles/115000224125-RMS-noise-of-accelerometers-and-gyroscopes}
}

@Misc{BASEc,
  Title                    = {{BASE}},

  Url                      = {https://base.xsens.com/hc/en-us/articles/115000224125-RMS-noise-of-accelerometers-and-gyroscopes}
}

@Misc{BasicDownload,
  Title                    = {{Basic variety of flat drones Vector | Free Download}},

  Url                      = {https://www.freepik.com/free-vector/basic-variety-flat-drones_1348538.htm#page=1&query=drone&position=2}
}

@Misc{ClassificationUse,
  Title                    = {{Classification Accuracy is Not Enough: More Performance Measures You Can Use}},

  Url                      = {https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/}
}

@TechReport{CS229Algorithm,
  Title                    = {{CS229 Simplified SMO Algorithm}},

  Url                      = {http://research.microsoft.com/}
}

@Misc{DataKaggle,
  Title                    = {{Data Science for Good: Kiva Crowdfunding | Kaggle}},

  Url                      = {https://www.kaggle.com/kiva/data-science-for-good-kiva-crowdfunding}
}

@Misc{DJISpecs,
  Title                    = {{DJI Tello Specs}},

  Url                      = {https://www.drone-world.com/dji-tello-specs}
}

@Misc{DJISpecsb,
  Title                    = {{DJI Tello Specs}},

  Url                      = {https://www.drone-world.com/dji-tello-specs}
}

@Misc{DragCoefficient,
  Title                    = {{Drag Coefficient}},

  Url                      = {https://www.engineeringtoolbox.com/drag-coefficient-d_627.html}
}

@Misc{DragPhysics,
  Title                    = {{Drag Forces – College Physics}},

  Url                      = {https://opentextbc.ca/physicstestbook2/chapter/drag-forces/}
}

@Misc{GetKingdom,
  Title                    = {{Get Started with ROS - MATLAB {\&}amp; Simulink - MathWorks United Kingdom}},

  Url                      = {https://uk.mathworks.com/help/robotics/examples/get-started-with-ros.html#d120e104}
}

@Misc{GPS.gov:Accuracy,
  Title                    = {{GPS.gov: GPS Accuracy}},

  Url                      = {https://www.gps.gov/systems/gps/performance/accuracy/}
}

@Misc{GPS.gov:Accuracyb,
  Title                    = {{GPS.gov: GPS Accuracy}},

  Url                      = {https://www.gps.gov/systems/gps/performance/accuracy/}
}

@Misc{GPS.gov:Accuracyc,
  Title                    = {{GPS.gov: GPS Accuracy}},

  Url                      = {https://www.gps.gov/systems/gps/performance/accuracy/}
}

@Misc{ModelingMotion,
  Title                    = {{Modeling Vehicle Dynamics - Quadcopter Equations of Motion - Autonomy in Motion}},

  Url                      = {http://charlestytler.com/quadcopter-equations-motion/}
}

@TechReport{ModuleObjectives,
  Title                    = {{Module 2 : Electrostatics Lecture 10 : Poisson Equations Objectives}},

  Url                      = {https://nptel.ac.in/courses/122101002/downloads/lec-10.pdf}
}

@Article{NoTitle,
  Title                    = {{(No Title)}}
}

@Misc{PIDInstruments,
  Title                    = {{PID Theory Explained - National Instruments}},

  Url                      = {http://www.ni.com/white-paper/3782/en/}
}

@Misc{PigpioLibrary,
  Title                    = {{pigpio library}},

  Url                      = {http://abyz.me.uk/rpi/pigpio/index.html}
}

@TechReport{QuadcopterControl,
  Title                    = {{Quadcopter Dynamics, Simulation, and Control}}
}

@TechReport{QuadcopterControlb,
  Title                    = {{Quadcopter Dynamics, Simulation, and Control}},

  Url                      = {http://andrew.gibiansky.com/downloads/pdf/Quadcopter%20Dynamics,%20Simulation,%20and%20Control.pdf}
}

@Misc{QuadcopterOfficial,
  Title                    = {{Quadcopter AR Drone 2.0 Elite Edition | Parrot Store Official}},

  Url                      = {https://www.parrot.com/uk/drones/parrot-ardrone-20-elite-edition}
}

@TechReport{TheEquation,
  Title                    = {{The Wave Equation}},

  Url                      = {http://ocw.mit.edu/terms.}
}

@Misc{TheSpeed,
  Title                    = {{The annual variability of wind speed}},

  Url                      = {https://www.wind-energy-the-facts.org/the-annual-variability-of-wind-speed.html}
}

@Misc{TrackingKingdom,
  Title                    = {{Tracking a Green Ball - MATLAB {\&}amp; Simulink Example - MathWorks United Kingdom}},

  Url                      = {https://uk.mathworks.com/help/supportpkg/raspberrypiio/examples/track-a-green-ball.html}
}

@Misc{UnderstandingRobotics,
  Title                    = {{Understanding Euler Angles | CH Robotics}},

  Url                      = {http://www.chrobotics.com/library/understanding-euler-angles}
}

@Misc{UsingKaggle,
  Title                    = {{Using Categorical Data with One Hot Encoding | Kaggle}},

  Url                      = {https://www.kaggle.com/dansbecker/using-categorical-data-with-one-hot-encoding}
}

@Misc{UsingKumar,
  Title                    = {{Using Support Vector Machines Effectively | Neeraj Kumar}},

  Url                      = {https://neerajkumar.org/writings/svm/}
}

@Book{2009ConvergenceSystems,
  Title                    = {{Convergence and Knowledge Processing in Multi-Agent Systems}},
  Publisher                = {Springer London},
  Year                     = {2009},

  Booktitle                = {Convergence and Knowledge Processing in Multi-Agent Systems},
  Doi                      = {10.1007/978-1-84882-063-0}
}

